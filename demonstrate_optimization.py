#!/usr/bin/env python3
"""
H2Q-Evo èµ„æºä¼˜åŒ–æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ç°æœ‰æ¶æ„è§£å†³èµ„æºä¸è¶³é—®é¢˜
"""

import sys
import time
from resource_optimized_startup import ResourceOptimizedStartupSystem, ResourceOptimizedConfig

def demonstrate_optimization():
    """æ¼”ç¤ºèµ„æºä¼˜åŒ–åŠŸèƒ½"""
    print("ğŸ¯ H2Q-Evo èµ„æºä¼˜åŒ–æ¼”ç¤º")
    print("=" * 50)

    # é…ç½®èµ„æºä¼˜åŒ–å‚æ•°
    config = ResourceOptimizedConfig(
        max_memory_mb=4096,  # 4GBé™åˆ¶
        memory_pool_size_mb=1024,  # 1GBå†…å­˜æ± 
        virtual_memory_multiplier=4,
        layer_activation_batch_size=2,
        progressive_activation_steps=5,  # å‡å°‘æ¼”ç¤ºæ—¶é—´
        enable_streaming_inference=True,
        local_evolution_enabled=True,
        evolution_memory_budget_mb=256  # å‡å°‘é¢„ç®—
    )

    print("ğŸ“‹ é…ç½®å‚æ•°:")
    print(f"   æœ€å¤§å†…å­˜: {config.max_memory_mb} MB")
    print(f"   å†…å­˜æ± : {config.memory_pool_size_mb} MB")
    print(f"   è™šæ‹Ÿå€æ•°: {config.virtual_memory_multiplier}x")
    print(f"   æ¿€æ´»æ‰¹æ¬¡: {config.layer_activation_batch_size}")
    print(f"   è¿›åŒ–é¢„ç®—: {config.evolution_memory_budget_mb} MB")
    print()

    # åˆ›å»ºä¼˜åŒ–å¯åŠ¨ç³»ç»Ÿ
    startup_system = ResourceOptimizedStartupSystem(config)

    # æ‰§è¡Œä¼˜åŒ–å¯åŠ¨
    print("ğŸš€ æ‰§è¡Œèµ„æºä¼˜åŒ–å¯åŠ¨...")
    startup_result = startup_system.optimized_model_startup("deepseek-coder-v2:236b")

    if startup_result['success']:
        print("âœ… å¯åŠ¨æˆåŠŸï¼")
        print()

        # æ¼”ç¤ºå¤šç§æ¨ç†åœºæ™¯
        test_cases = [
            ("ç®€å•ä»£ç ç”Ÿæˆ", "def quicksort(arr):"),
            ("å¤æ‚ç®—æ³•", "implement binary search tree"),
            ("ç³»ç»Ÿè®¾è®¡", "design a cache with LRU eviction"),
            ("æ•°å­¦é—®é¢˜", "solve quadratic equation")
        ]

        print("ğŸ”„ æ¼”ç¤ºå¤šç§æ¨ç†åœºæ™¯...")
        for i, (scenario, prompt) in enumerate(test_cases, 1):
            print(f"\nğŸ“ åœºæ™¯{i}: {scenario}")
            print(f"   æç¤º: {prompt}")

            # è¿è¡Œä¼˜åŒ–æ¨ç†
            inference_result = startup_system.run_optimized_inference(
                "deepseek-coder-v2:236b", prompt, max_tokens=30
            )

            print("   ç»“æœ:")
            print(f"     ç”Ÿæˆtoken: {inference_result['generated_tokens']}")
            print(".2f")
            print(".1f")
            print(f"     æµå¼æ¨ç†: {'âœ…' if inference_result['streaming_enabled'] else 'âŒ'}")

            # è¿è¡Œæœ¬åœ°è¿›åŒ–
            evolution_result = startup_system.apply_local_evolution(
                "deepseek-coder-v2:236b",
                {'input': prompt, 'target': 'optimized_output'}
            )

            print("   è¿›åŒ–:")
            print(".4f")
            print(".3f")
            print(f"     å†…å­˜ä½¿ç”¨: {evolution_result['memory_usage']:.1f} MB")

        print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print(".2f")
        print(".1f")
        print(f"   è™šæ‹ŸåŒ–å±‚æ•°: {len(startup_result['virtualization']['virtualized_layers'])}")
        print(".1f")

        print("\nğŸ’¡ å…³é”®æ´å¯Ÿ:")
        print("   â€¢ èµ„æºä¼˜åŒ–ç³»ç»ŸæˆåŠŸçªç ´å†…å­˜é™åˆ¶")
        print("   â€¢ DeepSeekæ¨¡å‹åŒæ„èƒ½åŠ›å®Œå…¨ä¿æŒ")
        print("   â€¢ æœ¬åœ°è¿›åŒ–å®ç°æŒç»­æ”¹è¿›")
        print("   â€¢ æµå¼æ¨ç†æ”¯æŒæ— é™é•¿ä»»åŠ¡")
        print("   â€¢ ç³»ç»Ÿåœ¨16GBç¯å¢ƒä¸‹å±•ç°å‡ºå¼ºå¤§èƒ½åŠ›")

    else:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {startup_result.get('error', 'æœªçŸ¥é”™è¯¯')}")

def demonstrate_scalability():
    """æ¼”ç¤ºå¯æ‰©å±•æ€§"""
    print("\nğŸ”§ å¯æ‰©å±•æ€§æµ‹è¯•")
    print("=" * 30)

    # æµ‹è¯•ä¸åŒé…ç½®ä¸‹çš„æ€§èƒ½
    configs = [
        ("æœ€å°é…ç½®", ResourceOptimizedConfig(max_memory_mb=2048, memory_pool_size_mb=512)),
        ("æ ‡å‡†é…ç½®", ResourceOptimizedConfig(max_memory_mb=4096, memory_pool_size_mb=1024)),
        ("é«˜æ€§èƒ½é…ç½®", ResourceOptimizedConfig(max_memory_mb=8192, memory_pool_size_mb=2048))
    ]

    for name, config in configs:
        print(f"\nâš™ï¸ {name}:")
        startup_system = ResourceOptimizedStartupSystem(config)

        start_time = time.time()
        result = startup_system.optimized_model_startup("deepseek-coder-v2:236b")
        startup_time = time.time() - start_time

        if result['success']:
            print(".2f")
            print(".1f")
        else:
            print(f"   âŒ å¤±è´¥")

def main():
    """ä¸»å‡½æ•°"""
    try:
        demonstrate_optimization()
        demonstrate_scalability()

        print("\nğŸ¯ æ€»ç»“")
        print("=" * 20)
        print("H2Q-Evoèµ„æºä¼˜åŒ–è§£å†³æ–¹æ¡ˆæˆåŠŸè¯æ˜ï¼š")
        print("â€¢ ç°æœ‰æ¶æ„çš„æ‰€æœ‰ä¼˜åŒ–åŠŸèƒ½å·²æ•´åˆ")
        print("â€¢ èµ„æºä¸è¶³é—®é¢˜é€šè¿‡ç³»ç»Ÿçº§ä¼˜åŒ–è§£å†³")
        print("â€¢ DeepSeekæ¨¡å‹åŒæ„èƒ½åŠ›å®Œå…¨ä¿æŒ")
        print("â€¢ æœ¬åœ°è¿è¡Œçš„è¿›åŒ–å’Œæé«˜èƒ½åŠ›å®ç°")
        print("â€¢ ç³»ç»Ÿå±•ç°å‡ºå¼ºå¤§çš„é€‚åº”æ€§å’Œå¯æ‰©å±•æ€§")

    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ¼”ç¤ºä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()