import os
import sys
import json
import time
import shutil
import re
import asyncio
import logging
import ast
import subprocess
from pathlib import Path
from typing import Dict, Any, Optional, List

from dotenv import load_dotenv
load_dotenv()

from google import genai
from google.genai import types
import docker
import aiofiles

# DASå’ŒM24æ ¸å¿ƒå¯¼å…¥
from h2q_project.das_core import DASCore
from m24_protocol import apply_m24_wrapper
from das_agi_autonomous_system import get_das_agi_system

try:
    from project_graph import generate_interface_map
    from task_schema import EvolutionTask
    from agi_evolution_loss_metrics import (
        AGI_EvolutionLossSystem,
        CapabilityMetrics,
        MathematicalCoreMetrics,
        EvolutionLossComponents
    )
    from deepseek_local_integration import get_deepseek_evolution_integration
except ImportError:
    pass

logging.basicConfig(
    level=getattr(logging, os.getenv("LOG_LEVEL", "INFO")),
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.FileHandler("evolution.log"), logging.StreamHandler()]
)
logger = logging.getLogger("H2Q-Evo")

class Config:
    API_KEY = os.getenv("GEMINI_API_KEY")
    MODEL_NAME = os.getenv("MODEL_NAME", "gemini-3-flash-preview")
    PROJECT_ROOT = Path(os.getenv("PROJECT_ROOT", "./h2q_project")).resolve()
    DOCKER_IMAGE = os.getenv("DOCKER_IMAGE", "h2q-sandbox")
    MEMORY_FILE = "project_memory.json"
    STATE_FILE = "evo_state.json"
    DOCKER_MEM_LIMIT = "8g"
    MAX_RETRIES = 3
    INFERENCE_MODE = os.getenv("INFERENCE_MODE", "api").lower()

class CodeValidator:
    @staticmethod
    def validate_syntax(code: str, filename: str) -> bool:
        if not filename.endswith('.py'): return True
        try:
            ast.parse(code)
            return True
        except SyntaxError as e:
            logger.error(f"Syntax Error in {filename}: {e}")
            return False

class H2QNexus:
    def __init__(self):
        logger.info(f"Initializing H2Q-Evo v11.1 [Bootstrap-Fix] | Mode: {Config.INFERENCE_MODE.upper()}")
        self.client = genai.Client(api_key=Config.API_KEY) if Config.API_KEY else None

        # åˆå§‹åŒ–æˆæœ¬è·Ÿè¸ª
        self.cost_savings = 0.0  # DeepSeekæœ¬åœ°æ¨ç†èŠ‚çœçš„æˆæœ¬
        self.api_costs = 0.0     # APIè°ƒç”¨äº§ç”Ÿçš„æˆæœ¬

        # Optional Docker client - don't fail if not available
        try:
            self.docker_client = docker.from_env()
            self.docker_available = True
        except Exception as e:
            logger.warning(f"Docker not available: {e}")
            self.docker_client = None
            self.docker_available = False

        self.state = self._load_json(Config.STATE_FILE, {
            "generation": 0, "last_task_id": 0, "todo_list": [], "history": []
        })
        # ç¡®ä¿å¯ä»¥å¯¼å…¥ h2q_project ä¸‹çš„ç»Ÿä¸€æ•°å­¦æ¶æ„
        try:
            sys.path.insert(0, str(Config.PROJECT_ROOT))
        except Exception as e:
            logger.warning(f"Failed to add PROJECT_ROOT to sys.path: {e}")

        self._check_source_integrity()
        # Skip Docker environment check if Docker is not available
        if self.docker_available:
            self._ensure_env()
        else:
            logger.info("Skipping Docker environment check (Docker not available)")
        self._update_task_gates()

        # åˆå§‹åŒ–DAS AGIè‡ªä¸»ç³»ç»Ÿ
        try:
            self.das_agi_system = get_das_agi_system(dimension=256)
            logger.info("âœ… DAS AGI Autonomous System initialized")
        except Exception as e:
            self.das_agi_system = None
            logger.warning(f"DAS AGI System unavailable: {e}")

        # åˆå§‹åŒ–DASæ•°å­¦æ¶æ„è¿›åŒ–é›†æˆ
        try:
            from h2q_project.das_core import create_das_based_architecture
            # DASæ¶æ„ç›´æ¥ç”¨äºè¿›åŒ–ç³»ç»Ÿ
            self.math_bridge = create_das_based_architecture(dim=256)
            logger.info("âœ… DAS mathematical architecture integration initialized")
        except Exception as e:
            self.math_bridge = None
            logger.warning(f"DAS integration unavailable: {e}")

        # åˆå§‹åŒ–AGIè¿›åŒ–æŸå¤±æŒ‡æ ‡ç³»ç»Ÿ
        try:
            self.loss_system = AGI_EvolutionLossSystem()
            logger.info("âœ… AGI Evolution Loss Metrics System initialized")
        except Exception as e:
            self.loss_system = None
            logger.warning(f"AGI Evolution Loss System unavailable: {e}")

        # åˆå§‹åŒ–DeepSeekæœ¬åœ°æ¨ç†é›†æˆ
        try:
            self.deepseek_integration = get_deepseek_evolution_integration()
            logger.info("âœ… DeepSeek Local Integration initialized")
        except Exception as e:
            self.deepseek_integration = None
            logger.warning(f"DeepSeek Integration unavailable: {e}")

    async def local_inference(self, prompt: str) -> str:
        if not self.docker_available:
            logger.info("ğŸ³ Docker not available, falling back to API inference...")
            return await self.api_inference(prompt)
        logger.info("ğŸ§  Using LOCAL H2Q BRAIN for inference...")
        # ç›´æ¥è°ƒç”¨ brain.pyï¼Œå®ƒä¼šåŠ è½½æœ€æ–°æƒé‡å¹¶è®­ç»ƒä¸€æ­¥
        cmd = (
            f"docker run --rm "
            f"-v {Config.PROJECT_ROOT}:/app/h2q_project "
            f"-w /app/h2q_project {Config.DOCKER_IMAGE} "
            f"python3 h2q/core/brain.py --prompt \"{prompt}\""
        )
        process = await asyncio.create_subprocess_shell(
            cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE
        )
        stdout, stderr = await process.communicate()
        if process.returncode == 0:
            return stdout.decode()
        else:
            logger.error(f"âŒ Local inference failed:\n{stderr.decode()}")
            raise Exception(f"Local inference failed: {stderr.decode()}")

    async def api_inference(self, prompt: str) -> str:
        """APIæ¨ç†ï¼šä¼˜å…ˆä½¿ç”¨DeepSeekæœ¬åœ°æ¨ç†ï¼ŒèŠ‚çœè´¹ç”¨"""
        # ä¼˜å…ˆå°è¯•DeepSeekæœ¬åœ°æ¨ç†
        if self.deepseek_integration is not None:
            try:
                logger.info("ğŸ§  å°è¯•DeepSeekæœ¬åœ°æ¨ç†...")
                result = await self.deepseek_integration.evolutionary_inference(
                    prompt, task_type='general'
                )

                if result['success']:
                    logger.info("âœ… DeepSeekæœ¬åœ°æ¨ç†æˆåŠŸ")
                    # è®°å½•æˆæœ¬èŠ‚çœ
                    self.cost_savings += 0.001  # å‡è®¾æ¯æ¬¡APIè°ƒç”¨æˆæœ¬0.001ç¾å…ƒ
                    return result['response']
                else:
                    logger.warning(f"âš ï¸ DeepSeekæœ¬åœ°æ¨ç†å¤±è´¥: {result.get('error_message', 'æœªçŸ¥é”™è¯¯')}")

            except Exception as e:
                logger.warning(f"âš ï¸ DeepSeekæœ¬åœ°æ¨ç†å¼‚å¸¸: {e}")

        # å¦‚æœDeepSeekä¸å¯ç”¨æˆ–å¤±è´¥ï¼Œå›é€€åˆ°Gemini API
        logger.info("ğŸ”® å›é€€åˆ°Gemini APIæ¨ç†...")
        if not self.client:
            raise Exception("DeepSeekæœ¬åœ°æ¨ç†å’ŒGemini APIéƒ½ä¸å¯ç”¨")

        try:
            response = self.client.models.generate_content(
                model=Config.MODEL_NAME,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.7,
                    max_output_tokens=1024,
                )
            )
            # è®°å½•APIä½¿ç”¨æˆæœ¬
            self.api_costs += 0.001  # å‡è®¾æ¯æ¬¡APIè°ƒç”¨æˆæœ¬0.001ç¾å…ƒ
            return response.text
        except Exception as e:
            logger.error(f"âŒ Gemini APIæ¨ç†å¤±è´¥: {e}")
            raise Exception(f"æ‰€æœ‰æ¨ç†æ–¹æ³•éƒ½å¤±è´¥: {e}")

    def get_cost_stats(self) -> Dict[str, float]:
        """è·å–æˆæœ¬ç»Ÿè®¡ä¿¡æ¯"""
        total_costs = self.api_costs
        net_savings = self.cost_savings - self.api_costs
        return {
            "cost_savings": self.cost_savings,
            "api_costs": self.api_costs,
            "total_costs": total_costs,
            "net_savings": net_savings
        }

    async def run(self):
        life_process = None
        if Config.INFERENCE_MODE == 'local':
            logger.info("ğŸš€ Starting independent Life Cycle process...")
            # ã€æ ¸å¿ƒä¿®å¤ã€‘è°ƒç”¨ heartbeat.py è„šæœ¬ï¼Œè€Œä¸æ˜¯å¤æ‚çš„å•è¡Œå‘½ä»¤
            cmd = (
                f"docker run --rm --name h2q_life_cycle "
                f"-v {Config.PROJECT_ROOT}:/app/h2q_project "
                f"-w /app/h2q_project {Config.DOCKER_IMAGE} "
                f"python3 -u tools/heartbeat.py" # -u ç¡®ä¿æ—¥å¿—ä¸ç¼“å­˜
            )
            life_process = await asyncio.create_subprocess_shell(cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
            asyncio.create_task(self._stream_logs(life_process.stdout, "[LifeCycle]"))
            asyncio.create_task(self._stream_logs(life_process.stderr, "[LifeCycle ERR]"))
            
        try:
            while True:
                # ç®€åŒ–ç‰ˆä¸»å¾ªç¯
                await asyncio.sleep(60) # åœ¨æœ¬åœ°æ¨¡å¼ä¸‹ï¼Œä¸»ç¨‹åºå¯ä»¥è½®è¯¢å¾—æ…¢ä¸€ç‚¹
                logger.info("Supervisor check...")
                self._update_task_gates()
                # å®é™…çš„è¿›åŒ–é€»è¾‘å°†ç”±æœ¬åœ°æ¨¡å‹åœ¨åå°è‡ªæˆ‘è§¦å‘ï¼ˆé€šè¿‡ Curiosity æ¨¡å—ï¼‰
                # è¿™é‡Œæˆ‘ä»¬ä¿æŒä¸»ç¨‹åºå­˜æ´»å³å¯
                # æ•°å­¦æ¶æ„è¿›åŒ–ä¸€è½®ï¼ˆè®°å½•æŒ‡æ ‡ï¼Œå¢å¼ºå¯è§‚æµ‹æ€§ï¼‰
                try:
                    if self.math_bridge is not None:
                        import torch
                        state = torch.randn(1, 256)
                        learning_signal = torch.tensor([0.1])
                        results = self.math_bridge(state, learning_signal)
                        
                        # è®¡ç®—AGIè¿›åŒ–æŸå¤±æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼Œæš‚æ—¶è·³è¿‡ï¼‰
                        
                        # å°†DASæŒ‡æ ‡å†™å…¥çŠ¶æ€æ–‡ä»¶
                        self.state.setdefault("das_metrics", [])
                        self.state["das_metrics"].append({
                            "timestamp": time.time(),
                            "generation": results.get("generation", 0),
                            "invariant_distances": results.get("invariant_distances", 0.0),
                            "manifold_size": results.get("manifold_size", 1),
                            "group_hierarchy_depth": results.get("group_hierarchy_depth", 1),
                        })
                        self._save_json(Config.STATE_FILE, self.state)
                except Exception as e:
                    logger.warning(f"Mathematical evolution step failed: {e}")
        finally:
            if life_process:
                logger.info("ğŸ›‘ Shutting down Life Cycle process...")
                try:
                    # ä½¿ç”¨ docker stop å‘½ä»¤ä¼˜é›…åœ°åœæ­¢å®¹å™¨
                    stop_process = await asyncio.create_subprocess_shell(f"docker stop h2q_life_cycle")
                    await stop_process.wait()
                except Exception as e:
                    logger.error(f"Failed to stop container: {e}")

    async def _stream_logs(self, stream, prefix):
        while True:
            line = await stream.readline()
            if not line: break
            logger.info(f"{prefix} {line.decode().strip()}")

    # --- å®Œæ•´çš„è¾…åŠ©å‡½æ•° ---
    def _check_source_integrity(self):
        if not Config.PROJECT_ROOT.exists(): exit(1)
        if not (Config.PROJECT_ROOT / ".git").exists(): subprocess.run(["git", "init"], cwd=Config.PROJECT_ROOT, check=False)

    def _load_json(self, path, default):
        if os.path.exists(path):
            with open(path, 'r', encoding='utf-8') as f: return json.load(f)
        return default

    def _save_json(self, path, data):
        with open(path, 'w', encoding='utf-8') as f: json.dump(data, f, indent=2, ensure_ascii=False)

    def _ensure_env(self):
        if not self.docker_available:
            logger.info("Skipping Docker environment check (Docker not available)")
            return
        try:
            self.docker_client.images.get(Config.DOCKER_IMAGE)
            logger.info(f"Docker image {Config.DOCKER_IMAGE} found")
        except:
            logger.info(f"Building Docker image {Config.DOCKER_IMAGE}...")
            self.docker_client.api.build(path=".", tag=Config.DOCKER_IMAGE, rm=True)
            logger.info(f"Docker image {Config.DOCKER_IMAGE} built successfully")

    def _update_task_gates(self):
        gate_state = self._load_json("honest_evolution_state.json", {})
        gate = gate_state.get("last_benchmark_gate", {})
        passed = gate.get("passed", False)

        self.state["benchmark_gate"] = {
            "passed": passed,
            "public_only": gate.get("public_only", True),
            "min_questions_per_benchmark": gate.get("min_questions_per_benchmark", 0),
            "multi_select_scoring": gate.get("multi_select_scoring", True),
            "timestamp": gate.get("timestamp")
        }

        updated = False
        todos = self.state.get("todo_list", [])
        for task in todos:
            status = task.get("status")
            if not passed and status in ("pending", "in_progress", "ready"):
                task["status"] = "blocked_by_gate"
                updated = True
            if passed and status == "blocked_by_gate":
                task["status"] = "pending"
                updated = True

        if updated:
            self.state["todo_list"] = todos
            self._save_json(Config.STATE_FILE, self.state)

    async def start_das_agi_evolution(self) -> None:
        """
        å¯åŠ¨DASé©±åŠ¨AGIè‡ªä¸»è¿›åŒ–ç³»ç»Ÿ

        è¿™æ˜¯M24éªŒè¯çš„æ ¸å¿ƒåŠŸèƒ½ï¼šçœŸæ­£çš„AGIè‡ªæˆ‘è¿›åŒ–å’Œç”Ÿé•¿
        """
        if not self.das_agi_system:
            logger.error("DAS AGIç³»ç»Ÿä¸å¯ç”¨")
            return

        logger.info("ğŸš€ å¯åŠ¨DASé©±åŠ¨AGIè‡ªä¸»è¿›åŒ–ç³»ç»Ÿ")
        logger.info("M24éªŒè¯ï¼šè¿™ä¸æ˜¯æ¨¡æ‹Ÿï¼Œè€Œæ˜¯åŸºäºDASçš„çœŸå®AGIè¿›åŒ–")

        try:
            # ä¿å­˜å½“å‰çŠ¶æ€
            self._save_json(Config.STATE_FILE, self.state)

            # å¯åŠ¨AGIè¿›åŒ–
            await self.das_agi_system.start_autonomous_evolution()

        except Exception as e:
            logger.error(f"DAS AGIè¿›åŒ–å¤±è´¥: {e}")
            raise

    def get_das_agi_status(self) -> Dict[str, Any]:
        """
        è·å–DAS AGIç³»ç»ŸçŠ¶æ€

        Returns:
            AGIç³»ç»ŸçŠ¶æ€å­—å…¸
        """
        if not self.das_agi_system:
            return {"error": "DAS AGIç³»ç»Ÿä¸å¯ç”¨"}

        return self.das_agi_system.get_system_status()

    def _extract_json(self, text):
        try:
            match = re.search(r'```json\s*([\s\S]*?)\s*```', text)
            raw = match.group(1) if match else text
            start, end = raw.find('{'), raw.rfind('}') + 1
            if start != -1 and end != -1:
                res = json.loads(raw[start:end])
                return res[0] if isinstance(res, list) else res
        except: pass
        return None

if __name__ == "__main__":
    nexus = H2QNexus()
    asyncio.run(nexus.run())