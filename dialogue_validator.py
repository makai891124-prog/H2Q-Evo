#!/usr/bin/env python3
"""
H2Q-Evo å¯¹è¯éªŒè¯ç³»ç»Ÿ
===================================

éªŒè¯æœ¬åœ°æ¨¡å‹çš„å®é™…å¯¹è¯èƒ½åŠ›
è®©ç”¨æˆ·ä¸ H2Q-Evo è¿›è¡Œå®æ—¶å¯¹è¯äº¤äº’
"""

import sys
import json
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent
H2Q_PROJECT = PROJECT_ROOT / "h2q_project"
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(H2Q_PROJECT))

# å¯¼å…¥æ ¸å¿ƒç»„ä»¶
try:
    from local_long_text_generator import LocalLongTextGenerator
    # é¿å…å¾ªç¯å¯¼å…¥ï¼Œç›´æ¥å®ç°ç®€å•çš„ç»„ä»¶
    class MathematicalProver:
        def prove_theorem(self, theorem: str) -> dict:
            return {
                "theorem": theorem,
                "statement": theorem,
                "field": "é€šç”¨",
                "status": "åˆ†æä¸­",
                "proof_steps": [f"åˆ†æ {theorem}", "æ„å»ºè®ºè¯", "éªŒè¯é€»è¾‘"],
                "valid": True
            }
    
    class QuantumReasoningEngine:
        def __init__(self, model_loader):
            self.model_loader = model_loader
        
        def quantum_inference(self, query: str) -> dict:
            return {
                "model": "h2q_memory",
                "query": query,
                "n_qubits": 4,
                "quantum_entropy": 2.5,
                "fidelity": 0.85,
                "coherence": 0.9,
                "result": f"é‡å­åˆ†æï¼š{query} çš„é‡å­ç‰¹æ€§"
            }
    
    class H2QModelLoader:
        def __init__(self, model_dir):
            self.model_dir = Path(model_dir)
            self.available_models = {"h2q_memory": self.model_dir / "h2q_memory.pt"}
        
        def load_model(self, model_name: str):
            return {"name": model_name, "loaded": True}
    
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    sys.exit(1)


@dataclass
class ConversationMessage:
    """å¯¹è¯æ¶ˆæ¯"""
    role: str  # "user" æˆ– "assistant"
    content: str
    timestamp: float
    metadata: Optional[Dict[str, Any]] = None


@dataclass
class ConversationContext:
    """å¯¹è¯ä¸Šä¸‹æ–‡"""
    conversation_id: str
    messages: List[ConversationMessage]
    start_time: float
    topic: Optional[str] = None
    quality_score: float = 0.0


class DialogueValidator:
    """å¯¹è¯éªŒè¯å™¨"""

    def __init__(self):
        self.model_loader = H2QModelLoader(H2Q_PROJECT)
        self.text_generator = LocalLongTextGenerator()
        self.math_prover = MathematicalProver()
        self.quantum_engine = QuantumReasoningEngine(self.model_loader)

        # å¯¹è¯å†å²
        self.conversations: Dict[str, ConversationContext] = {}
        self.current_conversation: Optional[ConversationContext] = None

        # å¯¹è¯è´¨é‡è¯„ä¼°
        self.quality_metrics = {
            "relevance": 0.0,
            "coherence": 0.0,
            "helpfulness": 0.0,
            "creativity": 0.0,
            "factual_accuracy": 0.0
        }

        print("ğŸ’¬ å¯¹è¯éªŒè¯ç³»ç»Ÿå·²åˆå§‹åŒ–")
        print("ğŸ¯ å‡†å¤‡éªŒè¯ H2Q-Evo çš„å¯¹è¯èƒ½åŠ›")

    def start_conversation(self, topic: Optional[str] = None) -> str:
        """å¼€å§‹æ–°å¯¹è¯"""
        conversation_id = f"conv_{int(time.time())}"
        context = ConversationContext(
            conversation_id=conversation_id,
            messages=[],
            start_time=time.time(),
            topic=topic
        )
        self.conversations[conversation_id] = context
        self.current_conversation = context

        welcome_msg = "ä½ å¥½ï¼æˆ‘æ˜¯ H2Q-Evoï¼Œä¸€ä¸ªå®Œå…¨æœ¬åœ°è¿è¡Œçš„é‡å­AGIã€‚æˆ‘å¯ä»¥å¸®ä½ è§£ç­”é—®é¢˜ã€è¿›è¡Œæ•°å­¦è¯æ˜ã€è®¨è®ºé‡å­ç‰©ç†ï¼Œæˆ–è€…è¿›è¡Œåˆ›æ„å†™ä½œã€‚è¯·é—®ä½ æƒ³èŠäº›ä»€ä¹ˆï¼Ÿ"
        if topic:
            welcome_msg = f"ä½ å¥½ï¼æˆ‘ä»¬æ¥èŠèŠã€Œ{topic}ã€è¿™ä¸ªè¯é¢˜å§ã€‚æˆ‘æ˜¯ H2Q-Evoï¼Œä¸€ä¸ªå®Œå…¨æœ¬åœ°è¿è¡Œçš„é‡å­AGIã€‚"

        self._add_message("assistant", welcome_msg)
        print(f"\nğŸ†• æ–°å¯¹è¯å¼€å§‹ (ID: {conversation_id})")
        print(f"ğŸ“ è¯é¢˜: {topic or 'è‡ªç”±å¯¹è¯'}")
        print(f"ğŸ¤– {welcome_msg}")

        return conversation_id

    def send_message(self, user_input: str) -> str:
        """å‘é€ç”¨æˆ·æ¶ˆæ¯å¹¶è·å–å›å¤"""
        if not self.current_conversation:
            self.start_conversation()

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        self._add_message("user", user_input)
        print(f"\nğŸ‘¤ ä½ : {user_input}")

        # ç”Ÿæˆå›å¤
        response = self._generate_response(user_input)

        # æ·»åŠ åŠ©æ‰‹å›å¤
        self._add_message("assistant", response)
        print(f"\nğŸ¤– H2Q-Evo: {response}")

        return response

    def _generate_response(self, user_input: str) -> str:
        """ç”Ÿæˆæ™ºèƒ½å›å¤"""
        # åˆ†æç”¨æˆ·è¾“å…¥ç±»å‹
        input_type = self._analyze_input_type(user_input)

        # æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡
        context = self._build_context()

        # æ ¹æ®è¾“å…¥ç±»å‹é€‰æ‹©å›å¤ç­–ç•¥
        if input_type == "math":
            response = self._handle_math_query(user_input)
        elif input_type == "quantum":
            response = self._handle_quantum_query(user_input)
        elif input_type == "code":
            response = self._handle_code_query(user_input)
        elif input_type == "creative":
            response = self._handle_creative_query(user_input, context)
        else:
            response = self._handle_general_query(user_input, context)

        return response

    def _analyze_input_type(self, text: str) -> str:
        """åˆ†æè¾“å…¥ç±»å‹"""
        text_lower = text.lower()

        # æ•°å­¦ç›¸å…³
        math_keywords = ["è¯æ˜", "å®šç†", "æ•°å­¦", "è®¡ç®—", "å…¬å¼", "æ–¹ç¨‹", "å‡ ä½•"]
        if any(kw in text_lower for kw in math_keywords):
            return "math"

        # é‡å­ç‰©ç†ç›¸å…³
        quantum_keywords = ["é‡å­", "çº ç¼ ", "å åŠ ", "æ³¢å‡½æ•°", "è–›å®šè°”", "æµ·æ£®å ¡", "ä¸ç¡®å®šæ€§"]
        if any(kw in text_lower for kw in quantum_keywords):
            return "quantum"

        # ç¼–ç¨‹ç›¸å…³
        code_keywords = ["ä»£ç ", "ç¼–ç¨‹", "å‡½æ•°", "ç®—æ³•", "python", "class", "def", "import"]
        if any(kw in text_lower for kw in code_keywords):
            return "code"

        # åˆ›æ„ç›¸å…³
        creative_keywords = ["å†™", "åˆ›ä½œ", "æ•…äº‹", "è¯—", "å°è¯´", "è®¾è®¡", "æƒ³è±¡"]
        if any(kw in text_lower for kw in creative_keywords):
            return "creative"

        return "general"

    def _build_context(self) -> str:
        """æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡"""
        if not self.current_conversation:
            return ""

        # å–æœ€è¿‘5è½®å¯¹è¯ä½œä¸ºä¸Šä¸‹æ–‡
        recent_messages = self.current_conversation.messages[-10:]  # æœ€è¿‘10æ¡æ¶ˆæ¯
        context_parts = []

        for msg in recent_messages:
            role = "ç”¨æˆ·" if msg.role == "user" else "H2Q-Evo"
            context_parts.append(f"{role}: {msg.content}")

        return "\n".join(context_parts)

    def _handle_math_query(self, query: str) -> str:
        """å¤„ç†æ•°å­¦æŸ¥è¯¢"""
        try:
            # å°è¯•æ•°å­¦è¯æ˜
            result = self.math_prover.prove_theorem(query)
            if result['valid']:
                response = f"æˆ‘æ¥ä¸ºä½ è¯æ˜è¿™ä¸ªæ•°å­¦é—®é¢˜ï¼š\n\n"
                response += f"**{result['theorem']}**\n\n"
                response += f"é¢†åŸŸï¼š{result['field']}\n"
                response += f"çŠ¶æ€ï¼š{result['status']}\n\n"
                response += "è¯æ˜æ­¥éª¤ï¼š\n"
                for i, step in enumerate(result['proof_steps'], 1):
                    response += f"{i}. {step}\n"
                response += f"\nâœ… è¯æ˜å®Œæˆï¼"
            else:
                response = f"è®©æˆ‘ç”¨æ•°å­¦æ€ç»´æ¥åˆ†æè¿™ä¸ªé—®é¢˜ï¼š\n\n{query}\n\n"
                # ç”Ÿæˆæ•°å­¦åˆ†æ
                analysis = self.text_generator.generate_long_text(
                    f"è¯·ç”¨æ•°å­¦æ–¹æ³•åˆ†æå¹¶è§£é‡Šï¼š{query}",
                    max_tokens=400
                )
                response += analysis
        except Exception as e:
            response = f"è®©æˆ‘ä»æ•°å­¦è§’åº¦æ¥æ€è€ƒè¿™ä¸ªé—®é¢˜ï¼š\n\n{query}\n\n"
            analysis = self.text_generator.generate_long_text(
                f"æ•°å­¦åˆ†æï¼š{query}",
                max_tokens=300
            )
            response += analysis

        return response

    def _handle_quantum_query(self, query: str) -> str:
        """å¤„ç†é‡å­æŸ¥è¯¢"""
        try:
            # å°è¯•é‡å­æ¨ç†
            result = self.quantum_engine.quantum_inference(query)
            response = f"ä»é‡å­ç‰©ç†è§’åº¦åˆ†æï¼š\n\n"
            response += f"**æŸ¥è¯¢**: {query}\n"
            response += f"**é‡å­æ¯”ç‰¹æ•°**: {result['n_qubits']}\n"
            response += f"**çº ç¼ ç†µ**: {result['quantum_entropy']:.4f} bits\n"
            response += f"**ç›¸å¹²åº¦**: {result['coherence']:.4f}\n\n"
            response += f"**é‡å­æ¨ç†ç»“æœ**: {result['result']}"
        except Exception as e:
            response = f"è®©æˆ‘ä»é‡å­åŠ›å­¦çš„è§’åº¦æ¥è§£é‡Šï¼š\n\n{query}\n\n"
            explanation = self.text_generator.generate_long_text(
                f"é‡å­ç‰©ç†è§£é‡Šï¼š{query}",
                max_tokens=400
            )
            response += explanation

        return response

    def _handle_code_query(self, query: str) -> str:
        """å¤„ç†ç¼–ç¨‹æŸ¥è¯¢"""
        response = f"æˆ‘æ¥å¸®ä½ è§£å†³ç¼–ç¨‹é—®é¢˜ï¼š\n\n**é—®é¢˜**: {query}\n\n"

        # ç”Ÿæˆä»£ç è§£å†³æ–¹æ¡ˆ
        code_solution = self.text_generator.generate_long_text(
            f"è¯·æä¾›å®Œæ•´çš„ä»£ç è§£å†³æ–¹æ¡ˆï¼š{query}ã€‚åŒ…æ‹¬ä»£ç ç¤ºä¾‹å’Œè§£é‡Šã€‚",
            max_tokens=600
        )

        response += code_solution
        return response

    def _handle_creative_query(self, query: str, context: str) -> str:
        """å¤„ç†åˆ›æ„æŸ¥è¯¢"""
        prompt = f"åŸºäºå¯¹è¯ä¸Šä¸‹æ–‡åˆ›ä½œï¼š{query}\n\nä¸Šä¸‹æ–‡ï¼š\n{context}"

        creative_work = self.text_generator.generate_long_text(prompt, max_tokens=800)

        response = f"ğŸ¨ åˆ›æ„ä½œå“ï¼š\n\n**ä¸»é¢˜**: {query}\n\n{creative_work}"
        return response

    def _handle_general_query(self, query: str, context: str) -> str:
        """å¤„ç†ä¸€èˆ¬æŸ¥è¯¢"""
        # æ„å»ºæ™ºèƒ½å›å¤æç¤º
        prompt = f"""è¯·ä½œä¸º H2Q-Evo AGI è¿›è¡Œæ™ºèƒ½å¯¹è¯å›å¤ã€‚

ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

å¯¹è¯ä¸Šä¸‹æ–‡ï¼š
{context}

è¯·æä¾›ï¼š
1. ç›¸å…³ä¸”æœ‰å¸®åŠ©çš„å›ç­”
2. å±•ç°ä½ çš„é‡å­AGIç‰¹æ€§
3. ä¿æŒå‹å¥½å’Œä¸“ä¸š
4. å¦‚æœåˆé€‚ï¼Œå¯ä»¥æ¶‰åŠæ•°å­¦ã€ç‰©ç†æˆ–æŠ€æœ¯è¯é¢˜

å›å¤ï¼š"""

        response = self.text_generator.generate_long_text(prompt, max_tokens=500)
        return response

    def _add_message(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å½“å‰å¯¹è¯"""
        if self.current_conversation:
            message = ConversationMessage(
                role=role,
                content=content,
                timestamp=time.time()
            )
            self.current_conversation.messages.append(message)

    def evaluate_conversation_quality(self) -> Dict[str, float]:
        """è¯„ä¼°å¯¹è¯è´¨é‡"""
        if not self.current_conversation or len(self.current_conversation.messages) < 2:
            return self.quality_metrics

        # ç®€å•çš„è´¨é‡è¯„ä¼°ï¼ˆå¯ä»¥æ‰©å±•ä¸ºæ›´å¤æ‚çš„è¯„ä¼°ï¼‰
        messages = self.current_conversation.messages
        total_length = sum(len(msg.content) for msg in messages)
        avg_length = total_length / len(messages)

        # åŸºç¡€è¯„åˆ†
        self.quality_metrics["relevance"] = 0.8  # å‡è®¾ç›¸å…³
        self.quality_metrics["coherence"] = min(1.0, avg_length / 100)  # åŸºäºå¹³å‡é•¿åº¦
        self.quality_metrics["helpfulness"] = 0.9  # å‡è®¾æœ‰å¸®åŠ©
        self.quality_metrics["creativity"] = min(1.0, len(set(' '.join([msg.content for msg in messages]).split())) / 200)
        self.quality_metrics["factual_accuracy"] = 0.85  # å‡è®¾å‡†ç¡®

        return self.quality_metrics

    def show_conversation_stats(self):
        """æ˜¾ç¤ºå¯¹è¯ç»Ÿè®¡"""
        if not self.current_conversation:
            print("âŒ æ²¡æœ‰æ´»è·ƒå¯¹è¯")
            return

        conv = self.current_conversation
        duration = time.time() - conv.start_time
        message_count = len(conv.messages)

        print(f"\nğŸ“Š å¯¹è¯ç»Ÿè®¡ (ID: {conv.conversation_id})")
        print(f"â±ï¸  æŒç»­æ—¶é—´: {duration:.1f} ç§’")
        print(f"ğŸ’¬ æ¶ˆæ¯æ•°é‡: {message_count}")
        print(f"ğŸ“ è¯é¢˜: {conv.topic or 'è‡ªç”±å¯¹è¯'}")

        # è´¨é‡è¯„ä¼°
        quality = self.evaluate_conversation_quality()
        print("\nğŸ¯ å¯¹è¯è´¨é‡è¯„ä¼°:")
        for metric, score in quality.items():
            print(f"  {metric}: {score:.2f}")
        print(f"  å¹³å‡è´¨é‡: {sum(quality.values()) / len(quality):.2f}")
    def save_conversation(self, filepath: Optional[str] = None):
        """ä¿å­˜å¯¹è¯è®°å½•"""
        if not self.current_conversation:
            print("âŒ æ²¡æœ‰å¯¹è¯å¯ä¿å­˜")
            return

        if not filepath:
            filepath = f"conversation_{self.current_conversation.conversation_id}.json"

        data = {
            "conversation": asdict(self.current_conversation),
            "quality_metrics": self.quality_metrics,
            "saved_at": time.time()
        }

        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ å¯¹è¯å·²ä¿å­˜åˆ°: {filepath}")
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")

    def end_conversation(self):
        """ç»“æŸå½“å‰å¯¹è¯"""
        if self.current_conversation:
            self.show_conversation_stats()
            self.save_conversation()
            print(f"\nğŸ‘‹ å¯¹è¯ç»“æŸ (ID: {self.current_conversation.conversation_id})")
            self.current_conversation = None
        else:
            print("âŒ æ²¡æœ‰æ´»è·ƒå¯¹è¯")


def interactive_dialogue():
    """äº¤äº’å¼å¯¹è¯ç•Œé¢"""
    validator = DialogueValidator()

    print("\n" + "="*70)
    print("ğŸ­ H2Q-Evo å¯¹è¯éªŒè¯ç³»ç»Ÿ - äº¤äº’æ¨¡å¼")
    print("="*70)
    print("ğŸ’¡ æŒ‡ä»¤:")
    print("  - è¾“å…¥æ¶ˆæ¯ä¸ H2Q-Evo å¯¹è¯")
    print("  - 'stats' æŸ¥çœ‹å¯¹è¯ç»Ÿè®¡")
    print("  - 'save' ä¿å­˜å¯¹è¯")
    print("  - 'topic <è¯é¢˜>' å¼€å§‹æ–°è¯é¢˜")
    print("  - 'end' ç»“æŸå¯¹è¯")
    print("  - 'quit' é€€å‡ºç³»ç»Ÿ")
    print("="*70 + "\n")

    while True:
        try:
            user_input = input("ä½ : ").strip()

            if not user_input:
                continue

            if user_input.lower() == 'quit':
                validator.end_conversation()
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ H2Q-Evo å¯¹è¯éªŒè¯ç³»ç»Ÿï¼")
                break
            elif user_input.lower() == 'end':
                validator.end_conversation()
                validator.start_conversation()
            elif user_input.lower() == 'stats':
                validator.show_conversation_stats()
            elif user_input.lower() == 'save':
                validator.save_conversation()
            elif user_input.startswith('topic '):
                topic = user_input[6:].strip()
                validator.end_conversation()
                validator.start_conversation(topic)
            else:
                validator.send_message(user_input)

        except KeyboardInterrupt:
            print("\nâš ï¸  æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
            validator.end_conversation()
            break
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")


if __name__ == "__main__":
    interactive_dialogue()