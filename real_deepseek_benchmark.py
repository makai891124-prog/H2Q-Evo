#!/usr/bin/env python3
"""
H2Q-Evo çœŸå®DeepSeekåŸºå‡†æµ‹è¯•

ä½¿ç”¨çœŸå®çš„DeepSeekæ¨¡å‹éªŒè¯H2Q-Evoç³»ç»Ÿçš„å®Œæ•´åŠŸèƒ½
"""

import requests
import json
import time
import torch
import torch.nn as nn
from typing import Dict, Any, List
import psutil
import numpy as np


def get_memory_info() -> Dict[str, float]:
    """è·å–å†…å­˜ä¿¡æ¯"""
    memory = psutil.virtual_memory()
    return {
        "total_gb": memory.total / (1024**3),
        "available_gb": memory.available / (1024**3),
        "used_gb": memory.used / (1024**3),
        "percentage": memory.percent
    }


class RealDeepSeekBenchmark:
    """çœŸå®DeepSeekåŸºå‡†æµ‹è¯•"""

    def __init__(self):
        self.model_name = "deepseek-coder:6.7b"
        self.base_url = "http://localhost:11434/api/generate"

    def test_basic_inference(self) -> Dict[str, Any]:
        """æµ‹è¯•åŸºæœ¬æ¨ç†"""
        print("ğŸ§ª æµ‹è¯•åŸºæœ¬æ¨ç†èƒ½åŠ›")

        payload = {
            "model": self.model_name,
            "prompt": "Write a Python function to calculate factorial",
            "stream": False,
            "options": {
                "num_predict": 50,
                "temperature": 0.1
            }
        }

        start_time = time.time()
        response = requests.post(self.base_url, json=payload, timeout=60)
        inference_time = time.time() - start_time

        if response.status_code == 200:
            result = response.json()
            output = result.get('response', '')

            return {
                "success": True,
                "inference_time": inference_time,
                "output_length": len(output),
                "output": output[:200] + "..." if len(output) > 200 else output
            }
        else:
            return {"success": False, "error": f"HTTP {response.status_code}"}

    def test_code_generation(self) -> Dict[str, Any]:
        """æµ‹è¯•ä»£ç ç”Ÿæˆ"""
        print("ğŸ’» æµ‹è¯•ä»£ç ç”Ÿæˆèƒ½åŠ›")

        payload = {
            "model": self.model_name,
            "prompt": "Create a Python class for a simple calculator with add, subtract, multiply, divide methods",
            "stream": False,
            "options": {
                "num_predict": 100,
                "temperature": 0.2
            }
        }

        start_time = time.time()
        response = requests.post(self.base_url, json=payload, timeout=60)
        inference_time = time.time() - start_time

        if response.status_code == 200:
            result = response.json()
            output = result.get('response', '')

            return {
                "success": True,
                "inference_time": inference_time,
                "output_length": len(output),
                "output": output[:300] + "..." if len(output) > 300 else output
            }
        else:
            return {"success": False, "error": f"HTTP {response.status_code}"}

    def test_crystallization_with_real_model(self) -> Dict[str, Any]:
        """ä½¿ç”¨çœŸå®æ¨¡å‹æµ‹è¯•ç»“æ™¶åŒ–"""
        print("ğŸ’ æµ‹è¯•ç»“æ™¶åŒ–ä¸çœŸå®æ¨¡å‹é›†æˆ")

        try:
            from model_crystallization_engine import ModelCrystallizationEngine, CrystallizationConfig

            # åˆ›å»ºä¸€ä¸ªæ›´å¤§çš„æµ‹è¯•æ¨¡å‹
            class LargerTestModel(nn.Module):
                def __init__(self):
                    super().__init__()
                    self.embedding = nn.Embedding(5000, 128)
                    self.layers = nn.ModuleList([
                        nn.TransformerEncoderLayer(
                            d_model=128, nhead=8, dim_feedforward=512, batch_first=True
                        ) for _ in range(3)
                    ])
                    self.output = nn.Linear(128, 5000)

                def forward(self, x):
                    x = self.embedding(x)
                    for layer in self.layers:
                        x = layer(x)
                    return self.output(x)

            model = LargerTestModel()
            original_params = sum(p.numel() for p in model.parameters())
            print(f"   åŸå§‹æ¨¡å‹å‚æ•°: {original_params:,}")

            # é…ç½®ç»“æ™¶åŒ–
            config = CrystallizationConfig(
                target_compression_ratio=8.0,
                max_memory_mb=1024
            )

            engine = ModelCrystallizationEngine(config)

            # æ‰§è¡Œç»“æ™¶åŒ–
            start_time = time.time()
            report = engine.crystallize_model(model, "real_model_test")
            crystallization_time = time.time() - start_time

            return {
                "success": True,
                "original_params": original_params,
                "compression_ratio": report.get('compression_ratio', 1.0),
                "quality_score": report.get('quality_score', 0.0),
                "crystallization_time": crystallization_time
            }

        except Exception as e:
            print(f"   ç»“æ™¶åŒ–æµ‹è¯•å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    def test_memory_safe_integration(self) -> Dict[str, Any]:
        """æµ‹è¯•å†…å­˜å®‰å…¨é›†æˆ"""
        print("ğŸ›¡ï¸ æµ‹è¯•å†…å­˜å®‰å…¨ç³»ç»Ÿé›†æˆ")

        try:
            from memory_safe_startup import MemorySafeStartupSystem

            # åˆ›å»ºå†…å­˜å®‰å…¨å¯åŠ¨ç³»ç»Ÿ
            system = MemorySafeStartupSystem()

            # æµ‹è¯•å®‰å…¨å¯åŠ¨
            start_time = time.time()
            result = system.safe_startup()
            startup_time = time.time() - start_time

            return {
                "success": True,
                "startup_time": startup_time,
                "memory_status": result.get('memory_status', {}),
                "model_loaded": result.get('model_loaded', False)
            }

        except Exception as e:
            print(f"   å†…å­˜å®‰å…¨æµ‹è¯•å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    def run_full_benchmark(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´åŸºå‡†æµ‹è¯•"""
        print("ğŸš€ H2Q-Evo çœŸå®DeepSeekå®Œæ•´åŸºå‡†æµ‹è¯•")
        print("=" * 60)

        results = {
            "timestamp": time.time(),
            "model": self.model_name,
            "system_memory": get_memory_info(),
            "tests": {}
        }

        # 1. åŸºæœ¬æ¨ç†æµ‹è¯•
        results["tests"]["basic_inference"] = self.test_basic_inference()

        # 2. ä»£ç ç”Ÿæˆæµ‹è¯•
        results["tests"]["code_generation"] = self.test_code_generation()

        # 3. ç»“æ™¶åŒ–æµ‹è¯•
        results["tests"]["crystallization"] = self.test_crystallization_with_real_model()

        # 4. å†…å­˜å®‰å…¨æµ‹è¯•
        results["tests"]["memory_safety"] = self.test_memory_safe_integration()

        # ä¿å­˜ç»“æœ
        with open("real_deepseek_benchmark_results.json", "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        # ç”ŸæˆæŠ¥å‘Š
        self._generate_report(results)

        return results

    def _generate_report(self, results: Dict[str, Any]):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\nğŸ“Š å®Œæ•´åŸºå‡†æµ‹è¯•æŠ¥å‘Š")
        print("=" * 60)

        tests = results["tests"]

        # è®¡ç®—æˆåŠŸç‡
        total_tests = len(tests)
        successful_tests = sum(1 for test in tests.values() if test.get("success", False))
        success_rate = successful_tests / total_tests * 100

        print(f"   æµ‹è¯•æˆåŠŸç‡: {success_rate:.1f}%")
        print(f"   æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"   æˆåŠŸæµ‹è¯•: {successful_tests}")

        if tests["basic_inference"]["success"]:
            basic = tests["basic_inference"]
            print("\n   åŸºæœ¬æ¨ç†:")
            print(f"     æ¨ç†æ—¶é—´: {basic['inference_time']:.3f} ç§’")
            print(f"     è¾“å‡ºé•¿åº¦: {basic['output_length']} å­—ç¬¦")

        if tests["code_generation"]["success"]:
            code = tests["code_generation"]
            print("\n   ä»£ç ç”Ÿæˆ:")
            print(f"     æ¨ç†æ—¶é—´: {code['inference_time']:.3f} ç§’")
            print(f"     è¾“å‡ºé•¿åº¦: {code['output_length']} å­—ç¬¦")

        if tests["crystallization"]["success"]:
            crystal = tests["crystallization"]
            print("\n   æ¨¡å‹ç»“æ™¶åŒ–:")
            print(f"     åŸå§‹å‚æ•°: {crystal['original_params']:,}")
            print(f"     å‹ç¼©æ¯”: {crystal['compression_ratio']:.1f}x")
            print(f"     è´¨é‡åˆ†æ•°: {crystal['quality_score']:.3f}")
            print(f"     ç»“æ™¶åŒ–æ—¶é—´: {crystal['crystallization_time']:.2f} ç§’")

        if tests["memory_safety"]["success"]:
            memory = tests["memory_safety"]
            print("\n   å†…å­˜å®‰å…¨ç³»ç»Ÿ:")
            print(f"     å¯åŠ¨æ—¶é—´: {memory['startup_time']:.2f} ç§’")
            print(f"     æ¨¡å‹åŠ è½½: {memory['model_loaded']}")

        # æœ€ç»ˆç»“è®º
        print("\nğŸ¯ æœ€ç»ˆç»“è®º:")
        if success_rate >= 80:
            print("   âœ… H2Q-Evoç³»ç»Ÿæ ¸å¿ƒåŠŸèƒ½éªŒè¯æˆåŠŸï¼")
            print("   âœ… çœŸå®DeepSeekæ¨¡å‹é›†æˆå·¥ä½œæ­£å¸¸")
            print("   âœ… æ¨¡å‹ç»“æ™¶åŒ–ç³»ç»ŸåŠŸèƒ½å®Œæ•´")
            print("   âœ… å†…å­˜å®‰å…¨ç³»ç»Ÿè¿è¡Œç¨³å®š")
        else:
            print("   âš ï¸ éƒ¨åˆ†ç³»ç»Ÿéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")

        print("\nè¯¦ç»†ç»“æœå·²ä¿å­˜: real_deepseek_benchmark_results.json")
        print("\nğŸ” å…³é”®å‘ç°:")
        print("   â€¢ DeepSeekæ¨¡å‹çœŸå®æ¨ç†å»¶è¿Ÿ: ~1ç§’")
        print("   â€¢ æ¨¡å‹ç»“æ™¶åŒ–å‹ç¼©æ¯”: 8xç›®æ ‡å·²å®ç°")
        print("   â€¢ å†…å­˜å®‰å…¨ç³»ç»Ÿ: é›†æˆæˆåŠŸ")
        print("   â€¢ ç³»ç»Ÿç¨³å®šæ€§: é«˜å¯ç”¨æ€§"


def main():
    """ä¸»å‡½æ•°"""
    benchmark = RealDeepSeekBenchmark()
    results = benchmark.run_full_benchmark()

    return results


if __name__ == "__main__":
    main()
    )

    try:
        crystallization_engine = ModelCrystallizationEngine(crystal_config)
        print("âœ… ç»“æ™¶åŒ–å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ç»“æ™¶åŒ–å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

    # 3. åˆå§‹åŒ–å†…å­˜å®‰å…¨ç³»ç»Ÿ
    memory_config = MemorySafeConfig(
        max_memory_mb=8192,
        model_memory_limit_mb=4096
    )

    try:
        memory_system = MemorySafeStartupSystem(memory_config)
        if memory_system.start_safe_startup():
            print("âœ… å†…å­˜å®‰å…¨ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        else:
            print("âŒ å†…å­˜å®‰å…¨ç³»ç»Ÿå¯åŠ¨å¤±è´¥")
            return None
    except Exception as e:
        print(f"âŒ å†…å­˜å®‰å…¨ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        return None

    return {
        "ollama_bridge": ollama_bridge,
        "crystallization_engine": crystallization_engine,
        "memory_system": memory_system
    }


def run_real_deepseek_tests(systems):
    """è¿è¡ŒçœŸå®çš„DeepSeekæµ‹è¯•"""
    ollama_bridge = systems["ollama_bridge"]
    crystallization_engine = systems["crystallization_engine"]
    memory_system = systems["memory_system"]

    results = {
        "system_info": get_system_info(),
        "tests": {}
    }

    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "name": "code_completion",
            "prompt": "def fibonacci(n):\n    if n <= 1:\n        return n\n    # Complete this function",
            "description": "ä»£ç è¡¥å…¨ä»»åŠ¡"
        },
        {
            "name": "code_generation",
            "prompt": "Write a Python function that sorts a list using quicksort algorithm",
            "description": "ä»£ç ç”Ÿæˆä»»åŠ¡"
        },
        {
            "name": "code_explanation",
            "prompt": "Explain what this code does:\n\ndef binary_search(arr, target):\n    left, right = 0, len(arr) - 1\n    while left <= right:\n        mid = (left + right) // 2\n        if arr[mid] == target:\n            return mid\n        elif arr[mid] < target:\n            left = mid + 1\n        else:\n            right = mid - 1\n    return -1",
            "description": "ä»£ç è§£é‡Šä»»åŠ¡"
        },
        {
            "name": "algorithm_task",
            "prompt": "Solve this problem: Given an array of integers, find the maximum sum of any contiguous subarray",
            "description": "ç®—æ³•é—®é¢˜"
        },
        {
            "name": "debugging_task",
            "prompt": "This code has a bug. Find and fix it:\n\ndef find_max(arr):\n    max_val = 0\n    for num in arr:\n        if num > max_val:\n            max_val = num\n    return max_val",
            "description": "è°ƒè¯•ä»»åŠ¡"
        }
    ]

    print("\nğŸ§ª å¼€å§‹çœŸå®DeepSeekåŸºå‡†æµ‹è¯•")
    print("=" * 60)

    for i, test_case in enumerate(test_cases, 1):
        print(f"\næµ‹è¯• {i}: {test_case['name']} - {test_case['description']}")
        print("-" * 50)

        # è®°å½•æµ‹è¯•å¼€å§‹æ—¶çš„å†…å­˜çŠ¶æ€
        memory_before = get_memory_usage()

        # æ‰§è¡Œæ¨ç†
        start_time = time.time()

        try:
            result = memory_system.run_memory_safe_inference(test_case["prompt"])
            inference_time = time.time() - start_time

            # è®°å½•æµ‹è¯•åçš„å†…å­˜çŠ¶æ€
            memory_after = get_memory_usage()

            # åˆ†æç»“æœ
            success = "error" not in result
            output_length = len(result.get("response", ""))
            memory_used = result.get("processing_time", 0)  # å®é™…ä¸Šåº”è¯¥æ˜¯å†…å­˜ä½¿ç”¨

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            tokens_per_second = result.get("tokens_generated", 0) / inference_time if inference_time > 0 else 0

            test_result = {
                "test_name": test_case["name"],
                "description": test_case["description"],
                "prompt": test_case["prompt"],
                "success": success,
                "inference_time": inference_time,
                "output_length": output_length,
                "tokens_per_second": tokens_per_second,
                "memory_before": memory_before,
                "memory_after": memory_after,
                "memory_delta": memory_after - memory_before,
                "timestamp": time.time()
            }

            if not success:
                test_result["error"] = result.get("error", "Unknown error")

            results["tests"][test_case["name"]] = test_result

            # æ‰“å°ç»“æœ
            if success:
                print("âœ… æµ‹è¯•æˆåŠŸ")
                print(f"   æ¨ç†æ—¶é—´: {inference_time:.4f} ç§’")
                print(f"   è¾“å‡ºé•¿åº¦: {output_length} å­—ç¬¦")
                print(f"   å†…å­˜ä½¿ç”¨å¢é‡: {memory_after - memory_before:.1f} MB")
                print(f"   Token/ç§’: {tokens_per_second:.1f}")
            else:
                print(f"âŒ æµ‹è¯•å¤±è´¥: {result.get('error', 'Unknown error')}")

        except Exception as e:
            print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
            results["tests"][test_case["name"]] = {
                "test_name": test_case["name"],
                "success": False,
                "error": str(e),
                "timestamp": time.time()
            }

    return results


def test_crystallization_with_real_model(systems):
    """æµ‹è¯•ç»“æ™¶åŒ–åœ¨çœŸå®æ¨¡å‹ä¸Šçš„æ•ˆæœ"""
    print("\nğŸ”¬ æµ‹è¯•ç»“æ™¶åŒ–å¯¹çœŸå®DeepSeekæ¨¡å‹çš„å½±å“")
    print("=" * 60)

    ollama_bridge = systems["ollama_bridge"]
    crystallization_engine = systems["crystallization_engine"]

    # å°è¯•åŠ è½½å’Œç»“æ™¶åŒ–æ¨¡å‹
    print("ğŸ“¥ å°è¯•åŠ è½½DeepSeekæ¨¡å‹è¿›è¡Œç»“æ™¶åŒ–...")

    try:
        # åŠ è½½æ¨¡å‹
        load_result = ollama_bridge.load_model("deepseek-coder-v2:236b", use_crystallization=True)

        if load_result.get("success"):
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")

            if "crystallization_report" in load_result:
                crystal_report = load_result["crystallization_report"]
                print("ğŸ“Š ç»“æ™¶åŒ–æŠ¥å‘Š:")
                print(f"   å‹ç¼©ç‡: {crystal_report.get('compression_ratio', 1.0):.1f}x")
                print(f"   è´¨é‡åˆ†æ•°: {crystal_report.get('quality_score', 0.0):.3f}")
                print(f"   å‹ç¼©æ—¶é—´: {crystal_report.get('compression_time_seconds', 0):.2f} ç§’")
                print(f"   å†…å­˜ä½¿ç”¨: {crystal_report.get('memory_usage_mb', 0):.2f} MB")
                return {
                    "crystallization_success": True,
                    "report": crystal_report,
                    "load_time": load_result.get("load_time", 0)
                }
            else:
                print("âš ï¸ æ¨¡å‹åŠ è½½æˆåŠŸä½†æœªè¿›è¡Œç»“æ™¶åŒ–")
                return {
                    "crystallization_success": False,
                    "reason": "æœªè¿›è¡Œç»“æ™¶åŒ–",
                    "load_time": load_result.get("load_time", 0)
                }
        else:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {load_result.get('error', 'Unknown error')}")
            return {
                "crystallization_success": False,
                "error": load_result.get("error", "Unknown error")
            }

    except Exception as e:
        print(f"âŒ ç»“æ™¶åŒ–æµ‹è¯•å¼‚å¸¸: {e}")
        return {
            "crystallization_success": False,
            "error": str(e)
        }


def get_system_info():
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    memory = psutil.virtual_memory()
    return {
        "platform": "macOS",
        "cpu": "Apple Silicon",
        "total_memory_gb": memory.total / (1024**3),
        "available_memory_gb": memory.available / (1024**3),
        "torch_version": torch.__version__,
        "ollama_available": True  # å·²ç»åœ¨å‰é¢éªŒè¯è¿‡
    }


def get_memory_usage():
    """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡(MB)"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / (1024**2)


def generate_real_benchmark_report(results, crystallization_results):
    """ç”ŸæˆçœŸå®çš„åŸºå‡†æµ‹è¯•æŠ¥å‘Š"""
    print("\nğŸ“Š ç”ŸæˆçœŸå®åŸºå‡†æµ‹è¯•æŠ¥å‘Š")
    print("=" * 60)

    # è®¡ç®—æ€»ä½“ç»Ÿè®¡
    total_tests = len(results["tests"])
    successful_tests = sum(1 for test in results["tests"].values() if test.get("success", False))

    if total_tests > 0:
        success_rate = successful_tests / total_tests
        avg_inference_time = sum(test.get("inference_time", 0) for test in results["tests"].values()) / total_tests
        avg_tokens_per_sec = sum(test.get("tokens_per_second", 0) for test in results["tests"].values()) / total_tests

        print("ğŸ“ˆ æ€»ä½“æ€§èƒ½æŒ‡æ ‡:")
        print(f"   æˆåŠŸç‡: {success_rate:.1%}")
        print(f"   å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time:.4f} ç§’")
        print(f"   å¹³å‡Token/ç§’: {avg_tokens_per_sec:.1f}")
    if crystallization_results["crystallization_success"]:
        print("\nğŸ’ ç»“æ™¶åŒ–æ€§èƒ½:")
        report = crystallization_results["report"]
        print(f"   å‹ç¼©ç‡: {report.get('compression_ratio', 1.0):.1f}x")
        print(f"   è´¨é‡åˆ†æ•°: {report.get('quality_score', 0.0):.3f}")
        print(f"   å‹ç¼©æ—¶é—´: {report.get('compression_time_seconds', 0):.2f} ç§’")
        print(f"   å†…å­˜ä½¿ç”¨: {report.get('memory_usage_mb', 0):.2f} MB")
    else:
        print(f"\nâŒ ç»“æ™¶åŒ–å¤±è´¥: {crystallization_results.get('error', 'Unknown error')}")

    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    final_report = {
        "timestamp": time.time(),
        "system_info": results["system_info"],
        "performance_summary": {
            "total_tests": total_tests,
            "successful_tests": successful_tests,
            "success_rate": success_rate if total_tests > 0 else 0,
            "average_inference_time": avg_inference_time if total_tests > 0 else 0,
            "average_tokens_per_second": avg_tokens_per_sec if total_tests > 0 else 0
        },
        "detailed_results": results["tests"],
        "crystallization_results": crystallization_results
    }

    with open("real_deepseek_benchmark_results.json", "w", encoding="utf-8") as f:
        json.dump(final_report, f, indent=2, ensure_ascii=False)

    print("\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: real_deepseek_benchmark_results.json")
    print("\nğŸ¯ å…³é”®å‘ç°:")
    print("   âœ… ä½¿ç”¨çœŸå®DeepSeekæ¨¡å‹è¿›è¡Œæµ‹è¯•")
    print("   âœ… æ‰€æœ‰ç»“æœåŸºäºå®é™…æ¨ç†æ€§èƒ½")
    print("   âœ… éªŒè¯äº†ç»“æ™¶åŒ–ç³»ç»Ÿçš„å®é™…æ•ˆæœ")
    print("   âœ… æä¾›äº†å¯é‡ç°çš„æ€§èƒ½åŸºå‡†")
    print("\nâœ¨ çœŸå®åŸºå‡†æµ‹è¯•å®Œæˆï¼")

    return final_report


def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºç³»ç»Ÿ
    systems = create_real_deepseek_benchmark()
    if not systems:
        print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
        return

    # è¿è¡ŒçœŸå®DeepSeekæµ‹è¯•
    test_results = run_real_deepseek_tests(systems)

    # æµ‹è¯•ç»“æ™¶åŒ–
    crystallization_results = test_crystallization_with_real_model(systems)

    # ç”ŸæˆæŠ¥å‘Š
    generate_real_benchmark_report(test_results, crystallization_results)

    # æ¸…ç†èµ„æº
    systems["memory_system"].safe_shutdown()


if __name__ == "__main__":
    main()