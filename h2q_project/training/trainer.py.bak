import torch
import torch.nn.functional as F
from h2q_project.quaternion import Quaternion

class Trainer:
    def __init__(self, model, optimizer, device):
        self.model = model
        self.optimizer = optimizer
        self.device = device

    def train_step(self, data, labels):
        self.model.train()
        self.optimizer.zero_grad()
        
        # Move data and labels to the device
        data = data.to(self.device)
        labels = labels.to(self.device)

        # Forward pass
        outputs = self.model(data)
        
        # Calculate loss
        loss = F.cross_entropy(outputs, labels)
        
        # Backward pass and optimization
        loss.backward()
        self.optimizer.step()

        return loss.item()

    def evaluate(self, data_loader):
        self.model.eval()
        total_loss = 0
        with torch.no_grad():
            for data, labels in data_loader:
                data = data.to(self.device)
                labels = labels.to(self.device)
                outputs = self.model(data)
                loss = F.cross_entropy(outputs, labels)
                total_loss += loss.item()
        return total_loss / len(data_loader)

    def train(self, train_loader, val_loader, epochs):
        for epoch in range(epochs):
            train_loss = 0.0
            for i, (data, labels) in enumerate(train_loader):
                loss = self.train_step(data, labels)
                train_loss += loss

                # Simple Self-Reflection (Quaternion-based - Minimal Example)
                # Note: This is a highly simplified example.  A real implementation
                # would require more sophisticated analysis and domain-specific knowledge.
                # This example merely shows how to incorporate quaternion concepts.
                gradient_norm = 0.0
                for param in self.model.parameters():
                    if param.grad is not None:
                        gradient_norm += torch.norm(param.grad).item()

                loss_quaternion = Quaternion(loss, 0, 0, 0) # loss as a real quaternion
                gradient_quaternion = Quaternion(gradient_norm, 0, 0, 0) # gradient norm as a quaternion

                # Crude 'reflection' by comparing loss and gradient.
                if loss_quaternion.abs() > 1.0 and gradient_quaternion.abs() < 0.1:
                    print(f"Epoch {epoch}, Batch {i}: Potential issue - High Loss ({loss:.4f}), Low Gradient ({gradient_norm:.4f}). Consider early stopping or adjusting learning rate.")

            avg_train_loss = train_loss / len(train_loader)
            val_loss = self.evaluate(val_loader)
            print(f'Epoch {epoch}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}')