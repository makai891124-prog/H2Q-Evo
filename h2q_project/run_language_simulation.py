# run_language_simulation.py

import torch
import os
import matplotlib.pyplot as plt
from transformers import GPT2Tokenizer
from h2q.system import AutonomousSystem

# --- [ä¸­å›½åŒºåŠ é€Ÿé…ç½®] ---
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

def run_simulation():
    print("ğŸš€ [H2Q] å¯åŠ¨è¯­è¨€è®¤çŸ¥æ¨¡æ‹Ÿå®éªŒ...")

    # 1. å‡†å¤‡â€œæ„Ÿå®˜â€ (Tokenizer)
    print("ğŸ“– æ­£åœ¨åŠ è½½ GPT-2 åˆ†è¯å™¨...")
    tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
    
    # 2. åˆå§‹åŒ–ç³»ç»Ÿ (256ç»´å°„å½±ç©ºé—´)
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ç”¨ 256 ç»´ï¼Œå› ä¸ºæˆ‘ä»¬çš„è®°å¿†æ™¶ä½“æ˜¯ 256 ç»´çš„
    system = AutonomousSystem(context_dim=256, action_dim=256)
    
    # 3. æ³¨å…¥çŸ¥è¯† (åŠ è½½æ™¶ä½“)
    crystal_path = "h2q_memory.pt"
    if os.path.exists(crystal_path):
        system.load_knowledge(crystal_path)
    else:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°è®°å¿†æ™¶ä½“ï¼Œè¯·å…ˆè¿è¡Œ tools/prism_converter.py")
        return

    # 4. å‡†å¤‡æµ‹è¯•æ–‡æœ¬
    # è¿™æ˜¯ä¸€æ®µåŒ…å«ç®€å•è¯æ±‡å’Œå¤æ‚æ¦‚å¿µçš„æ–‡æœ¬
    text = "The cat sat on the mat. However, the quantum entanglement implies a spooky action at a distance."
    print(f"\nğŸ“„ è¾“å…¥æ–‡æœ¬: \"{text}\"")
    
    # å°†æ–‡æœ¬è½¬æ¢ä¸ºç´¢å¼• (Tokens)
    inputs = tokenizer(text, return_tensors="pt")["input_ids"] # [1, Seq_Len]
    tokens = [tokenizer.decode([t]) for t in inputs[0]] # ç”¨äºåç»­ç»˜å›¾æ ‡ç­¾
    
    print(f"ğŸ”¢ Token åºåˆ—é•¿åº¦: {inputs.shape[1]}")

    # 5. è®¤çŸ¥å¾ªç¯ (Cognitive Loop)
    eta_history = []
    
    print("\nğŸ§  å¼€å§‹é€è¯é˜…è¯»ä¸è®¤çŸ¥...")
    # æˆ‘ä»¬æ¨¡æ‹Ÿä¸€ä¸ªè‡ªå›å½’è¿‡ç¨‹ï¼šç³»ç»Ÿçœ‹åˆ°å‰ N ä¸ªè¯ï¼Œæ€è€ƒç¬¬ N+1 ä¸ªè¯
    # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ç›´æ¥æŠŠå½“å‰è¯ä½œä¸ºâ€œè¡ŒåŠ¨â€ï¼Œè®¡ç®—å®ƒå¸¦æ¥çš„è®¤çŸ¥åè½¬
    
    # åˆå§‹åŒ–ä¸€ä¸ªéšæœºçš„è®¤çŸ¥ä¸Šä¸‹æ–‡ (æ¨¡æ‹Ÿâ€œå¤§è„‘ä¸€ç‰‡ç©ºç™½â€)
    current_context = torch.randn(1, 256)
    current_context = torch.nn.functional.normalize(current_context, p=2, dim=-1)

    for i in range(inputs.shape[1]):
        # è·å–å½“å‰çœ‹åˆ°çš„è¯ (ä½œä¸ºå€™é€‰è¡ŒåŠ¨)
        # åœ¨çœŸå®ç”Ÿæˆä¸­ï¼Œè¿™é‡Œä¼šæœ‰å¤šä¸ªå€™é€‰ï¼Œç°åœ¨æˆ‘ä»¬å¼ºåˆ¶å®ƒâ€œé˜…è¯»â€è¿™ä¸ªè¯
        current_token_idx = inputs[:, i:i+1] # [1, 1]
        
        # æ‰§è¡Œä¸€æ­¥ (è¿™é‡Œæˆ‘ä»¬æ‰‹åŠ¨è°ƒç”¨ DDE çš„ forward æ¥è·å–å…ƒæ•°æ®)
        # æˆ‘ä»¬ä¼ å…¥ current_token_idx ä½œä¸º candidate_actions
        # DDE ä¼šå»æ™¶ä½“é‡ŒæŸ¥è¿™ä¸ªè¯å¯¹åº”çš„ 256ç»´ å‡ ä½•å‘é‡
        with torch.no_grad():
            _, metadata = system.dde(current_context, current_token_idx)
        
        # è·å–æœ¬æ¬¡çš„è°±ä½ç§» (è®¤çŸ¥åè½¬è§’)
        eta = metadata['chosen_eta'].item()
        eta_history.append(eta)
        
        # æ›´æ–°ä¸Šä¸‹æ–‡ï¼šç®€å•çš„ç§»åŠ¨å¹³å‡ï¼Œæ¨¡æ‹Ÿâ€œè®°å¿†æ®‹ç•™â€
        # æ–°ä¸Šä¸‹æ–‡ = æ—§ä¸Šä¸‹æ–‡ * 0.8 + æ–°è¯å‘é‡ * 0.2
        # (æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä» DDE å†…éƒ¨è·å–æ–°è¯å‘é‡ï¼Œä¸ºç®€åŒ–æ¼”ç¤ºï¼Œæˆ‘ä»¬ç•¥è¿‡è¿™ä¸€æ­¥çš„ç²¾ç¡®å®ç°ï¼Œ
        # ä»…è®°å½• eta çš„å˜åŒ–ï¼Œå› ä¸º eta æœ¬èº«åæ˜ äº†æ–°è¯ä¸æ—§çŠ¶æ€çš„å†²çªç¨‹åº¦)
        
        print(f"   Step {i:02d}: Token = '{tokens[i]:<10}' | Î· (åè½¬è§’) = {eta:.4f} rad")

    # 6. å¯è§†åŒ–ç»“æœ
    print("\nğŸ“Š æ­£åœ¨ç»˜åˆ¶è®¤çŸ¥è°±å›¾...")
    plt.figure(figsize=(12, 6))
    plt.plot(eta_history, marker='o', linestyle='-', color='#00ff00', label='Spectral Shift (Î·)')
    
    # è®¾ç½® X è½´æ ‡ç­¾ä¸ºå•è¯
    plt.xticks(range(len(tokens)), tokens, rotation=45, ha='right')
    plt.title(f"Cognitive Spectral Shift Analysis\nInput: {text}")
    plt.ylabel("Cognitive Deflection (Î·) [Radians]")
    plt.xlabel("Token Stream")
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    run_simulation()