"""
H2Q-Evo ç”Ÿäº§å°±ç»ªç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶ã€å¥åº·æ£€æŸ¥ã€é²æ£’æ€§åŒ…è£…å™¨ç­‰åŠŸèƒ½
"""

import torch
import torch.nn as nn
from pathlib import Path

def main():
    print("ğŸš€ H2Q-Evo ç”Ÿäº§å°±ç»ªç³»ç»Ÿæ¼”ç¤º")
    print("="*60)
    
    # ====================================================================
    # ç¬¬1æ­¥: å¯¼å…¥æ ¸å¿ƒç»„ä»¶
    # ====================================================================
    print("\nğŸ“¦ ç¬¬1æ­¥: å¯¼å…¥æ ¸å¿ƒç»„ä»¶...")
    
    from h2q.core.discrete_decision_engine import (
        DiscreteDecisionEngine,
        LatentConfig,
        get_canonical_dde
    )
    from h2q.core.algorithm_version_control import (
        get_version_control,
        AlgorithmStatus,
        verify_algorithm_compatibility
    )
    from h2q.core.production_validator import (
        ProductionValidator,
        run_production_validation
    )
    from h2q.core.robustness_wrapper import (
        RobustWrapper,
        RobustDiscreteDecisionEngine,
        SafetyGuard,
        robust_inference
    )
    
    print("âœ… æ‰€æœ‰æ ¸å¿ƒç»„ä»¶å·²å¯¼å…¥")
    
    # ====================================================================
    # ç¬¬2æ­¥: åˆå§‹åŒ–ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ
    # ====================================================================
    print("\nğŸ“ ç¬¬2æ­¥: åˆå§‹åŒ–ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ...")
    
    vc = get_version_control()
    
    # åˆ›å»ºé…ç½®
    config = LatentConfig(dim=256, n_choices=64, temperature=1.0)
    
    # åˆ›å»ºæ¨¡å‹
    base_model = get_canonical_dde(config=config)
    
    # æ³¨å†Œç®—æ³•ç‰ˆæœ¬
    try:
        version_info = vc.register_algorithm(
            name="DiscreteDecisionEngine",
            version="2.1.0",
            status=AlgorithmStatus.PRODUCTION,
            description="ç”Ÿäº§ç¯å¢ƒç¨³å®šç‰ˆæœ¬",
            module=base_model,
            config={'latent_dim': 256, 'n_choices': 64},
            author="H2Q-Evo Team"
        )
        print(f"âœ… å·²æ³¨å†Œç®—æ³•: {version_info.name} v{version_info.version}")
        print(f"   çŠ¶æ€: {version_info.status.value}")
        print(f"   ç­¾å: {version_info.signature}")
    except Exception as e:
        print(f"âš ï¸ ç®—æ³•å·²æ³¨å†Œæˆ–æ³¨å†Œå¤±è´¥: {e}")
    
    # éªŒè¯å…¼å®¹æ€§
    is_compatible = verify_algorithm_compatibility(
        "DiscreteDecisionEngine",
        "2.0.0"
    )
    print(f"âœ… ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥: {'é€šè¿‡' if is_compatible else 'å¤±è´¥'}")
    
    # ====================================================================
    # ç¬¬3æ­¥: åŒ…è£…æ¨¡å‹ä»¥å¢å¼ºé²æ£’æ€§
    # ====================================================================
    print("\nğŸ›¡ï¸ ç¬¬3æ­¥: åŒ…è£…æ¨¡å‹ä»¥å¢å¼ºé²æ£’æ€§...")
    
    robust_model = RobustDiscreteDecisionEngine(base_model)
    print("âœ… é²æ£’æ€§åŒ…è£…å™¨å·²åº”ç”¨")
    print("   - è‡ªåŠ¨è¾“å…¥éªŒè¯")
    print("   - NaN/Inf æ£€æµ‹ä¸ä¿®å¤")
    print("   - GPU OOM è‡ªåŠ¨é™çº§åˆ° CPU")
    print("   - å¼‚å¸¸å€¼è£å‰ª")
    
    # ====================================================================
    # ç¬¬4æ­¥: è¿è¡Œç”Ÿäº§ç¯å¢ƒéªŒè¯
    # ====================================================================
    print("\nğŸ¥ ç¬¬4æ­¥: è¿è¡Œç”Ÿäº§ç¯å¢ƒå¥åº·æ£€æŸ¥...")
    
    validator = ProductionValidator()
    health_report = validator.run_full_validation()
    
    overall_status = health_report['overall_status']
    print(f"\næ•´ä½“å¥åº·çŠ¶æ€: {overall_status.upper()}")
    
    if overall_status == 'healthy':
        print("âœ… ç³»ç»Ÿå¥åº·ï¼Œå¯ä»¥ç»§ç»­")
    else:
        print("âš ï¸ ç³»ç»ŸçŠ¶æ€å¼‚å¸¸ï¼Œå»ºè®®æ£€æŸ¥")
    
    # ====================================================================
    # ç¬¬5æ­¥: æ¼”ç¤ºæ¨ç†åŠŸèƒ½
    # ====================================================================
    print("\nğŸ§  ç¬¬5æ­¥: æ¼”ç¤ºæ¨ç†åŠŸèƒ½...")
    
    # æ­£å¸¸è¾“å…¥
    print("\næ¡ˆä¾‹ 1: æ­£å¸¸è¾“å…¥")
    normal_input = torch.randn(4, 256)
    
    with torch.no_grad():
        output = robust_model(normal_input)
    
    print(f"âœ… è¾“å…¥å½¢çŠ¶: {normal_input.shape}")
    print(f"âœ… è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"âœ… è¾“å‡ºèŒƒå›´: [{output.min():.4f}, {output.max():.4f}]")
    
    # å¼‚å¸¸è¾“å…¥ï¼ˆåŒ…å« NaN å’Œ Infï¼‰
    print("\næ¡ˆä¾‹ 2: å¼‚å¸¸è¾“å…¥ï¼ˆåŒ…å« NaN å’Œ Infï¼‰")
    bad_input = torch.randn(4, 256)
    bad_input[0, 0] = float('nan')
    bad_input[1, 0] = float('inf')
    bad_input[2, 0] = -float('inf')
    
    print(f"âš ï¸ è¾“å…¥åŒ…å«å¼‚å¸¸å€¼:")
    print(f"   - NaN æ•°é‡: {torch.isnan(bad_input).sum()}")
    print(f"   - Inf æ•°é‡: {torch.isinf(bad_input).sum()}")
    
    try:
        with torch.no_grad():
            cleaned_output = robust_model(bad_input)
        print(f"âœ… é²æ£’åŒ…è£…å™¨è‡ªåŠ¨å¤„ç†äº†å¼‚å¸¸å€¼")
        print(f"âœ… è¾“å‡ºå½¢çŠ¶: {cleaned_output.shape}")
        print(f"âœ… è¾“å‡ºä¸­ NaN æ•°é‡: {torch.isnan(cleaned_output).sum()}")
        print(f"âœ… è¾“å‡ºä¸­ Inf æ•°é‡: {torch.isinf(cleaned_output).sum()}")
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
    
    # ====================================================================
    # ç¬¬6æ­¥: æ¼”ç¤ºå®‰å…¨æ•°å­¦æ“ä½œ
    # ====================================================================
    print("\nğŸ”’ ç¬¬6æ­¥: æ¼”ç¤ºå®‰å…¨æ•°å­¦æ“ä½œ...")
    
    a = torch.tensor([1.0, 2.0, 3.0])
    b = torch.tensor([2.0, 0.0, 4.0])  # åŒ…å«é›¶
    
    # ä¸å®‰å…¨çš„é™¤æ³•ä¼šå¯¼è‡´ Inf
    print("\nä¸å®‰å…¨é™¤æ³•:")
    unsafe_result = a / b
    print(f"   ç»“æœ: {unsafe_result}")
    print(f"   åŒ…å« Inf: {torch.isinf(unsafe_result).any()}")
    
    # å®‰å…¨é™¤æ³•é¿å…é™¤é›¶
    print("\nå®‰å…¨é™¤æ³•:")
    safe_result = SafetyGuard.safe_division(a, b, epsilon=1e-8)
    print(f"   ç»“æœ: {safe_result}")
    print(f"   åŒ…å« Inf: {torch.isinf(safe_result).any()}")
    
    # å®‰å…¨å¯¹æ•°
    x = torch.tensor([0.0, 1.0, 2.0])
    print("\nå®‰å…¨å¯¹æ•°:")
    safe_log = SafetyGuard.safe_log(x)
    print(f"   è¾“å…¥: {x}")
    print(f"   è¾“å‡º: {safe_log}")
    
    # ====================================================================
    # ç¬¬7æ­¥: æ€§èƒ½åŸºå‡†æµ‹è¯•
    # ====================================================================
    print("\nâš¡ ç¬¬7æ­¥: æ€§èƒ½åŸºå‡†æµ‹è¯•...")
    
    import time
    
    test_input = torch.randn(1, 256)
    times = []
    
    # é¢„çƒ­
    for _ in range(10):
        with torch.no_grad():
            _ = robust_model(test_input)
    
    # åŸºå‡†æµ‹è¯•
    num_iterations = 100
    for _ in range(num_iterations):
        start = time.time()
        with torch.no_grad():
            _ = robust_model(test_input)
        times.append((time.time() - start) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
    
    import statistics
    avg_time = statistics.mean(times)
    p50_time = statistics.median(times)
    p95_time = sorted(times)[int(0.95 * len(times))]
    p99_time = sorted(times)[int(0.99 * len(times))]
    
    print(f"âœ… åŸºå‡†æµ‹è¯•å®Œæˆ ({num_iterations} æ¬¡è¿­ä»£)")
    print(f"   å¹³å‡å»¶è¿Ÿ: {avg_time:.2f}ms")
    print(f"   P50 å»¶è¿Ÿ: {p50_time:.2f}ms")
    print(f"   P95 å»¶è¿Ÿ: {p95_time:.2f}ms")
    print(f"   P99 å»¶è¿Ÿ: {p99_time:.2f}ms")
    print(f"   ååé‡: ~{1000/avg_time:.0f} QPS")
    
    # ====================================================================
    # ç¬¬8æ­¥: ä¿å­˜æŠ¥å‘Šå’Œæ—¥å¿—
    # ====================================================================
    print("\nğŸ“Š ç¬¬8æ­¥: ç”Ÿæˆå’Œä¿å­˜æŠ¥å‘Š...")
    
    reports_dir = Path("reports")
    reports_dir.mkdir(exist_ok=True)
    
    # ä¿å­˜å¥åº·æ£€æŸ¥æŠ¥å‘Š
    import json
    health_report_path = reports_dir / "health_check_demo.json"
    with open(health_report_path, 'w') as f:
        json.dump(health_report, f, indent=2)
    print(f"âœ… å¥åº·æ£€æŸ¥æŠ¥å‘Šå·²ä¿å­˜: {health_report_path}")
    
    # ä¿å­˜æ€§èƒ½æŠ¥å‘Š
    perf_report = {
        'timestamp': '2026-01-20',
        'model': 'DiscreteDecisionEngine v2.1.0',
        'metrics': {
            'avg_latency_ms': avg_time,
            'p50_latency_ms': p50_time,
            'p95_latency_ms': p95_time,
            'p99_latency_ms': p99_time,
            'throughput_qps': 1000/avg_time
        },
        'environment': {
            'device': str(test_input.device),
            'dtype': str(test_input.dtype)
        }
    }
    
    perf_report_path = reports_dir / "performance_demo.json"
    with open(perf_report_path, 'w') as f:
        json.dump(perf_report, f, indent=2)
    print(f"âœ… æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: {perf_report_path}")
    
    # ====================================================================
    # æ€»ç»“
    # ====================================================================
    print("\n" + "="*60)
    print("âœ… æ‰€æœ‰æ¼”ç¤ºæ­¥éª¤å®Œæˆ!")
    print("="*60)
    
    print("\nğŸ“‹ æ€»ç»“:")
    print(f"1. âœ… ç®—æ³•ç‰ˆæœ¬æ§åˆ¶: DiscreteDecisionEngine v2.1.0 å·²æ³¨å†Œ")
    print(f"2. âœ… å¥åº·æ£€æŸ¥: {overall_status.upper()}")
    print(f"3. âœ… é²æ£’æ€§å¢å¼º: è‡ªåŠ¨å¤„ç†å¼‚å¸¸å€¼")
    print(f"4. âœ… æ€§èƒ½ä¼˜ç§€: å¹³å‡å»¶è¿Ÿ {avg_time:.2f}ms")
    print(f"5. âœ… æŠ¥å‘Šç”Ÿæˆ: {reports_dir}")
    
    print("\nğŸ¯ ç”Ÿäº§ç¯å¢ƒå»ºè®®:")
    print("- å®šæœŸè¿è¡Œå¥åº·æ£€æŸ¥ (æ¯5åˆ†é’Ÿ)")
    print("- ç›‘æ§å…³é”®æŒ‡æ ‡ (å»¶è¿Ÿã€å†…å­˜ã€é”™è¯¯ç‡)")
    print("- å¯ç”¨ç†”æ–­å™¨ä¿æŠ¤å…³é”®æœåŠ¡")
    print("- ä¿æŒç®—æ³•ç‰ˆæœ¬è®°å½•")
    print("- å»ºç«‹å‘Šè­¦å’Œå›æ»šæœºåˆ¶")
    
    print("\nğŸš€ ç³»ç»Ÿå·²å‡†å¤‡å¥½ç”¨äºç”Ÿäº§ç¯å¢ƒ!")

if __name__ == "__main__":
    main()
