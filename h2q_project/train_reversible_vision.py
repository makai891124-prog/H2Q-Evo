# train_reversible_vision.py

import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
import psutil
import os

# å¯¼å…¥å¯é€†å†…æ ¸å’Œè§†è§‰æ•°æ®åŠ è½½å™¨
from h2q.reversible_kernel import H2Q_Reversible_Kernel
from tools.vision_loader import get_vision_dataloader

# --- é…ç½® ---
DEVICE = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
BATCH_SIZE = 128 # [å‡çº§] å°è¯•æ›´å¤§çš„ Batch Sizeï¼Œæµ‹è¯•å†…å­˜ä¼˜åŒ–æ•ˆæœ
SEQ_LEN = 3072  # CIFAR-10 (32*32*3)
LR = 5e-4
STEPS = 3000
VOCAB_SIZE = 257

# ä¿å­˜è·¯å¾„
VISION_KERNEL_PATH = "h2q_vision_reversible_kernel.pth"

def get_memory_usage():
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024 # MB

def train_reversible():
    print(f"ğŸš€ [H2Q-Reversible] å¯åŠ¨å†…å­˜ä¼˜åŒ–è§†è§‰è®­ç»ƒ... è®¾å¤‡: {DEVICE}")
    
    # 1. åˆå§‹åŒ–å¯é€†æ¨¡å‹
    model = H2Q_Reversible_Kernel(max_dim=256, vocab_size=VOCAB_SIZE, depth=6).to(DEVICE)
    
    # 2. æ•°æ®
    loader = get_vision_dataloader(split="train", batch_size=BATCH_SIZE)
    
    # 3. ä¼˜åŒ–å™¨
    optimizer = optim.AdamW(model.parameters(), lr=LR)
    loss_fn = nn.CrossEntropyLoss()
    
    model.train()
    progress_bar = tqdm(range(STEPS), desc="Reversible Vision Training")
    data_iter = iter(loader)
    
    initial_mem = get_memory_usage()
    print(f"   åˆå§‹å†…å­˜: {initial_mem:.2f} MB")
    
    for step in progress_bar:
        try:
            batch = next(data_iter).to(DEVICE)
        except StopIteration:
            data_iter = iter(loader)
            batch = next(data_iter).to(DEVICE)
            
        # å‰å‘ä¼ æ’­ (å†…éƒ¨ä½¿ç”¨ checkpoint)
        logits, stab = model(batch)
        
        # æŸå¤±
        loss = loss_fn(logits.reshape(-1, VOCAB_SIZE), batch.reshape(-1))
        total_loss = loss + 0.1 * stab
        
        # åå‘ä¼ æ’­ (PyTorch ä¼šè‡ªåŠ¨é‡è®¡ç®—)
        optimizer.zero_grad()
        total_loss.backward()
        optimizer.step()
        
        # ç›‘æ§å†…å­˜
        if step % 100 == 0:
            mem_usage = get_memory_usage()
            progress_bar.set_postfix({
                "Loss": f"{loss.item():.4f}", 
                "Mem": f"{mem_usage:.2f} MB"
            })

    final_mem = get_memory_usage()
    print("âœ… è®­ç»ƒå®Œæˆã€‚")
    print(f"   æœ€ç»ˆå†…å­˜: {final_mem:.2f} MB")
    print(f"   å†…å­˜å¢é‡: {final_mem - initial_mem:.2f} MB (ç›¸æ¯”éå¯é€†ç‰ˆæœ¬åº”æ˜¾è‘—é™ä½)")
    
    # ä¿å­˜æƒé‡
    torch.save(model.state_dict(), VISION_KERNEL_PATH)
    print(f"ğŸ’¾ å¯é€†è§†è§‰æ ¸å·²ä¿å­˜: {VISION_KERNEL_PATH}")

if __name__ == "__main__":
    # å®‰è£… psutil
    try:
        import psutil
    except ImportError:
        print("è¯·å…ˆå®‰è£… psutil: pip install psutil")
    else:
        train_reversible()