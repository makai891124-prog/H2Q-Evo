# train_vision_core.py

import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
import os

from h2q.knot_kernel import H2Q_Knot_Kernel
from h2q.hierarchical_decoder import ConceptDecoder
from tools.vision_loader import get_vision_dataloader

# --- é…ç½® ---
DEVICE = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
BATCH_SIZE = 64 
SEQ_LEN = 3072 # CIFAR-10 (32*32*3)
LR = 5e-4
STEPS = 3000
VOCAB_SIZE = 257 # åƒç´ å€¼ 0-255

# ä¿å­˜è·¯å¾„
VISION_KERNEL_PATH = "h2q_vision_kernel.pth"
VISION_DECODER_PATH = "h2q_vision_decoder.pth"

def train_vision():
    print(f"ğŸš€ [H2Q-Vision] å¯åŠ¨ CIFAR-10 è§†è§‰æµå½¢è®­ç»ƒ... è®¾å¤‡: {DEVICE}")
    
    # 1. åˆå§‹åŒ–è§†è§‰ç³»ç»Ÿ
    # L0 æ‹¼å†™æ ¸ï¼šè´Ÿè´£ç†è§£åƒç´ é—´çš„æ‹“æ‰‘å…³ç³»
    kernel = H2Q_Knot_Kernel(max_dim=256, vocab_size=VOCAB_SIZE, depth=6).to(DEVICE)
    
    # Decoderï¼šè´Ÿè´£è¿˜åŸåƒç´ 
    # Stride=1: å…ˆåš 1:1 æ— æŸè¿˜åŸéªŒè¯
    decoder = ConceptDecoder(dim=256, vocab_size=VOCAB_SIZE, stride=1).to(DEVICE)
    
    # 2. æ•°æ®
    # é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½ CIFAR-10 (~160MB)
    loader = get_vision_dataloader(split="train", batch_size=BATCH_SIZE)
    
    # 3. ä¼˜åŒ–å™¨
    optimizer = optim.AdamW(list(kernel.parameters()) + list(decoder.parameters()), lr=LR)
    loss_fn = nn.CrossEntropyLoss()
    
    kernel.train()
    decoder.train()
    
    progress_bar = tqdm(range(STEPS), desc="Vision Topology Learning")
    data_iter = iter(loader)
    
    for step in progress_bar:
        try:
            batch = next(data_iter).to(DEVICE)
        except StopIteration:
            data_iter = iter(loader)
            batch = next(data_iter).to(DEVICE)
            
        # ç¼–ç 
        features, stab = kernel(batch, return_features=True)
        
        # è§£ç 
        logits = decoder(features)
        
        # æŸå¤±
        recon_loss = loss_fn(logits.reshape(-1, VOCAB_SIZE), batch.reshape(-1))
        total_loss = recon_loss + 0.01 * stab
        
        optimizer.zero_grad()
        total_loss.backward()
        optimizer.step()
        
        progress_bar.set_postfix({"Loss": f"{recon_loss.item():.4f}", "Stab": f"{stab.item():.4f}"})

    print("âœ… è§†è§‰æ ¸å¿ƒè®­ç»ƒå®Œæˆã€‚")
    torch.save(kernel.state_dict(), VISION_KERNEL_PATH)
    torch.save(decoder.state_dict(), VISION_DECODER_PATH)
    print(f"ğŸ’¾ æƒé‡å·²ä¿å­˜ã€‚")

if __name__ == "__main__":
    train_vision()