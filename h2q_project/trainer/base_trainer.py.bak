import torch
import torch.nn as nn
import os
from typing import Dict, Any, Optional

class BaseTrainer:
    """Base class for all trainers."""

    def __init__(self, model: nn.Module, optimizer: torch.optim.Optimizer, config: Dict[str, Any], device: torch.device):
        self.model = model
        self.optimizer = optimizer
        self.config = config
        self.device = device
        self.epochs = config.get('epochs', 10)
        self.save_dir = config.get('save_dir', 'checkpoints')
        os.makedirs(self.save_dir, exist_ok=True)

    def train_epoch(self, epoch: int, train_loader: torch.utils.data.DataLoader) -> float:
        """Training logic for an epoch.

        Args:
            epoch (int): Current epoch number.
            train_loader (torch.utils.data.DataLoader): Training data loader.

        Returns:
            float: Average training loss for the epoch.
        """
        raise NotImplementedError

    def validation_epoch(self, epoch: int, val_loader: torch.utils.data.DataLoader) -> float:
        """Validation logic for an epoch.

        Args:
            epoch (int): Current epoch number.
            val_loader (torch.utils.data.DataLoader): Validation data loader.

        Returns:
            float: Average validation loss for the epoch.
        """
        raise NotImplementedError

    def train(self, train_loader: torch.utils.data.DataLoader, val_loader: torch.utils.data.DataLoader) -> None:
        """Full training logic.

        Args:
            train_loader (torch.utils.data.DataLoader): Training data loader.
            val_loader (torch.utils.data.DataLoader): Validation data loader.
        """
        best_val_loss = float('inf')
        for epoch in range(1, self.epochs + 1):
            train_loss = self.train_epoch(epoch, train_loader)
            val_loss = self.validation_epoch(epoch, val_loader)

            print(f'Epoch: {epoch}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')

            if val_loss < best_val_loss:
                best_val_loss = val_loss
                self.save_checkpoint(epoch)

    def save_checkpoint(self, epoch: int) -> None:
        """Saves model checkpoint.

        Args:
            epoch (int): Current epoch number.
        """
        checkpoint_path = os.path.join(self.save_dir, f'checkpoint_epoch_{epoch}.pth')
        torch.save({
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
        }, checkpoint_path)
        print(f'Checkpoint saved to {checkpoint_path}')

    def load_checkpoint(self, checkpoint_path: str) -> None:
        """Loads model checkpoint.

        Args:
            checkpoint_path (str): Path to the checkpoint file.
        """
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        epoch = checkpoint['epoch']
        print(f'Checkpoint loaded from {checkpoint_path} (epoch {epoch})')

    def get_model(self) -> nn.Module:
        """Returns the model.

        Returns:
            nn.Module: The model.
        """
        return self.model