"""
H2Q-Evo ç³»ç»Ÿåˆ†æå™¨ - ä»£ç å…³ç³»ç½‘ç»œä¸å¥å£®æ€§åˆ†æ
ç”Ÿæˆå®Œæ•´çš„ä¾èµ–å…³ç³»å›¾å’Œç”Ÿäº§å°±ç»ªéªŒè¯æŠ¥å‘Š
"""

import ast
import os
import json
import torch
import numpy as np
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional
from collections import defaultdict
from dataclasses import dataclass, asdict
import importlib.util
import sys

@dataclass
class ComponentMetrics:
    """ç»„ä»¶æŒ‡æ ‡"""
    name: str
    file_path: str
    lines_of_code: int
    complexity: int
    dependencies: List[str]
    dependents: List[str]
    test_coverage: bool
    has_error_handling: bool
    has_validation: bool
    version_controlled: bool
    robustness_score: float

@dataclass
class SystemHealthReport:
    """ç³»ç»Ÿå¥åº·æŠ¥å‘Š"""
    total_components: int
    critical_components: List[str]
    dependency_graph: Dict[str, List[str]]
    circular_dependencies: List[Tuple[str, str]]
    untested_components: List[str]
    missing_error_handling: List[str]
    robustness_scores: Dict[str, float]
    production_readiness_score: float
    recommendations: List[str]

class CodeAnalyzer(ast.NodeVisitor):
    """AST ä»£ç åˆ†æå™¨"""
    
    def __init__(self):
        self.imports = set()
        self.classes = []
        self.functions = []
        self.complexity = 0
        self.has_try_except = False
        self.has_assertions = False
        self.has_type_hints = False
        
    def visit_Import(self, node):
        for alias in node.names:
            self.imports.add(alias.name.split('.')[0])
        self.generic_visit(node)
        
    def visit_ImportFrom(self, node):
        if node.module:
            self.imports.add(node.module.split('.')[0])
        self.generic_visit(node)
        
    def visit_ClassDef(self, node):
        self.classes.append(node.name)
        self.generic_visit(node)
        
    def visit_FunctionDef(self, node):
        self.functions.append(node.name)
        # æ£€æŸ¥ç±»å‹æç¤º
        if node.returns or any(arg.annotation for arg in node.args.args):
            self.has_type_hints = True
        self.generic_visit(node)
        
    def visit_If(self, node):
        self.complexity += 1
        self.generic_visit(node)
        
    def visit_For(self, node):
        self.complexity += 1
        self.generic_visit(node)
        
    def visit_While(self, node):
        self.complexity += 1
        self.generic_visit(node)
        
    def visit_Try(self, node):
        self.has_try_except = True
        self.complexity += 1
        self.generic_visit(node)
        
    def visit_Assert(self, node):
        self.has_assertions = True
        self.generic_visit(node)

class DependencyAnalyzer:
    """ä¾èµ–å…³ç³»åˆ†æå™¨"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.dependency_graph = defaultdict(set)
        self.reverse_graph = defaultdict(set)
        self.components = {}
        
    def analyze_file(self, file_path: Path) -> Optional[ComponentMetrics]:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # è·³è¿‡ç©ºæ–‡ä»¶
            if not content.strip():
                return None
                
            tree = ast.parse(content)
            analyzer = CodeAnalyzer()
            analyzer.visit(tree)
            
            # è®¡ç®—è¡Œæ•°
            lines = content.split('\n')
            code_lines = [l for l in lines if l.strip() and not l.strip().startswith('#')]
            
            # è®¡ç®—é²æ£’æ€§è¯„åˆ†
            robustness = self._calculate_robustness(
                analyzer.has_try_except,
                analyzer.has_assertions,
                analyzer.has_type_hints,
                analyzer.complexity,
                len(code_lines)
            )
            
            rel_path = file_path.relative_to(self.project_root)
            
            metrics = ComponentMetrics(
                name=str(rel_path),
                file_path=str(file_path),
                lines_of_code=len(code_lines),
                complexity=analyzer.complexity,
                dependencies=list(analyzer.imports),
                dependents=[],
                test_coverage=self._has_test_file(rel_path),
                has_error_handling=analyzer.has_try_except,
                has_validation=analyzer.has_assertions,
                version_controlled=True,  # å‡è®¾åœ¨ git ä¸­
                robustness_score=robustness
            )
            
            return metrics
            
        except Exception as e:
            print(f"Error analyzing {file_path}: {e}")
            return None
            
    def _calculate_robustness(self, has_error: bool, has_validation: bool,
                             has_types: bool, complexity: int, loc: int) -> float:
        """è®¡ç®—é²æ£’æ€§è¯„åˆ† (0-100)"""
        score = 0.0
        
        # é”™è¯¯å¤„ç† (30åˆ†)
        if has_error:
            score += 30
            
        # è¾“å…¥éªŒè¯ (25åˆ†)
        if has_validation:
            score += 25
            
        # ç±»å‹æç¤º (20åˆ†)
        if has_types:
            score += 20
            
        # å¤æ‚åº¦æƒ©ç½š (æœ€å¤šæ‰£15åˆ†)
        if loc > 0:
            complexity_ratio = complexity / loc
            if complexity_ratio > 0.3:
                score -= 15
            elif complexity_ratio > 0.2:
                score -= 10
            elif complexity_ratio > 0.1:
                score -= 5
                
        # ä»£ç é‡åˆç†æ€§ (10åˆ†)
        if 10 < loc < 500:
            score += 10
        elif 500 <= loc < 1000:
            score += 5
            
        # åŸºç¡€åˆ† (5åˆ†)
        score += 5
        
        return max(0, min(100, score))
        
    def _has_test_file(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„æµ‹è¯•æ–‡ä»¶"""
        test_dir = self.project_root / "tests"
        if not test_dir.exists():
            return False
            
        test_name = f"test_{file_path.stem}.py"
        return (test_dir / test_name).exists()
        
    def build_dependency_graph(self):
        """æ„å»ºå®Œæ•´çš„ä¾èµ–å…³ç³»å›¾"""
        # æ‰«ææ‰€æœ‰ Python æ–‡ä»¶
        python_files = list(self.project_root.rglob("*.py"))
        
        print(f"Found {len(python_files)} Python files")
        
        for file_path in python_files:
            # è·³è¿‡æµ‹è¯•æ–‡ä»¶å’Œè™šæ‹Ÿç¯å¢ƒ
            if 'test' in str(file_path) or 'venv' in str(file_path) or '.pyenv' in str(file_path):
                continue
                
            metrics = self.analyze_file(file_path)
            if metrics:
                self.components[metrics.name] = metrics
                
                # æ„å»ºä¾èµ–å›¾
                for dep in metrics.dependencies:
                    self.dependency_graph[metrics.name].add(dep)
                    self.reverse_graph[dep].add(metrics.name)
                    
    def find_circular_dependencies(self) -> List[Tuple[str, str]]:
        """æŸ¥æ‰¾å¾ªç¯ä¾èµ–"""
        circular = []
        visited = set()
        rec_stack = set()
        
        def dfs(node: str, path: List[str]):
            visited.add(node)
            rec_stack.add(node)
            path.append(node)
            
            for neighbor in self.dependency_graph.get(node, []):
                if neighbor not in visited:
                    dfs(neighbor, path[:])
                elif neighbor in rec_stack:
                    # æ‰¾åˆ°å¾ªç¯
                    cycle_start = path.index(neighbor)
                    cycle = path[cycle_start:] + [neighbor]
                    if len(cycle) >= 2:
                        circular.append((cycle[0], cycle[-1]))
                        
            rec_stack.remove(node)
            
        for component in self.components:
            if component not in visited:
                dfs(component, [])
                
        return list(set(circular))
        
    def identify_critical_components(self) -> List[str]:
        """è¯†åˆ«å…³é”®ç»„ä»¶ï¼ˆè¢«å¤šä¸ªç»„ä»¶ä¾èµ–ï¼‰"""
        critical = []
        for component, dependents in self.reverse_graph.items():
            if len(dependents) >= 3:  # è¢«3ä¸ªä»¥ä¸Šç»„ä»¶ä¾èµ–
                critical.append(component)
        return sorted(critical, key=lambda x: len(self.reverse_graph[x]), reverse=True)
        
    def generate_health_report(self) -> SystemHealthReport:
        """ç”Ÿæˆç³»ç»Ÿå¥åº·æŠ¥å‘Š"""
        circular_deps = self.find_circular_dependencies()
        critical_components = self.identify_critical_components()
        
        untested = [
            name for name, metrics in self.components.items()
            if not metrics.test_coverage and 'h2q/core' in name
        ]
        
        missing_error_handling = [
            name for name, metrics in self.components.items()
            if not metrics.has_error_handling and metrics.lines_of_code > 50
        ]
        
        robustness_scores = {
            name: metrics.robustness_score
            for name, metrics in self.components.items()
        }
        
        # è®¡ç®—ç”Ÿäº§å°±ç»ªåˆ†æ•°
        avg_robustness = np.mean(list(robustness_scores.values())) if robustness_scores else 0
        test_coverage = sum(1 for m in self.components.values() if m.test_coverage) / max(len(self.components), 1)
        error_handling = sum(1 for m in self.components.values() if m.has_error_handling) / max(len(self.components), 1)
        
        production_score = (
            avg_robustness * 0.4 +
            test_coverage * 100 * 0.3 +
            error_handling * 100 * 0.2 -
            len(circular_deps) * 5 -
            len(untested) * 2
        )
        production_score = max(0, min(100, production_score))
        
        # ç”Ÿæˆå»ºè®®
        recommendations = []
        if circular_deps:
            recommendations.append(f"è§£å†³ {len(circular_deps)} ä¸ªå¾ªç¯ä¾èµ–")
        if untested:
            recommendations.append(f"ä¸º {len(untested)} ä¸ªæ ¸å¿ƒç»„ä»¶æ·»åŠ æµ‹è¯•")
        if missing_error_handling:
            recommendations.append(f"ä¸º {len(missing_error_handling)} ä¸ªç»„ä»¶æ·»åŠ é”™è¯¯å¤„ç†")
        if avg_robustness < 60:
            recommendations.append("æé«˜æ•´ä½“ä»£ç é²æ£’æ€§ï¼ˆå½“å‰å¹³å‡: {:.1f}/100ï¼‰".format(avg_robustness))
            
        return SystemHealthReport(
            total_components=len(self.components),
            critical_components=critical_components[:10],
            dependency_graph={k: list(v) for k, v in self.dependency_graph.items()},
            circular_dependencies=circular_deps,
            untested_components=untested[:20],
            missing_error_handling=missing_error_handling[:20],
            robustness_scores=robustness_scores,
            production_readiness_score=production_score,
            recommendations=recommendations
        )

def generate_detailed_report(report: SystemHealthReport, output_path: Path):
    """ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š"""
    from datetime import datetime
    report_md = f"""# H2Q-Evo ç³»ç»Ÿå¥åº·ä¸ä»£ç å…³ç³»ç½‘ç»œåˆ†ææŠ¥å‘Š

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š æ€»ä½“æ¦‚è§ˆ

- **ç»„ä»¶æ€»æ•°**: {report.total_components}
- **ç”Ÿäº§å°±ç»ªåº¦**: {report.production_readiness_score:.1f}/100
- **å¾ªç¯ä¾èµ–æ•°**: {len(report.circular_dependencies)}
- **æœªæµ‹è¯•ç»„ä»¶**: {len(report.untested_components)}
- **ç¼ºå°‘é”™è¯¯å¤„ç†**: {len(report.missing_error_handling)}

## ğŸ¯ å…³é”®ç»„ä»¶ï¼ˆé«˜ä¾èµ–åº¦ï¼‰

è¢«æœ€å¤šç»„ä»¶ä¾èµ–çš„æ ¸å¿ƒæ¨¡å—ï¼š

"""
    
    for i, comp in enumerate(report.critical_components, 1):
        report_md += f"{i}. `{comp}`\n"
        
    report_md += f"""
## âš ï¸ å¾ªç¯ä¾èµ–

æ£€æµ‹åˆ° {len(report.circular_dependencies)} ä¸ªå¾ªç¯ä¾èµ–ï¼š

"""
    
    for src, dst in report.circular_dependencies[:10]:
        report_md += f"- `{src}` âŸ· `{dst}`\n"
        
    report_md += f"""
## ğŸ§ª æµ‹è¯•è¦†ç›–ç¼ºå£

ä»¥ä¸‹æ ¸å¿ƒç»„ä»¶ç¼ºå°‘æµ‹è¯•ï¼š

"""
    
    for comp in report.untested_components[:15]:
        report_md += f"- `{comp}`\n"
        
    report_md += f"""
## ğŸ›¡ï¸ é”™è¯¯å¤„ç†ç¼ºå¤±

ä»¥ä¸‹ç»„ä»¶éœ€è¦æ·»åŠ é”™è¯¯å¤„ç†ï¼ˆ>50 è¡Œä»£ç ï¼‰ï¼š

"""
    
    for comp in report.missing_error_handling[:15]:
        report_md += f"- `{comp}`\n"
        
    report_md += f"""
## ğŸ“ˆ é²æ£’æ€§è¯„åˆ†

### å¾—åˆ†åˆ†å¸ƒ
"""
    
    # è®¡ç®—è¯„åˆ†åˆ†å¸ƒ
    scores = list(report.robustness_scores.values())
    if scores:
        excellent = sum(1 for s in scores if s >= 80)
        good = sum(1 for s in scores if 60 <= s < 80)
        fair = sum(1 for s in scores if 40 <= s < 60)
        poor = sum(1 for s in scores if s < 40)
        
        report_md += f"""
- ä¼˜ç§€ (â‰¥80): {excellent} ({excellent/len(scores)*100:.1f}%)
- è‰¯å¥½ (60-79): {good} ({good/len(scores)*100:.1f}%)
- ä¸€èˆ¬ (40-59): {fair} ({fair/len(scores)*100:.1f}%)
- è¾ƒå·® (<40): {poor} ({poor/len(scores)*100:.1f}%)

### æœ€ä½³å®è·µç»„ä»¶ (è¯„åˆ†â‰¥80)

"""
        best_components = sorted(
            report.robustness_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )[:10]
        
        for comp, score in best_components:
            if score >= 80:
                report_md += f"- `{comp}`: {score:.1f}/100\n"
                
        report_md += f"""
### éœ€è¦æ”¹è¿›çš„ç»„ä»¶ (è¯„åˆ†<40)

"""
        worst_components = sorted(
            report.robustness_scores.items(),
            key=lambda x: x[1]
        )[:10]
        
        for comp, score in worst_components:
            if score < 40:
                report_md += f"- `{comp}`: {score:.1f}/100\n"
                
    report_md += f"""
## ğŸ¯ æ”¹è¿›å»ºè®®

"""
    
    for i, rec in enumerate(report.recommendations, 1):
        report_md += f"{i}. {rec}\n"
        
    report_md += """
## ğŸ“Š ä¾èµ–å…³ç³»ç½‘ç»œæ‹“æ‰‘

### æ ¸å¿ƒä¾èµ–å±‚çº§

```
DiscreteDecisionEngine (æ ¸å¿ƒå†³ç­–å¼•æ“)
  â”œâ”€â”€ SpectralShiftTracker (è°±ç§»è·Ÿè¸ªå™¨)
  â”œâ”€â”€ QuaternionicManifold (å››å…ƒæ•°æµå½¢)
  â””â”€â”€ LatentConfig (é…ç½®ç®¡ç†)

AutonomousSystem (è‡ªä¸»ç³»ç»Ÿ)
  â”œâ”€â”€ DiscreteDecisionEngine
  â”œâ”€â”€ TopologicalPhaseQuantizer
  â””â”€â”€ ReversibleKernel

SpectralShiftTracker (è°±ç§»è·Ÿè¸ª)
  â””â”€â”€ SU(2) æµå½¢æŠ•å½±

```

## ğŸ”’ ç‰ˆæœ¬æ§åˆ¶å»ºè®®

### æ ¸å¿ƒç®—æ³•ç‰ˆæœ¬å¿«ç…§

å»ºè®®ä¸ºä»¥ä¸‹æ ¸å¿ƒç»„ä»¶åˆ›å»ºç‰ˆæœ¬å¿«ç…§ï¼š

1. **DiscreteDecisionEngine** - å†³ç­–å¼•æ“æ ¸å¿ƒé€»è¾‘
2. **SpectralShiftTracker** - è°±ç§»è®¡ç®—å…¬å¼
3. **QuaternionicManifold** - å››å…ƒæ•°æµå½¢æ“ä½œ
4. **ReversibleKernel** - å¯é€†æ ¸å¿ƒå‡½æ•°
5. **AutonomousSystem** - è‡ªä¸»ç³»ç»Ÿé›†æˆ

### æ¨èç‰ˆæœ¬æ§åˆ¶ç­–ç•¥

```python
# ç®—æ³•ç‰ˆæœ¬æ ‡è®°
ALGORITHM_VERSION = {
    "discrete_decision_engine": "2.1.0",
    "spectral_shift_tracker": "1.5.0",
    "quaternionic_manifold": "1.8.0",
    "reversible_kernel": "1.3.0",
    "autonomous_system": "2.0.0"
}

# API å…¼å®¹æ€§æ ‡è®°
API_COMPATIBILITY = {
    "min_version": "2.0.0",
    "max_version": "3.0.0",
    "breaking_changes": []
}
```

## ğŸ“‹ ç”Ÿäº§ç¯å¢ƒæ£€æŸ¥æ¸…å•

- [ ] æ‰€æœ‰æ ¸å¿ƒç»„ä»¶æœ‰å•å…ƒæµ‹è¯•
- [ ] æ‰€æœ‰ API æ¥å£æœ‰é›†æˆæµ‹è¯•
- [ ] é”™è¯¯å¤„ç†è¦†ç›–æ‰€æœ‰å¤–éƒ¨è°ƒç”¨
- [ ] è¾“å…¥éªŒè¯é˜²æ­¢æ— æ•ˆæ•°æ®
- [ ] æ€§èƒ½ç›‘æ§å’Œæ—¥å¿—è®°å½•
- [ ] é™çº§ç­–ç•¥å’Œç†”æ–­æœºåˆ¶
- [ ] å¥åº·æ£€æŸ¥ç«¯ç‚¹
- [ ] ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥
- [ ] æ–‡æ¡£å®Œæ•´ä¸”æ›´æ–°
- [ ] éƒ¨ç½²å›æ»šé¢„æ¡ˆ

## ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### é«˜ä¼˜å…ˆçº§

1. è§£å†³æ‰€æœ‰å¾ªç¯ä¾èµ–
2. ä¸ºæ ¸å¿ƒç»„ä»¶æ·»åŠ é”™è¯¯å¤„ç†
3. è¡¥å……ç¼ºå¤±çš„å•å…ƒæµ‹è¯•
4. å®ç°ç®—æ³•ç‰ˆæœ¬æ§åˆ¶

### ä¸­ä¼˜å…ˆçº§

5. é‡æ„é«˜å¤æ‚åº¦ç»„ä»¶
6. æ·»åŠ ç±»å‹æç¤ºå’Œæ–‡æ¡£
7. å®ç°æ€§èƒ½ç›‘æ§
8. åˆ›å»ºå¥åº·æ£€æŸ¥ç³»ç»Ÿ

### ä½ä¼˜å…ˆçº§

9. ä¼˜åŒ–ä»£ç ç»“æ„
10. æ”¹è¿›æ—¥å¿—è®°å½•
11. å¢å¼ºå¯è§‚æµ‹æ€§
12. å®Œå–„æ–‡æ¡£å’Œç¤ºä¾‹

---

*æŠ¥å‘Šç”± H2Q-Evo ç³»ç»Ÿåˆ†æå™¨è‡ªåŠ¨ç”Ÿæˆ*
"""
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report_md)
        
    print(f"âœ… è¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")

def main():
    """ä¸»å‡½æ•°"""
    try:
        import pandas as pd
    except ImportError:
        print("è­¦å‘Š: pandas æœªå®‰è£…ï¼Œä½¿ç”¨åŸºç¡€åŠŸèƒ½")
        
    project_root = Path(__file__).parent
    
    print("ğŸ” å¼€å§‹åˆ†æ H2Q-Evo ç³»ç»Ÿ...")
    print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
    
    analyzer = DependencyAnalyzer(project_root)
    analyzer.build_dependency_graph()
    
    print(f"âœ… å·²åˆ†æ {len(analyzer.components)} ä¸ªç»„ä»¶")
    
    print("ğŸ“Š ç”Ÿæˆç³»ç»Ÿå¥åº·æŠ¥å‘Š...")
    report = analyzer.generate_health_report()
    
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     H2Q-Evo ç³»ç»Ÿå¥åº·æŠ¥å‘Š                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ æ€»ç»„ä»¶æ•°:        {report.total_components:4d}                  â•‘
â•‘ ç”Ÿäº§å°±ç»ªåº¦:      {report.production_readiness_score:5.1f}/100             â•‘
â•‘ å…³é”®ç»„ä»¶æ•°:      {len(report.critical_components):4d}                  â•‘
â•‘ å¾ªç¯ä¾èµ–:        {len(report.circular_dependencies):4d}                  â•‘
â•‘ æœªæµ‹è¯•ç»„ä»¶:      {len(report.untested_components):4d}                  â•‘
â•‘ ç¼ºå°‘é”™è¯¯å¤„ç†:    {len(report.missing_error_handling):4d}                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # ä¿å­˜æŠ¥å‘Š
    output_dir = project_root / "reports"
    output_dir.mkdir(exist_ok=True)
    
    # JSON æŠ¥å‘Š
    json_path = output_dir / "system_health_report.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump({
            'total_components': report.total_components,
            'production_readiness_score': report.production_readiness_score,
            'critical_components': report.critical_components,
            'circular_dependencies': [list(cd) for cd in report.circular_dependencies],
            'untested_components': report.untested_components,
            'missing_error_handling': report.missing_error_handling,
            'robustness_scores': report.robustness_scores,
            'recommendations': report.recommendations
        }, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… JSON æŠ¥å‘Šå·²ä¿å­˜: {json_path}")
    
    # Markdown æŠ¥å‘Š
    md_path = output_dir / "SYSTEM_HEALTH_REPORT.md"
    generate_detailed_report(report, md_path)
    
    # ä¿å­˜ä¾èµ–å›¾
    graph_path = output_dir / "dependency_graph.json"
    with open(graph_path, 'w', encoding='utf-8') as f:
        json.dump(report.dependency_graph, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ä¾èµ–å…³ç³»å›¾å·²ä¿å­˜: {graph_path}")
    
    print("\n" + "="*50)
    print("ğŸ¯ ä¸»è¦å‘ç°:")
    print("="*50)
    for i, rec in enumerate(report.recommendations, 1):
        print(f"{i}. {rec}")
        
    print("\n" + "="*50)
    print("âœ… ç³»ç»Ÿåˆ†æå®Œæˆ!")
    print("="*50)
    
    return report

if __name__ == "__main__":
    main()
