import torch
import torch.nn as nn
from typing import Tuple, Optional
from h2q.core.interface_registry import get_canonical_dde, LatentConfig

class TPQBitPacker(nn.Module):
    """
    TPQ (Topological Phase Quantization) Bit-Packing Kernel.
    Enables 8:1 memory reduction for 'frozen' knots in the RSKH vault.
    Optimized for M4 (MPS) using vectorized bit-shifting.
    
    Symmetry: pack_4bit(unpack_4bit(x)) â‰ˆ x within Fueter analytic bounds.
    """
    def __init__(self, n_knots: int = 64, atoms_per_knot: int = 4):
        super().__init__()
        self.n_knots = n_knots
        self.atoms_per_knot = atoms_per_knot
        self.total_dim = n_knots * atoms_per_knot # 256
        
        # Fix for Runtime Error: DiscreteDecisionEngine.__init__() got an unexpected keyword argument 'dim'
        # Using canonical registry to instantiate DDE with LatentConfig
        config = LatentConfig(latent_dim=self.total_dim)
        self.dde = get_canonical_dde(config)

    @torch.no_grad()
    def quantize_to_4bit(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Maps quaternionic manifold atoms to 4-bit phase indices [0, 15].
        """
        # Calculate dynamic range for the manifold slice
        min_val = x.min()
        max_val = x.max()
        scale = (max_val - min_val) / 15.0
        
        # Avoid division by zero in dead knots
        scale = torch.clamp(scale, min=1e-6)
        
        # Quantize to 0-15
        q_x = torch.round((x - min_val) / scale).to(torch.uint8)
        q_x = torch.clamp(q_x, 0, 15)
        
        return q_x, min_val, scale

    def pack_4bit(self, x: torch.Tensor) -> torch.Tensor:
        """
        Packs two 4-bit atoms into a single uint8 byte.
        Input shape: [..., 256]
        Output shape: [..., 128] (8:1 reduction from float32)
        """
        # Ensure even number of atoms for packing
        assert x.shape[-1] % 2 == 0, "Atom count must be even for 4-bit packing."
        
        # Vectorized bit-shifting for M4/MPS
        # high_bits: shift left by 4
        # low_bits: keep as is
        high = torch.bitwise_left_shift(x[..., 0::2], 4)
        low = x[..., 1::2]
        
        packed = torch.bitwise_or(high, low)
        return packed.to(torch.uint8)

    def unpack_4bit(self, packed: torch.Tensor, min_val: torch.Tensor, scale: torch.Tensor) -> torch.Tensor:
        """
        Unpacks uint8 bytes back into 4-bit atoms and dequantizes to float32.
        """
        # Extract high and low 4-bit nibbles
        high = torch.bitwise_right_shift(packed, 4)
        low = torch.bitwise_and(packed, 0x0F)
        
        # Interleave back to original dimension
        # Shape: [..., 128] -> [..., 256]
        unpacked = torch.stack([high, low], dim=-1).flatten(start_dim=-2)
        
        # Dequantize
        return unpacked.to(torch.float32) * scale + min_val

    def freeze_knot(self, manifold_tensor: torch.Tensor) -> dict:
        """
        EXPERIMENTAL: Compresses a knot for RSKH vault storage.
        Verifies structural veracity via DDE before finalizing.
        """
        # 1. Quantize
        q_indices, min_v, scale = self.quantize_to_4bit(manifold_tensor)
        
        # 2. Pack
        packed_data = self.pack_4bit(q_indices)
        
        # 3. Verify Integrity (Topological Tear Check)
        # We simulate a reconstruction to check if the DDE accepts the precision loss
        reconstructed = self.unpack_4bit(packed_data, min_v, scale)
        
        # DDE evaluates the 'drag' caused by quantization noise
        # Note: DDE call follows the verified registry signature
        decision = self.dde(reconstructed)
        
        return {
            "data": packed_data,
            "metadata": {
                "min": min_v,
                "scale": scale,
                "decision_eta": decision.get('eta', 0.0)
            }
        }

def audit_tpq_packing():
    """STABLE: Verification routine for 8:1 reduction veracity."""
    packer = TPQBitPacker()
    test_knot = torch.randn(1, 256, device='cpu') # Use CPU for audit logic
    
    frozen = packer.freeze_knot(test_knot)
    packed_size = frozen['data'].element_size() * frozen['data'].nelement()
    orig_size = test_knot.element_size() * test_knot.nelement()
    
    reduction = orig_size / packed_size
    print(f"[TPQ Audit] Original: {orig_size} bytes | Packed: {packed_size} bytes")
    print(f"[TPQ Audit] Reduction Ratio: {reduction}:1")
    
    return reduction == 8.0