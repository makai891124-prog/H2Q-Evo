"""
H2Q-Evo é²æ£’æ€§å¢å¼ºåŒ…è£…å™¨
ä¸ºæ ¸å¿ƒç®—æ³•æ·»åŠ é”™è¯¯å¤„ç†ã€è¾“å…¥éªŒè¯ã€è¾¹ç•Œæ£€æŸ¥å’Œé™çº§ç­–ç•¥
"""

import torch
import torch.nn as nn
from typing import Any, Callable, Optional, Dict, Tuple, Union
from functools import wraps
import traceback
import time
from dataclasses import dataclass
from enum import Enum

class ErrorSeverity(Enum):
    """é”™è¯¯ä¸¥é‡ç¨‹åº¦"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

@dataclass
class ValidationError:
    """éªŒè¯é”™è¯¯"""
    field_name: str
    error_message: str
    severity: ErrorSeverity
    actual_value: Any
    expected_range: Optional[Tuple[Any, Any]] = None

class RobustWrapper:
    """é²æ£’æ€§åŒ…è£…å™¨"""
    
    def __init__(
        self,
        enable_validation: bool = True,
        enable_fallback: bool = True,
        enable_logging: bool = True,
        retry_attempts: int = 3
    ):
        self.enable_validation = enable_validation
        self.enable_fallback = enable_fallback
        self.enable_logging = enable_logging
        self.retry_attempts = retry_attempts
        self.error_count = 0
        self.total_calls = 0
        
    def validate_tensor_input(
        self,
        tensor: torch.Tensor,
        name: str,
        expected_shape: Optional[Tuple[int, ...]] = None,
        expected_dtype: Optional[torch.dtype] = None,
        min_value: Optional[float] = None,
        max_value: Optional[float] = None,
        allow_nan: bool = False,
        allow_inf: bool = False
    ) -> list[ValidationError]:
        """éªŒè¯å¼ é‡è¾“å…¥"""
        errors = []
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå¼ é‡
        if not isinstance(tensor, torch.Tensor):
            errors.append(ValidationError(
                field_name=name,
                error_message=f"æœŸæœ› torch.Tensorï¼Œå®é™…æ˜¯ {type(tensor)}",
                severity=ErrorSeverity.CRITICAL,
                actual_value=type(tensor)
            ))
            return errors
            
        # æ£€æŸ¥å½¢çŠ¶
        if expected_shape is not None:
            if len(expected_shape) != len(tensor.shape):
                errors.append(ValidationError(
                    field_name=name,
                    error_message=f"å½¢çŠ¶ç»´åº¦ä¸åŒ¹é…: æœŸæœ› {len(expected_shape)}Dï¼Œå®é™… {len(tensor.shape)}D",
                    severity=ErrorSeverity.HIGH,
                    actual_value=tensor.shape,
                    expected_range=(expected_shape, expected_shape)
                ))
            else:
                for i, (expected, actual) in enumerate(zip(expected_shape, tensor.shape)):
                    if expected != -1 and expected != actual:
                        errors.append(ValidationError(
                            field_name=f"{name}.shape[{i}]",
                            error_message=f"ç»´åº¦ {i} ä¸åŒ¹é…: æœŸæœ› {expected}ï¼Œå®é™… {actual}",
                            severity=ErrorSeverity.HIGH,
                            actual_value=actual,
                            expected_range=(expected, expected)
                        ))
                        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        if expected_dtype is not None and tensor.dtype != expected_dtype:
            errors.append(ValidationError(
                field_name=f"{name}.dtype",
                error_message=f"æ•°æ®ç±»å‹ä¸åŒ¹é…: æœŸæœ› {expected_dtype}ï¼Œå®é™… {tensor.dtype}",
                severity=ErrorSeverity.MEDIUM,
                actual_value=tensor.dtype,
                expected_range=(expected_dtype, expected_dtype)
            ))
            
        # æ£€æŸ¥ NaN
        if not allow_nan and torch.isnan(tensor).any():
            errors.append(ValidationError(
                field_name=name,
                error_message="åŒ…å« NaN å€¼",
                severity=ErrorSeverity.CRITICAL,
                actual_value="NaN detected"
            ))
            
        # æ£€æŸ¥ Inf
        if not allow_inf and torch.isinf(tensor).any():
            errors.append(ValidationError(
                field_name=name,
                error_message="åŒ…å« Inf å€¼",
                severity=ErrorSeverity.CRITICAL,
                actual_value="Inf detected"
            ))
            
        # æ£€æŸ¥å€¼èŒƒå›´
        if min_value is not None:
            actual_min = tensor.min().item()
            if actual_min < min_value:
                errors.append(ValidationError(
                    field_name=f"{name}.min",
                    error_message=f"æœ€å°å€¼ä½äºé˜ˆå€¼: {actual_min} < {min_value}",
                    severity=ErrorSeverity.MEDIUM,
                    actual_value=actual_min,
                    expected_range=(min_value, None)
                ))
                
        if max_value is not None:
            actual_max = tensor.max().item()
            if actual_max > max_value:
                errors.append(ValidationError(
                    field_name=f"{name}.max",
                    error_message=f"æœ€å¤§å€¼è¶…è¿‡é˜ˆå€¼: {actual_max} > {max_value}",
                    severity=ErrorSeverity.MEDIUM,
                    actual_value=actual_max,
                    expected_range=(None, max_value)
                ))
                
        return errors
        
    def sanitize_tensor(
        self,
        tensor: torch.Tensor,
        replace_nan: Optional[float] = 0.0,
        replace_inf: Optional[float] = None,
        clip_min: Optional[float] = None,
        clip_max: Optional[float] = None
    ) -> torch.Tensor:
        """æ¸…ç†å¼ é‡ï¼ˆæ›¿æ¢å¼‚å¸¸å€¼ï¼‰"""
        tensor = tensor.clone()
        
        # æ›¿æ¢ NaN
        if replace_nan is not None:
            tensor = torch.nan_to_num(tensor, nan=replace_nan)
            
        # æ›¿æ¢ Inf
        if replace_inf is not None:
            tensor = torch.nan_to_num(tensor, posinf=replace_inf, neginf=-replace_inf)
            
        # è£å‰ªå€¼èŒƒå›´
        if clip_min is not None or clip_max is not None:
            tensor = torch.clamp(tensor, min=clip_min, max=clip_max)
            
        return tensor

def robust_inference(
    validate_input: bool = True,
    sanitize_output: bool = True,
    fallback_value: Optional[Any] = None,
    max_retries: int = 3
):
    """é²æ£’æ¨ç†è£…é¥°å™¨"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            wrapper_obj = RobustWrapper()
            wrapper_obj.total_calls += 1
            
            # è¾“å…¥éªŒè¯
            if validate_input:
                for arg in args:
                    if isinstance(arg, torch.Tensor):
                        errors = wrapper_obj.validate_tensor_input(
                            arg,
                            name="input_tensor",
                            allow_nan=False,
                            allow_inf=False
                        )
                        if errors:
                            critical_errors = [e for e in errors if e.severity == ErrorSeverity.CRITICAL]
                            if critical_errors:
                                raise ValueError(f"è¾“å…¥éªŒè¯å¤±è´¥: {critical_errors[0].error_message}")
                                
            # é‡è¯•é€»è¾‘
            last_exception = None
            for attempt in range(max_retries):
                try:
                    result = func(*args, **kwargs)
                    
                    # è¾“å‡ºæ¸…ç†
                    if sanitize_output and isinstance(result, torch.Tensor):
                        result = wrapper_obj.sanitize_tensor(
                            result,
                            replace_nan=0.0,
                            replace_inf=1e6
                        )
                        
                    return result
                    
                except Exception as e:
                    last_exception = e
                    wrapper_obj.error_count += 1
                    
                    if attempt < max_retries - 1:
                        time.sleep(0.1 * (attempt + 1))  # æŒ‡æ•°é€€é¿
                        continue
                    else:
                        if fallback_value is not None:
                            print(f"âš ï¸ ä½¿ç”¨é™çº§å€¼: {fallback_value}")
                            return fallback_value
                        else:
                            raise last_exception
                            
        return wrapper
    return decorator

class RobustDiscreteDecisionEngine(nn.Module):
    """å¢å¼ºé²æ£’æ€§çš„å†³ç­–å¼•æ“åŒ…è£…å™¨"""
    
    def __init__(self, base_engine: nn.Module):
        super().__init__()
        self.base_engine = base_engine
        self.wrapper = RobustWrapper()
        self.fallback_enabled = True
        self.performance_degraded = False
        
    @robust_inference(validate_input=True, sanitize_output=True, max_retries=3)
    def forward(self, x: torch.Tensor, **kwargs) -> torch.Tensor:
        """å‰å‘ä¼ æ’­ï¼Œå¸¦æœ‰é²æ£’æ€§æ£€æŸ¥"""
        # è¾“å…¥éªŒè¯
        errors = self.wrapper.validate_tensor_input(
            x,
            name="input",
            expected_shape=(-1, self.base_engine.config.latent_dim),
            allow_nan=False,
            allow_inf=False
        )
        
        if errors:
            critical = [e for e in errors if e.severity == ErrorSeverity.CRITICAL]
            if critical:
                # å°è¯•ä¿®å¤è¾“å…¥
                x = self.wrapper.sanitize_tensor(x, replace_nan=0.0, replace_inf=1e6)
                print(f"âš ï¸ è¾“å…¥å·²æ¸…ç†: {len(critical)} ä¸ªä¸¥é‡é”™è¯¯")
                
        # æ‰§è¡Œæ¨ç†
        try:
            output = self.base_engine(x, **kwargs)
            
            # è¾“å‡ºéªŒè¯
            output_errors = self.wrapper.validate_tensor_input(
                output,
                name="output",
                allow_nan=False,
                allow_inf=False
            )
            
            if output_errors:
                output = self.wrapper.sanitize_tensor(output, replace_nan=0.0, replace_inf=1e6)
                
            return output
            
        except RuntimeError as e:
            # GPU å†…å­˜ä¸è¶³æ—¶é™çº§åˆ° CPU
            if "out of memory" in str(e).lower():
                print("âš ï¸ GPU å†…å­˜ä¸è¶³ï¼Œé™çº§åˆ° CPU")
                self.performance_degraded = True
                x_cpu = x.cpu()
                self.base_engine.cpu()
                output = self.base_engine(x_cpu, **kwargs)
                return output.to(x.device)
            else:
                raise e

def add_input_validation(
    tensor_name: str,
    expected_shape: Optional[Tuple[int, ...]] = None,
    min_value: Optional[float] = None,
    max_value: Optional[float] = None
):
    """æ·»åŠ è¾“å…¥éªŒè¯çš„è£…é¥°å™¨"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(self, *args, **kwargs):
            # æŸ¥æ‰¾åä¸º tensor_name çš„å‚æ•°
            if args and isinstance(args[0], torch.Tensor):
                tensor = args[0]
                wrapper_obj = RobustWrapper()
                errors = wrapper_obj.validate_tensor_input(
                    tensor,
                    name=tensor_name,
                    expected_shape=expected_shape,
                    min_value=min_value,
                    max_value=max_value,
                    allow_nan=False,
                    allow_inf=False
                )
                
                if errors:
                    critical = [e for e in errors if e.severity == ErrorSeverity.CRITICAL]
                    if critical:
                        raise ValueError(f"è¾“å…¥éªŒè¯å¤±è´¥: {critical[0].error_message}")
                        
            return func(self, *args, **kwargs)
        return wrapper
    return decorator

class SafetyGuard:
    """å®‰å…¨é˜²æŠ¤å±‚"""
    
    @staticmethod
    def check_numerical_stability(tensor: torch.Tensor, name: str = "tensor") -> bool:
        """æ£€æŸ¥æ•°å€¼ç¨³å®šæ€§"""
        if torch.isnan(tensor).any():
            print(f"âŒ {name} åŒ…å« NaN")
            return False
        if torch.isinf(tensor).any():
            print(f"âŒ {name} åŒ…å« Inf")
            return False
        return True
        
    @staticmethod
    def safe_division(a: torch.Tensor, b: torch.Tensor, epsilon: float = 1e-8) -> torch.Tensor:
        """å®‰å…¨é™¤æ³•ï¼ˆé¿å…é™¤é›¶ï¼‰"""
        return a / (b + epsilon)
        
    @staticmethod
    def safe_log(x: torch.Tensor, epsilon: float = 1e-8) -> torch.Tensor:
        """å®‰å…¨å¯¹æ•°ï¼ˆé¿å… log(0)ï¼‰"""
        return torch.log(x + epsilon)
        
    @staticmethod
    def safe_sqrt(x: torch.Tensor, epsilon: float = 1e-8) -> torch.Tensor:
        """å®‰å…¨å¹³æ–¹æ ¹ï¼ˆé¿å…è´Ÿæ•°ï¼‰"""
        return torch.sqrt(torch.clamp(x, min=epsilon))
        
    @staticmethod
    def gradient_clipping(tensor: torch.Tensor, max_norm: float = 1.0) -> torch.Tensor:
        """æ¢¯åº¦è£å‰ª"""
        if tensor.grad is not None:
            torch.nn.utils.clip_grad_norm_([tensor], max_norm)
        return tensor

if __name__ == "__main__":
    print("ğŸ›¡ï¸ H2Q-Evo é²æ£’æ€§å¢å¼ºç³»ç»Ÿ")
    print("="*50)
    
    # æµ‹è¯•è¾“å…¥éªŒè¯
    wrapper = RobustWrapper()
    
    # æ­£å¸¸è¾“å…¥
    normal_tensor = torch.randn(1, 256)
    errors = wrapper.validate_tensor_input(
        normal_tensor,
        name="test_tensor",
        expected_shape=(-1, 256),
        allow_nan=False
    )
    print(f"âœ… æ­£å¸¸è¾“å…¥éªŒè¯: {len(errors)} ä¸ªé”™è¯¯")
    
    # å¼‚å¸¸è¾“å…¥
    bad_tensor = torch.tensor([float('nan'), float('inf'), 1.0, 2.0])
    errors = wrapper.validate_tensor_input(
        bad_tensor,
        name="bad_tensor",
        allow_nan=False,
        allow_inf=False
    )
    print(f"âš ï¸ å¼‚å¸¸è¾“å…¥éªŒè¯: {len(errors)} ä¸ªé”™è¯¯")
    for error in errors:
        print(f"   - {error.error_message}")
        
    # æµ‹è¯•æ¸…ç†
    cleaned = wrapper.sanitize_tensor(bad_tensor, replace_nan=0.0, replace_inf=1e6)
    print(f"âœ… æ¸…ç†å: {cleaned}")
    
    # æµ‹è¯•å®‰å…¨æ“ä½œ
    print("\n" + "="*50)
    print("ğŸ”’ å®‰å…¨æ“ä½œæµ‹è¯•:")
    print("="*50)
    
    a = torch.tensor([1.0, 2.0, 3.0])
    b = torch.tensor([2.0, 0.0, 4.0])
    
    safe_result = SafetyGuard.safe_division(a, b)
    print(f"âœ… å®‰å…¨é™¤æ³•: {safe_result}")
    
    x = torch.tensor([0.0, 1.0, 2.0])
    safe_log_result = SafetyGuard.safe_log(x)
    print(f"âœ… å®‰å…¨å¯¹æ•°: {safe_log_result}")
    
    print("\nâœ… é²æ£’æ€§å¢å¼ºç³»ç»Ÿæµ‹è¯•å®Œæˆ")
