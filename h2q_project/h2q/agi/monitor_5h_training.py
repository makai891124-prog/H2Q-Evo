#!/usr/bin/env python3
"""
5å°æ—¶çœŸå®è®­ç»ƒç›‘æ§å™¨
"""

import os
import json
import time
import subprocess
from pathlib import Path
from datetime import datetime, timedelta

SCRIPT_DIR = Path(__file__).resolve().parent
LOG_DIR = SCRIPT_DIR / 'real_training_logs'
MODEL_DIR = SCRIPT_DIR / 'real_trained_models'
CHECKPOINT_DIR = SCRIPT_DIR / 'checkpoints'
OUTPUT_LOG = SCRIPT_DIR / 'real_training_output.log'


def get_process_info():
    """è·å–è®­ç»ƒè¿›ç¨‹ä¿¡æ¯"""
    result = subprocess.run(
        ['pgrep', '-f', 'real_5h_training.py'],
        capture_output=True, text=True
    )
    
    if result.returncode == 0:
        pids = result.stdout.strip().split('\n')
        # è·å–è¿›ç¨‹è¯¦æƒ…
        ps_result = subprocess.run(
            ['ps', '-p', pids[0], '-o', 'pid,%cpu,%mem,etime'],
            capture_output=True, text=True
        )
        return {'running': True, 'pids': pids, 'details': ps_result.stdout}
    return {'running': False}


def get_latest_log_entries(n=20):
    """è·å–æœ€æ–°çš„æ—¥å¿—æ¡ç›®"""
    # æŸ¥æ‰¾æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶
    if LOG_DIR.exists():
        log_files = sorted(LOG_DIR.glob('training_*.log'), reverse=True)
        if log_files:
            with open(log_files[0], 'r') as f:
                lines = f.readlines()
                return lines[-n:] if len(lines) >= n else lines
    
    # å°è¯•è¾“å‡ºæ—¥å¿—
    if OUTPUT_LOG.exists():
        with open(OUTPUT_LOG, 'r') as f:
            lines = f.readlines()
            return lines[-n:] if len(lines) >= n else lines
    
    return []


def get_checkpoint_info():
    """è·å–æ£€æŸ¥ç‚¹ä¿¡æ¯"""
    checkpoint_path = CHECKPOINT_DIR / 'latest_checkpoint.pt'
    if checkpoint_path.exists():
        import torch
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        return {
            'exists': True,
            'epoch': checkpoint.get('epoch', 0),
            'global_step': checkpoint.get('global_step', 0),
            'total_samples': checkpoint.get('total_samples', 0),
            'best_accuracy': checkpoint.get('best_accuracy', 0),
            'total_time': checkpoint.get('total_time', 0),
            'file_size': checkpoint_path.stat().st_size / (1024 * 1024)
        }
    return {'exists': False}


def get_model_info():
    """è·å–æ¨¡å‹ä¿¡æ¯"""
    model_path = MODEL_DIR / 'real_agi_model_latest.pt'
    if model_path.exists():
        import torch
        model_data = torch.load(model_path, map_location='cpu')
        return {
            'exists': True,
            'epoch': model_data.get('epoch', 0),
            'best_accuracy': model_data.get('best_accuracy', 0),
            'total_samples': model_data.get('total_samples', 0),
            'file_size': model_path.stat().st_size / (1024 * 1024),
            'modified': datetime.fromtimestamp(model_path.stat().st_mtime)
        }
    return {'exists': False}


def main():
    print("\n" + "=" * 70)
    print("   5å°æ—¶çœŸå®AGIè®­ç»ƒç›‘æ§")
    print("   Real 5-Hour AGI Training Monitor")
    print("=" * 70)
    print(f"   å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    # è¿›ç¨‹çŠ¶æ€
    print("\nğŸ“Š è¿›ç¨‹çŠ¶æ€:")
    print("-" * 50)
    proc_info = get_process_info()
    if proc_info['running']:
        print(f"   çŠ¶æ€: âœ… è¿è¡Œä¸­")
        print(f"   PID: {', '.join(proc_info['pids'])}")
        if 'details' in proc_info:
            print(f"   {proc_info['details'].strip()}")
    else:
        print("   çŠ¶æ€: âŒ æœªè¿è¡Œ")
    
    # æ£€æŸ¥ç‚¹çŠ¶æ€
    print("\nğŸ’¾ æ£€æŸ¥ç‚¹çŠ¶æ€:")
    print("-" * 50)
    ckpt_info = get_checkpoint_info()
    if ckpt_info['exists']:
        print(f"   Epoch: {ckpt_info['epoch']}")
        print(f"   å…¨å±€æ­¥æ•°: {ckpt_info['global_step']:,}")
        print(f"   æ€»æ ·æœ¬: {ckpt_info['total_samples']:,}")
        print(f"   æœ€ä½³å‡†ç¡®ç‡: {ckpt_info['best_accuracy']:.2%}")
        print(f"   è®­ç»ƒæ—¶é•¿: {timedelta(seconds=int(ckpt_info['total_time']))}")
        print(f"   æ–‡ä»¶å¤§å°: {ckpt_info['file_size']:.1f} MB")
    else:
        print("   å°šæœªåˆ›å»ºæ£€æŸ¥ç‚¹")
    
    # æ¨¡å‹çŠ¶æ€
    print("\nğŸ¤– æ¨¡å‹çŠ¶æ€:")
    print("-" * 50)
    model_info = get_model_info()
    if model_info['exists']:
        print(f"   Epoch: {model_info['epoch']}")
        print(f"   æœ€ä½³å‡†ç¡®ç‡: {model_info['best_accuracy']:.2%}")
        print(f"   æ€»æ ·æœ¬: {model_info['total_samples']:,}")
        print(f"   æ–‡ä»¶å¤§å°: {model_info['file_size']:.1f} MB")
        print(f"   æœ€åæ›´æ–°: {model_info['modified'].strftime('%H:%M:%S')}")
    else:
        print("   å°šæœªä¿å­˜æ¨¡å‹")
    
    # æœ€æ–°æ—¥å¿—
    print("\nğŸ“ æœ€æ–°è®­ç»ƒæ—¥å¿—:")
    print("-" * 50)
    log_entries = get_latest_log_entries(15)
    if log_entries:
        for line in log_entries:
            print(f"   {line.rstrip()}")
    else:
        print("   æš‚æ— æ—¥å¿—")
    
    # è¿›åº¦ä¼°ç®—
    print("\nâ±ï¸ è¿›åº¦ä¼°ç®—:")
    print("-" * 50)
    if ckpt_info.get('exists') and ckpt_info.get('total_time', 0) > 0:
        elapsed_hours = ckpt_info['total_time'] / 3600
        progress = elapsed_hours / 5.0 * 100
        remaining_hours = max(0, 5.0 - elapsed_hours)
        eta = datetime.now() + timedelta(hours=remaining_hours)
        
        print(f"   å·²è®­ç»ƒ: {elapsed_hours:.2f} å°æ—¶")
        print(f"   è¿›åº¦: {progress:.1f}%")
        print(f"   é¢„è®¡å‰©ä½™: {remaining_hours:.2f} å°æ—¶")
        print(f"   é¢„è®¡å®Œæˆ: {eta.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ç»˜åˆ¶è¿›åº¦æ¡
        bar_len = 40
        filled = int(bar_len * progress / 100)
        bar = "â–ˆ" * filled + "â–‘" * (bar_len - filled)
        print(f"\n   [{bar}] {progress:.1f}%")
    else:
        print("   ç­‰å¾…è®­ç»ƒæ•°æ®...")
    
    print("\n" + "=" * 70)
    print("   æç¤º: å†æ¬¡è¿è¡Œæ­¤è„šæœ¬æŸ¥çœ‹æœ€æ–°çŠ¶æ€")
    print("   åœæ­¢è®­ç»ƒ: kill <PID>")
    print("=" * 70)


if __name__ == "__main__":
    main()
