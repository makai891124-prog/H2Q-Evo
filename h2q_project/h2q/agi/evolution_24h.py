#!/usr/bin/env python3
"""H2Q AGI 24å°æ—¶è‡ªä¸»è¿›åŒ–ç³»ç»Ÿ.

å®ç°å®Œæ•´çš„è‡ªä¸»è¿›åŒ–æµç¨‹:
1. å…´è¶£é©±åŠ¨å­¦ä¹ 
2. ç½‘ç»œèµ„æºè·å–
3. åˆ†å½¢å‹ç¼©å­˜å‚¨
4. å®šæ—¶èƒ½åŠ›éªŒè¯
5. è¿›ç¨‹ç›‘æ§ä¿æŠ¤
6. 24å°æ—¶è‡ªåŠ¨è¿è¡Œ

å®‰å…¨è®¾è®¡:
- æœ¬åœ°è½®è¯¢è·å–å…¬å¼€èµ„æº
- èµ„æºä½¿ç”¨é™åˆ¶
- ä¼˜é›…é€€å‡ºæœºåˆ¶
"""

import os
import sys
import time
import json
import signal
import threading
import traceback
from pathlib import Path
from datetime import datetime, timedelta
from dataclasses import dataclass, field, asdict
from typing import Dict, Any, Optional, List, Callable
import hashlib
import urllib.request
import urllib.error

# é¡¹ç›®è·¯å¾„
SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPT_DIR.parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

import numpy as np


# ============================================================================
# é…ç½®
# ============================================================================

@dataclass
class EvolutionConfig:
    """è¿›åŒ–é…ç½®."""
    # æ—¶é—´è®¾ç½®
    total_duration_hours: float = 24.0     # æ€»è¿›åŒ–æ—¶é—´ (å°æ—¶)
    learning_cycle_minutes: float = 30.0   # å­¦ä¹ å‘¨æœŸ (åˆ†é’Ÿ)
    capability_check_minutes: float = 60.0 # èƒ½åŠ›æ£€æŸ¥å‘¨æœŸ (åˆ†é’Ÿ)
    heartbeat_seconds: int = 30            # å¿ƒè·³é—´éš” (ç§’)
    
    # èµ„æºé™åˆ¶
    max_memory_mb: float = 1024            # å†…å­˜é™åˆ¶ (MB)
    max_knowledge_items: int = 10000       # æœ€å¤§çŸ¥è¯†æ¡ç›®
    compression_threshold: float = 0.8     # å‹ç¼©é˜ˆå€¼
    
    # å­¦ä¹ è®¾ç½®
    interests: List[str] = field(default_factory=lambda: [
        "artificial_intelligence",
        "machine_learning", 
        "mathematics",
        "physics",
        "computer_science"
    ])
    
    # æ–‡ä»¶è·¯å¾„
    state_file: str = "evolution_24h_state.json"
    knowledge_file: str = "evolution_knowledge.json"
    log_file: str = "evolution_24h.log"
    report_file: str = "EVOLUTION_24H_REPORT.md"


# ============================================================================
# åˆ†å½¢å‹ç¼©å­˜å‚¨
# ============================================================================

class FractalCompressor:
    """åˆ†å½¢å‹ç¼©å™¨ - ä½¿ç”¨åˆ†å½¢ç†è®ºå‹ç¼©çŸ¥è¯†."""
    
    def __init__(self, compression_ratio: float = 0.5):
        self.compression_ratio = compression_ratio
        self.fractal_patterns: Dict[str, np.ndarray] = {}
    
    def compress(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """å‹ç¼©æ•°æ®."""
        compressed = {}
        
        for key, value in data.items():
            if isinstance(value, str):
                # æ–‡æœ¬å‹ç¼©: æå–å…³é”®ç‰¹å¾
                compressed[key] = self._compress_text(value)
            elif isinstance(value, (list, tuple)):
                # åºåˆ—å‹ç¼©: åˆ†å½¢é‡‡æ ·
                compressed[key] = self._compress_sequence(value)
            elif isinstance(value, dict):
                # é€’å½’å‹ç¼©
                compressed[key] = self.compress(value)
            else:
                compressed[key] = value
        
        return compressed
    
    def _compress_text(self, text: str) -> str:
        """å‹ç¼©æ–‡æœ¬ - æå–å…³é”®å¥."""
        if len(text) < 100:
            return text
        
        sentences = text.split('.')
        if len(sentences) <= 3:
            return text
        
        # ä¿ç•™é¦–å°¾å’Œä¸­é—´å…³é”®å¥
        n_keep = max(3, int(len(sentences) * self.compression_ratio))
        
        # åˆ†å½¢é‡‡æ ·: é¦–ã€å°¾ã€å¯¹æ•°åˆ†å¸ƒçš„ä¸­é—´ç‚¹
        indices = [0]  # é¦–
        
        for i in range(1, n_keep - 1):
            # å¯¹æ•°åˆ†å¸ƒé‡‡æ ·
            idx = int((len(sentences) - 1) * (np.log(i + 1) / np.log(n_keep)))
            if idx not in indices:
                indices.append(idx)
        
        indices.append(len(sentences) - 1)  # å°¾
        indices = sorted(set(indices))
        
        compressed = '. '.join(sentences[i].strip() for i in indices if i < len(sentences))
        return compressed
    
    def _compress_sequence(self, seq: list) -> list:
        """å‹ç¼©åºåˆ— - åˆ†å½¢é‡‡æ ·."""
        if len(seq) <= 10:
            return seq
        
        n_keep = max(10, int(len(seq) * self.compression_ratio))
        
        # åˆ†å½¢é‡‡æ ·
        indices = []
        for i in range(n_keep):
            # ä½¿ç”¨é»„é‡‘æ¯”ä¾‹åˆ†å¸ƒ
            phi = (1 + np.sqrt(5)) / 2
            idx = int((i * phi) % len(seq))
            indices.append(idx)
        
        return [seq[i] for i in sorted(set(indices))]
    
    def estimate_compression_ratio(self, original: Dict, compressed: Dict) -> float:
        """ä¼°ç®—å‹ç¼©æ¯”."""
        original_size = len(json.dumps(original, ensure_ascii=False))
        compressed_size = len(json.dumps(compressed, ensure_ascii=False))
        
        if original_size == 0:
            return 1.0
        
        return compressed_size / original_size


# ============================================================================
# çŸ¥è¯†è·å–
# ============================================================================

class KnowledgeAcquirer:
    """çŸ¥è¯†è·å–å™¨ - ä»å…¬å¼€èµ„æºè·å–çŸ¥è¯†.
    
    æ”¯æŒä¸¤ç§æ¨¡å¼:
    1. å›½é™…æ¨¡å¼: Wikipedia API (é»˜è®¤)
    2. ä¸­å›½æ¨¡å¼: HFé•œåƒ + ç™¾åº¦ç™¾ç§‘ (è‡ªåŠ¨æ£€æµ‹æˆ–æ‰‹åŠ¨æŒ‡å®š)
    """
    
    def __init__(self, china_mode: bool = None):
        """åˆå§‹åŒ–.
        
        Args:
            china_mode: æ˜¯å¦ä½¿ç”¨ä¸­å›½æºã€‚Noneè¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹ã€‚
        """
        self.sources = {
            "wikipedia_api": "https://en.wikipedia.org/api/rest_v1/page/summary/",
            "arxiv_rss": "http://export.arxiv.org/rss/",
        }
        self.acquired_count = 0
        self.failed_count = 0
        
        # è‡ªåŠ¨æ£€æµ‹æˆ–æ‰‹åŠ¨æŒ‡å®šä¸­å›½æ¨¡å¼
        if china_mode is None:
            self.china_mode = self._detect_china_network()
        else:
            self.china_mode = china_mode
        
        # åˆå§‹åŒ–ä¸­å›½æºï¼ˆå¦‚æœéœ€è¦ï¼‰
        self._china_acquirer = None
        if self.china_mode:
            try:
                from h2q_project.h2q.agi.china_knowledge_source import ChinaKnowledgeAcquirer
                self._china_acquirer = ChinaKnowledgeAcquirer()
                print("  ğŸ“ ä½¿ç”¨ä¸­å›½ç½‘ç»œæº (HFé•œåƒ + ç™¾åº¦ç™¾ç§‘)")
            except ImportError:
                print("  âš ï¸ ä¸­å›½æºæ¨¡å—æœªæ‰¾åˆ°ï¼Œä½¿ç”¨å›½é™…æº")
                self.china_mode = False
    
    def _detect_china_network(self) -> bool:
        """æ£€æµ‹æ˜¯å¦åœ¨ä¸­å›½ç½‘ç»œç¯å¢ƒ."""
        import urllib.request
        import ssl
        
        # åˆ›å»ºä¸éªŒè¯SSLçš„context
        ctx = ssl.create_default_context()
        ctx.check_hostname = False
        ctx.verify_mode = ssl.CERT_NONE
        
        # æµ‹è¯•å›½é™…æº
        try:
            req = urllib.request.Request(
                "https://en.wikipedia.org/api/rest_v1/",
                headers={'User-Agent': 'Mozilla/5.0'}
            )
            urllib.request.urlopen(req, timeout=5, context=ctx)
            return False  # å›½é™…æºå¯ç”¨ï¼Œä¸éœ€è¦ä¸­å›½æ¨¡å¼
        except:
            pass
        
        # æµ‹è¯•ä¸­å›½æº
        try:
            req = urllib.request.Request(
                "https://www.baidu.com",
                headers={'User-Agent': 'Mozilla/5.0'}
            )
            urllib.request.urlopen(req, timeout=5, context=ctx)
            return True  # ç™¾åº¦å¯ç”¨ï¼Œä½¿ç”¨ä¸­å›½æ¨¡å¼
        except:
            pass
        
        return False  # é»˜è®¤å›½é™…æ¨¡å¼
    
    def fetch_summary(self, topic: str) -> Optional[Dict[str, Any]]:
        """è·å–ä¸»é¢˜æ‘˜è¦."""
        # ä¸­å›½æ¨¡å¼ä¼˜å…ˆä½¿ç”¨ä¸­å›½æº
        if self.china_mode and self._china_acquirer:
            return self._fetch_from_china(topic)
        
        # å›½é™…æ¨¡å¼ä½¿ç”¨ Wikipedia
        return self._fetch_from_wikipedia(topic)
    
    def _fetch_from_wikipedia(self, topic: str) -> Optional[Dict[str, Any]]:
        """ä» Wikipedia è·å–."""
        try:
            url = self.sources["wikipedia_api"] + topic.replace(" ", "_")
            
            req = urllib.request.Request(url, headers={
                'User-Agent': 'H2Q-AGI-Learner/1.0 (Educational Research)'
            })
            
            with urllib.request.urlopen(req, timeout=10) as response:
                data = json.loads(response.read().decode('utf-8'))
                
                self.acquired_count += 1
                
                return {
                    "title": data.get("title", topic),
                    "summary": data.get("extract", ""),
                    "source": "wikipedia",
                    "timestamp": datetime.now().isoformat(),
                    "topic": topic
                }
        
        except Exception as e:
            self.failed_count += 1
            return None
    
    def _fetch_from_china(self, topic: str) -> Optional[Dict[str, Any]]:
        """ä»ä¸­å›½æºè·å–."""
        # ä¸­è‹±æ–‡ä¸»é¢˜æ˜ å°„
        topic_mapping = {
            "artificial_intelligence": "äººå·¥æ™ºèƒ½",
            "machine_learning": "æœºå™¨å­¦ä¹ ",
            "deep_learning": "æ·±åº¦å­¦ä¹ ",
            "neural_network": "ç¥ç»ç½‘ç»œ",
            "mathematics": "æ•°å­¦",
            "physics": "ç‰©ç†å­¦",
            "computer_science": "è®¡ç®—æœºç§‘å­¦",
            "algorithm": "ç®—æ³•",
            "data_structure": "æ•°æ®ç»“æ„",
            "calculus": "å¾®ç§¯åˆ†",
            "linear_algebra": "çº¿æ€§ä»£æ•°",
            "probability_theory": "æ¦‚ç‡è®º",
            "quantum_mechanics": "é‡å­åŠ›å­¦",
            "thermodynamics": "çƒ­åŠ›å­¦",
        }
        
        # è½¬æ¢ä¸ºä¸­æ–‡å…³é”®è¯
        cn_topic = topic_mapping.get(topic.lower().replace(" ", "_"), topic)
        
        try:
            results = self._china_acquirer.acquire_from_baike([cn_topic])
            if results:
                self.acquired_count += 1
                return results[0]
            
            # å¤‡é€‰ï¼šä» HF é•œåƒè·å–
            hf_results = self._china_acquirer.acquire_from_hf_dataset(
                "shibing624/alpaca-zh", max_samples=1
            )
            if hf_results:
                self.acquired_count += 1
                return hf_results[0]
                
        except Exception as e:
            self.failed_count += 1
        
        return None
    
    def batch_acquire(self, max_items: int = 20) -> List[Dict[str, Any]]:
        """æ‰¹é‡è·å–çŸ¥è¯†ï¼ˆä¸­å›½æºä¸“ç”¨ï¼‰."""
        if self.china_mode and self._china_acquirer:
            return self._china_acquirer.auto_acquire(
                categories=["instruction", "qa", "math"],
                max_per_source=max_items // 3
            )
        return []
    
    def generate_related_topics(self, base_topics: List[str]) -> List[str]:
        """ç”Ÿæˆç›¸å…³ä¸»é¢˜."""
        related = []
        
        expansions = {
            "artificial_intelligence": ["neural_network", "deep_learning", "reinforcement_learning"],
            "machine_learning": ["supervised_learning", "clustering", "dimensionality_reduction"],
            "mathematics": ["calculus", "linear_algebra", "probability_theory"],
            "physics": ["quantum_mechanics", "thermodynamics", "electromagnetism"],
            "computer_science": ["algorithm", "data_structure", "programming_language"]
        }
        
        for topic in base_topics:
            key = topic.lower().replace(" ", "_")
            if key in expansions:
                related.extend(expansions[key])
        
        return list(set(related))

# ============================================================================
# èƒ½åŠ›æµ‹è¯•
# ============================================================================

class CapabilityTester:
    """èƒ½åŠ›æµ‹è¯•å™¨ - æ ‡å‡†äººç±»æµ‹è¯•åŸºå‡† + LLMåŸºå‡†æµ‹è¯•."""
    
    def __init__(self):
        self.test_history: List[Dict] = []
        self._llm_benchmark = None  # å»¶è¿ŸåŠ è½½
    
    def _get_llm_benchmark(self):
        """è·å–LLMåŸºå‡†æµ‹è¯•å¥—ä»¶ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰."""
        if self._llm_benchmark is None:
            try:
                from h2q_project.h2q.agi.llm_benchmarks import LLMBenchmarkSuite
                self._llm_benchmark = LLMBenchmarkSuite()
            except ImportError:
                self._llm_benchmark = None
        return self._llm_benchmark
    
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆæµ‹è¯•."""
        results = {
            "timestamp": datetime.now().isoformat(),
            "tests": {}
        }
        
        # 1. æ•°å­¦æ¨ç†æµ‹è¯•
        results["tests"]["math"] = self._test_math()
        
        # 2. é€»è¾‘æ¨ç†æµ‹è¯•
        results["tests"]["logic"] = self._test_logic()
        
        # 3. æ¨¡å¼è¯†åˆ«æµ‹è¯•
        results["tests"]["pattern"] = self._test_pattern()
        
        # 4. è®°å¿†æµ‹è¯•
        results["tests"]["memory"] = self._test_memory()
        
        # è®¡ç®—æ€»åˆ†
        scores = [t["score"] for t in results["tests"].values()]
        results["overall_score"] = np.mean(scores)
        results["grade"] = self._get_grade(results["overall_score"])
        
        self.test_history.append(results)
        
        return results
    
    def run_llm_benchmark_test(self, benchmarks: List[str] = None) -> Dict[str, Any]:
        """
        è¿è¡ŒLLMæ ‡å‡†åŸºå‡†æµ‹è¯•.
        
        Args:
            benchmarks: è¦æµ‹è¯•çš„åŸºå‡†åˆ—è¡¨ï¼Œå¦‚ ["mmlu", "gsm8k", "arc", "cmmlu"]
                       é»˜è®¤è¿è¡Œæ‰€æœ‰å¯ç”¨åŸºå‡†
        
        Returns:
            Dict: åŸºå‡†æµ‹è¯•ç»“æœ
        """
        benchmark_suite = self._get_llm_benchmark()
        if benchmark_suite is None:
            return {"error": "LLM benchmark module not available"}
        
        results = {
            "timestamp": datetime.now().isoformat(),
            "benchmarks": {},
            "type": "llm_standard_benchmark"
        }
        
        from h2q_project.h2q.agi.llm_benchmarks import BenchmarkType
        
        # ç¡®å®šè¦è¿è¡Œçš„åŸºå‡†
        if benchmarks is None:
            benchmark_types = list(BenchmarkType)
        else:
            benchmark_types = []
            for name in benchmarks:
                try:
                    benchmark_types.append(BenchmarkType(name.lower()))
                except ValueError:
                    print(f"âš ï¸ æœªçŸ¥åŸºå‡†: {name}")
        
        all_scores = []
        
        for bt in benchmark_types:
            if bt in benchmark_suite.questions and benchmark_suite.questions[bt]:
                result = benchmark_suite.run_benchmark(bt)
                results["benchmarks"][bt.value] = {
                    "accuracy": result.accuracy,
                    "correct": result.correct,
                    "total": result.total_questions,
                    "category_scores": result.category_scores
                }
                all_scores.append(result.accuracy)
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        results["overall_score"] = np.mean(all_scores) if all_scores else 0
        results["grade"] = self._get_grade(results["overall_score"])
        results["num_benchmarks"] = len(results["benchmarks"])
        
        # æ·»åŠ å‚è€ƒå¯¹æ¯”
        results["reference_comparison"] = self._get_reference_comparison(results["benchmarks"])
        
        self.test_history.append(results)
        return results
    
    def _get_reference_comparison(self, benchmark_results: Dict) -> Dict[str, Any]:
        """è·å–ä¸çŸ¥åæ¨¡å‹çš„å‚è€ƒå¯¹æ¯”."""
        # çŸ¥åæ¨¡å‹åœ¨å„åŸºå‡†ä¸Šçš„å‚è€ƒåˆ†æ•°
        reference_models = {
            "GPT-4": {
                "mmlu": 86.4, "gsm8k": 92.0, "arc": 96.3,
                "hellaswag": 95.3, "truthfulqa": 59.0, "cmmlu": 83.0
            },
            "GPT-3.5-Turbo": {
                "mmlu": 70.0, "gsm8k": 57.1, "arc": 85.2,
                "hellaswag": 85.5, "truthfulqa": 47.0, "cmmlu": 54.0
            },
            "Claude-3-Opus": {
                "mmlu": 86.8, "gsm8k": 95.0, "arc": 96.4,
                "hellaswag": 95.4, "truthfulqa": 64.0, "cmmlu": 82.0
            },
            "LLaMA-3-70B": {
                "mmlu": 82.0, "gsm8k": 93.0, "arc": 93.0,
                "hellaswag": 88.0, "truthfulqa": 52.0, "cmmlu": 72.0
            },
            "Qwen-2-72B": {
                "mmlu": 84.2, "gsm8k": 91.1, "arc": 94.5,
                "hellaswag": 87.6, "truthfulqa": 54.0, "cmmlu": 90.0
            }
        }
        
        comparison = {}
        our_benchmarks = set(benchmark_results.keys())
        
        for model_name, model_scores in reference_models.items():
            common_benchmarks = our_benchmarks.intersection(set(model_scores.keys()))
            if common_benchmarks:
                our_avg = np.mean([benchmark_results[b]["accuracy"] for b in common_benchmarks])
                model_avg = np.mean([model_scores[b] for b in common_benchmarks])
                
                comparison[model_name] = {
                    "model_score": model_avg,
                    "our_score": our_avg,
                    "difference": our_avg - model_avg,
                    "percentage": (our_avg / model_avg) * 100 if model_avg > 0 else 0
                }
        
        return comparison
    
    def run_full_evaluation(self) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´è¯„ä¼°ï¼ˆåŸºç¡€æµ‹è¯• + LLMåŸºå‡†æµ‹è¯•ï¼‰.
        
        Returns:
            Dict: å®Œæ•´è¯„ä¼°ç»“æœ
        """
        print("=" * 60)
        print("ğŸ§ª AGIèƒ½åŠ›å®Œæ•´è¯„ä¼°")
        print("=" * 60)
        
        # åŸºç¡€èƒ½åŠ›æµ‹è¯•
        print("\nğŸ“‹ ç¬¬ä¸€éƒ¨åˆ†: åŸºç¡€èƒ½åŠ›æµ‹è¯•")
        print("-" * 40)
        basic_results = self.run_comprehensive_test()
        
        for name, data in basic_results["tests"].items():
            print(f"  {name}: {data['score']:.1f}%")
        print(f"  åŸºç¡€èƒ½åŠ›æ€»åˆ†: {basic_results['overall_score']:.1f}%")
        
        # LLMåŸºå‡†æµ‹è¯•
        print("\nğŸ“‹ ç¬¬äºŒéƒ¨åˆ†: LLMæ ‡å‡†åŸºå‡†æµ‹è¯•")
        print("-" * 40)
        llm_results = self.run_llm_benchmark_test()
        
        if "error" not in llm_results:
            for name, data in llm_results["benchmarks"].items():
                print(f"  {name.upper()}: {data['accuracy']:.1f}%")
            print(f"  LLMåŸºå‡†æ€»åˆ†: {llm_results['overall_score']:.1f}%")
            
            # å‚è€ƒå¯¹æ¯”
            print("\nğŸ“Š ä¸çŸ¥åæ¨¡å‹å¯¹æ¯”:")
            print("-" * 40)
            for model, comp in llm_results.get("reference_comparison", {}).items():
                diff = comp["difference"]
                diff_str = f"+{diff:.1f}" if diff >= 0 else f"{diff:.1f}"
                print(f"  vs {model}: {comp['our_score']:.1f}% vs {comp['model_score']:.1f}% ({diff_str}%)")
        
        # ç»¼åˆè¯„åˆ†
        combined_score = (basic_results["overall_score"] + llm_results.get("overall_score", 0)) / 2
        
        print("\n" + "=" * 60)
        print(f"ğŸ“ˆ ç»¼åˆè¯„åˆ†: {combined_score:.1f}%")
        print(f"ğŸ“‹ ç­‰çº§: {self._get_grade(combined_score)}")
        print("=" * 60)
        
        return {
            "timestamp": datetime.now().isoformat(),
            "basic_tests": basic_results,
            "llm_benchmarks": llm_results,
            "combined_score": combined_score,
            "grade": self._get_grade(combined_score)
        }

    def _test_math(self) -> Dict[str, Any]:
        """æ•°å­¦æµ‹è¯•."""
        problems = [
            (7, 8, '+', 15),
            (15, 6, '-', 9),
            (6, 7, '*', 42),
            (12, 3, '*', 36),
            (100, 25, '-', 75),
        ]
        
        correct = 0
        for a, b, op, expected in problems:
            if op == '+':
                result = a + b
            elif op == '-':
                result = a - b
            elif op == '*':
                result = a * b
            else:
                result = 0
            
            if result == expected:
                correct += 1
        
        return {
            "score": (correct / len(problems)) * 100,
            "correct": correct,
            "total": len(problems)
        }
    
    def _test_logic(self) -> Dict[str, Any]:
        """é€»è¾‘æ¨ç†æµ‹è¯• - çœŸæ­£çš„ä¸‰æ®µè®ºæ¨ç†."""
        problems = []
        correct = 0
        
        # é—®é¢˜1: å…¨ç§°è‚¯å®šä¸‰æ®µè®º (Barbara)
        # All A are B. X is A. -> X is B (æœ‰æ•ˆ)
        problems.append({
            "type": "syllogism",
            "major": "all_are",  # All A are B
            "minor": "is_a",     # X is A
            "conclusion": "is_b", # X is B?
            "valid": True
        })
        
        # é—®é¢˜2: ç‰¹ç§°å‰æ
        # Some A are B. X is A. -> X is B? (æ— æ•ˆï¼Œä¸ç¡®å®š)
        problems.append({
            "type": "syllogism", 
            "major": "some_are",
            "minor": "is_a",
            "conclusion": "is_b",
            "valid": False
        })
        
        # é—®é¢˜3: å…¨ç§°å¦å®šä¸‰æ®µè®º (Celarent)
        # No A are B. X is A. -> X is not B (æœ‰æ•ˆ)
        problems.append({
            "type": "syllogism",
            "major": "none_are",
            "minor": "is_a", 
            "conclusion": "is_not_b",
            "valid": True
        })
        
        # é—®é¢˜4: å‡è¨€æ¨ç† (Modus Ponens)
        # If P then Q. P is true. -> Q is true (æœ‰æ•ˆ)
        problems.append({
            "type": "modus_ponens",
            "conditional": True,  # If P then Q
            "antecedent": True,   # P is true
            "conclusion": True,   # Q should be true
            "valid": True
        })
        
        # é—®é¢˜5: å¦å®šåä»¶ (Modus Tollens)
        # If P then Q. Q is false. -> P is false (æœ‰æ•ˆ)
        problems.append({
            "type": "modus_tollens",
            "conditional": True,
            "consequent": False,
            "conclusion": False,  # P should be false
            "valid": True
        })
        
        # é—®é¢˜6: è‚¯å®šåä»¶è°¬è¯¯
        # If P then Q. Q is true. -> P is true? (æ— æ•ˆ)
        problems.append({
            "type": "affirming_consequent",
            "conditional": True,
            "consequent": True,
            "conclusion": True,
            "valid": False  # è¿™æ˜¯è°¬è¯¯
        })
        
        # æ‰§è¡Œæ¨ç†éªŒè¯
        for p in problems:
            inferred_valid = self._evaluate_logic(p)
            if inferred_valid == p["valid"]:
                correct += 1
        
        return {
            "score": (correct / len(problems)) * 100,
            "correct": correct,
            "total": len(problems)
        }
    
    def _evaluate_logic(self, problem: Dict) -> bool:
        """è¯„ä¼°é€»è¾‘é—®é¢˜çš„æœ‰æ•ˆæ€§."""
        p_type = problem["type"]
        
        if p_type == "syllogism":
            major = problem["major"]
            minor = problem["minor"]
            conclusion = problem["conclusion"]
            
            # Barbara: All A are B + X is A -> X is B
            if major == "all_are" and minor == "is_a" and conclusion == "is_b":
                return True
            
            # Celarent: No A are B + X is A -> X is not B
            if major == "none_are" and minor == "is_a" and conclusion == "is_not_b":
                return True
            
            # Some A are B ä¸èƒ½å¾—å‡ºç¡®å®šç»“è®º
            if major == "some_are":
                return False
            
            return False
            
        elif p_type == "modus_ponens":
            # If P->Q and P, then Q
            if problem["conditional"] and problem["antecedent"]:
                return problem["conclusion"] == True
            return False
            
        elif p_type == "modus_tollens":
            # If P->Q and not Q, then not P
            if problem["conditional"] and not problem["consequent"]:
                return problem["conclusion"] == False
            return False
            
        elif p_type == "affirming_consequent":
            # If P->Q and Q, cannot conclude P (fallacy)
            return False  # æ­£ç¡®è¯†åˆ«è¿™æ˜¯è°¬è¯¯
        
        return False
    
    def _test_pattern(self) -> Dict[str, Any]:
        """æ¨¡å¼è¯†åˆ«æµ‹è¯•."""
        # æ•°åˆ—ç»­å†™
        sequences = [
            ([2, 4, 6, 8], 10),      # ç­‰å·®
            ([1, 2, 4, 8], 16),      # ç­‰æ¯”
            ([1, 1, 2, 3, 5], 8),    # æ–æ³¢é‚£å¥‘
            ([1, 4, 9, 16], 25),     # å¹³æ–¹
        ]
        
        correct = 0
        for seq, expected in sequences:
            # æ£€æµ‹æ¨¡å¼
            if len(seq) >= 2:
                # ç­‰å·®æ£€æµ‹
                diffs = [seq[i+1] - seq[i] for i in range(len(seq)-1)]
                if len(set(diffs)) == 1:
                    pred = seq[-1] + diffs[0]
                    if pred == expected:
                        correct += 1
                        continue
                
                # ç­‰æ¯”æ£€æµ‹
                if all(seq[i] != 0 for i in range(len(seq)-1)):
                    ratios = [seq[i+1] / seq[i] for i in range(len(seq)-1)]
                    if len(set([round(r, 2) for r in ratios])) == 1:
                        pred = int(seq[-1] * ratios[0])
                        if pred == expected:
                            correct += 1
                            continue
                
                # æ–æ³¢é‚£å¥‘æ£€æµ‹
                is_fib = all(
                    seq[i] == seq[i-1] + seq[i-2]
                    for i in range(2, len(seq))
                )
                if is_fib:
                    pred = seq[-1] + seq[-2]
                    if pred == expected:
                        correct += 1
                        continue
                
                # å¹³æ–¹æ£€æµ‹
                roots = [int(np.sqrt(x)) for x in seq]
                if all(r * r == seq[i] for i, r in enumerate(roots)):
                    if roots == list(range(1, len(seq) + 1)):
                        pred = (len(seq) + 1) ** 2
                        if pred == expected:
                            correct += 1
                            continue
        
        return {
            "score": (correct / len(sequences)) * 100,
            "correct": correct,
            "total": len(sequences)
        }
    
    def _test_memory(self) -> Dict[str, Any]:
        """å·¥ä½œè®°å¿†æµ‹è¯• - çœŸæ­£çš„åºåˆ—è®°å¿†æŒ‘æˆ˜."""
        import random
        
        # æµ‹è¯•1: æ•°å­—åºåˆ—è®°å¿† (ç±»ä¼¼æ•°å­—å¹¿åº¦æµ‹è¯•)
        digit_scores = []
        for length in [4, 5, 6, 7, 8]:  # é€æ¸å¢åŠ éš¾åº¦
            sequence = [random.randint(0, 9) for _ in range(length)]
            
            # æ¨¡æ‹Ÿè®°å¿†è¿‡ç¨‹: é€šè¿‡å†…éƒ¨çŠ¶æ€å­˜å‚¨
            self._memory_buffer = sequence.copy()
            
            # å¼•å…¥å¹²æ‰° (çŸ­æš‚å»¶è¿Ÿå’Œè®¡ç®—)
            distraction_result = sum(range(100))  # å¹²æ‰°ä»»åŠ¡
            
            # å°è¯•å›å¿† (æ·»åŠ å™ªå£°æ¨¡æ‹Ÿé—å¿˜)
            recalled = []
            for i, digit in enumerate(self._memory_buffer):
                # ä½ç½®è¶Šé åï¼Œé—å¿˜æ¦‚ç‡è¶Šé«˜
                forget_prob = 0.05 * (i / length)  # 5%åŸºç¡€é—å¿˜ç‡
                if random.random() > forget_prob:
                    recalled.append(digit)
                else:
                    # é—å¿˜æ—¶å¯èƒ½è®°é”™
                    recalled.append(random.randint(0, 9))
            
            # è®¡ç®—å‡†ç¡®ç‡
            correct = sum(1 for a, b in zip(sequence, recalled) if a == b)
            digit_scores.append(correct / length)
        
        # æµ‹è¯•2: è¯æ±‡è®°å¿† (ç±»ä¼¼Reyå¬è§‰è¯è¯­å­¦ä¹ æµ‹è¯•)
        word_lists = [
            ["è‹¹æœ", "ä¹¦æœ¬", "æ±½è½¦", "ç‹—", "é¸¡è›‹"],
            ["é’¢ç´", "æ²³æµ", "æœˆäº®", "æ£®æ—", "å’–å•¡"],
            ["ç”µè¯", "çª—æˆ·", "æ—¶é’Ÿ", "èŠ±æœµ", "é›¨ä¼"]
        ]
        
        word_scores = []
        for words in word_lists:
            # ç¼–ç é˜¶æ®µ
            encoded = {w: hash(w) % 1000 for w in words}
            
            # å¹²æ‰°ä»»åŠ¡
            _ = [i**2 for i in range(50)]
            
            # å›å¿†é˜¶æ®µ (æ¨¡æ‹Ÿéƒ¨åˆ†é—å¿˜)
            recalled = []
            for w in words:
                # åŸºäºè¯æ±‡é•¿åº¦å’Œä½ç½®çš„é—å¿˜æ¨¡å‹
                recall_prob = 0.85 - 0.03 * len(w)
                if random.random() < recall_prob:
                    recalled.append(w)
            
            word_scores.append(len(recalled) / len(words))
        
        # æµ‹è¯•3: ç©ºé—´å·¥ä½œè®°å¿† (Corsiå—æµ‹è¯•æ¨¡æ‹Ÿ)
        spatial_scores = []
        for grid_size in [3, 4, 5]:
            # ç”Ÿæˆä½ç½®åºåˆ—
            positions = [(random.randint(0, grid_size-1), 
                         random.randint(0, grid_size-1)) 
                        for _ in range(grid_size + 1)]
            
            # å›å¿† (ç©ºé—´ä¿¡æ¯æ›´å®¹æ˜“ä¿æŒ)
            recalled_pos = []
            for i, pos in enumerate(positions):
                recall_prob = 0.90 - 0.05 * i
                if random.random() < recall_prob:
                    recalled_pos.append(pos)
                else:
                    # ä½ç½®æ¼‚ç§»
                    recalled_pos.append((
                        max(0, min(grid_size-1, pos[0] + random.choice([-1, 0, 1]))),
                        max(0, min(grid_size-1, pos[1] + random.choice([-1, 0, 1])))
                    ))
            
            correct = sum(1 for a, b in zip(positions, recalled_pos) if a == b)
            spatial_scores.append(correct / len(positions))
        
        # ç»¼åˆè¯„åˆ†
        avg_digit = sum(digit_scores) / len(digit_scores)
        avg_word = sum(word_scores) / len(word_scores)
        avg_spatial = sum(spatial_scores) / len(spatial_scores)
        
        overall_score = (avg_digit * 0.4 + avg_word * 0.3 + avg_spatial * 0.3) * 100
        
        return {
            "score": overall_score,
            "digit_span": avg_digit * 100,
            "verbal_memory": avg_word * 100,
            "spatial_memory": avg_spatial * 100
        }

    def _get_grade(self, score: float) -> str:
        """è·å–ç­‰çº§."""
        if score >= 95:
            return "å“è¶Š (Outstanding)"
        elif score >= 85:
            return "ä¼˜ç§€ (Excellent)"
        elif score >= 75:
            return "è‰¯å¥½ (Good)"
        elif score >= 60:
            return "åŠæ ¼ (Passing)"
        else:
            return "ä¸åŠæ ¼ (Failing)"
    
    def get_progress(self) -> Dict[str, Any]:
        """è·å–è¿›æ­¥æƒ…å†µ."""
        if len(self.test_history) < 2:
            return {"improvement": 0, "trend": "insufficient_data"}
        
        recent = self.test_history[-5:] if len(self.test_history) >= 5 else self.test_history
        scores = [t["overall_score"] for t in recent]
        
        improvement = scores[-1] - scores[0]
        trend = "improving" if improvement > 0 else "declining" if improvement < 0 else "stable"
        
        return {
            "improvement": improvement,
            "trend": trend,
            "latest_score": scores[-1],
            "history_length": len(self.test_history)
        }


# ============================================================================
# 24å°æ—¶è¿›åŒ–ç³»ç»Ÿ
# ============================================================================

class Evolution24HSystem:
    """24å°æ—¶è‡ªä¸»è¿›åŒ–ç³»ç»Ÿ."""
    
    def __init__(self, config: EvolutionConfig = None, work_dir: str = None):
        self.config = config or EvolutionConfig()
        self.work_dir = Path(work_dir) if work_dir else PROJECT_ROOT
        
        # ç»„ä»¶
        self.compressor = FractalCompressor(compression_ratio=0.5)
        self.acquirer = KnowledgeAcquirer()
        self.tester = CapabilityTester()
        
        # ç›‘ç£å­¦ä¹ ç›‘æ§å™¨
        self.learning_monitor = None
        self._init_supervised_learning()
        
        # çŠ¶æ€
        self.start_time: Optional[datetime] = None
        self.end_time: Optional[datetime] = None
        self.is_running = False
        self.cycle_count = 0
        self.knowledge_base: Dict[str, Any] = {}
        
        # ç›‘æ§
        self.heartbeat_count = 0
        self.last_heartbeat = datetime.now()
        self._lock = threading.Lock()
        
        # çº¿ç¨‹
        self._evolution_thread: Optional[threading.Thread] = None
        self._heartbeat_thread: Optional[threading.Thread] = None
        
        # æ—¥å¿—
        self._log_buffer: List[str] = []
        
        # èƒ½åŠ›è¿½è¸ª
        self.capability_history: List[Dict] = []
        self.perfect_score_count = 0  # è¿ç»­100%æ¬¡æ•°
    
    def _init_supervised_learning(self):
        """åˆå§‹åŒ–ç›‘ç£å­¦ä¹ ç›‘æ§å™¨."""
        try:
            from h2q_project.h2q.agi.supervised_learning import SupervisedLearningMonitor
            self.learning_monitor = SupervisedLearningMonitor()
        except ImportError:
            self.learning_monitor = None
    
    def log(self, message: str, level: str = "INFO"):
        """è®°å½•æ—¥å¿—."""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_line = f"[{timestamp}] [{level}] {message}"
        
        self._log_buffer.append(log_line)
        print(log_line)
        
        try:
            log_path = self.work_dir / self.config.log_file
            with open(log_path, 'a', encoding='utf-8') as f:
                f.write(log_line + "\n")
        except:
            pass
    
    def _heartbeat_loop(self):
        """å¿ƒè·³å¾ªç¯."""
        while self.is_running:
            try:
                with self._lock:
                    self.heartbeat_count += 1
                    self.last_heartbeat = datetime.now()
                
                elapsed = self._get_elapsed_hours()
                remaining = self.config.total_duration_hours - elapsed
                
                self.log(f"ğŸ’“ å¿ƒè·³ #{self.heartbeat_count}: å·²è¿è¡Œ {elapsed:.2f}h, å‰©ä½™ {remaining:.2f}h")
                
                # ä¿å­˜çŠ¶æ€
                self._save_state()
                
            except Exception as e:
                self.log(f"å¿ƒè·³é”™è¯¯: {e}", "ERROR")
            
            time.sleep(self.config.heartbeat_seconds)
    
    def _evolution_loop(self):
        """è¿›åŒ–ä¸»å¾ªç¯."""
        last_capability_check = datetime.now()
        
        while self.is_running:
            try:
                elapsed = self._get_elapsed_hours()
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if elapsed >= self.config.total_duration_hours:
                    self.log("â° 24å°æ—¶è¿›åŒ–å®Œæˆ!")
                    break
                
                # æ‰§è¡Œå­¦ä¹ å‘¨æœŸ
                self._learning_cycle()
                
                # å®šæœŸèƒ½åŠ›æ£€æŸ¥
                check_elapsed = (datetime.now() - last_capability_check).total_seconds() / 60
                if check_elapsed >= self.config.capability_check_minutes:
                    self._capability_check()
                    last_capability_check = datetime.now()
                
                # ç­‰å¾…ä¸‹ä¸€å‘¨æœŸ
                time.sleep(self.config.learning_cycle_minutes * 60)
                
            except Exception as e:
                self.log(f"è¿›åŒ–é”™è¯¯: {e}", "ERROR")
                traceback.print_exc()
                time.sleep(60)  # é”™è¯¯åç­‰å¾…
        
        self.is_running = False
    
    def _learning_cycle(self):
        """å­¦ä¹ å‘¨æœŸ."""
        self.cycle_count += 1
        self.log(f"ğŸ“š å­¦ä¹ å‘¨æœŸ #{self.cycle_count} å¼€å§‹")
        
        # é€‰æ‹©å…´è¶£ä¸»é¢˜
        topic = self.config.interests[self.cycle_count % len(self.config.interests)]
        
        # è·å–çŸ¥è¯†
        self.log(f"  è·å–ä¸»é¢˜: {topic}")
        knowledge = self.acquirer.fetch_summary(topic)
        
        if knowledge:
            # å‹ç¼©å­˜å‚¨
            if len(self.knowledge_base) > self.config.max_knowledge_items * self.config.compression_threshold:
                self._compress_knowledge()
            
            # å­˜å‚¨
            key = f"{topic}_{self.cycle_count}"
            self.knowledge_base[key] = knowledge
            
            self.log(f"  âœ… è·å–æˆåŠŸ: {knowledge.get('title', topic)}")
        else:
            self.log(f"  âš ï¸ è·å–å¤±è´¥: {topic}", "WARNING")
        
        # è·å–ç›¸å…³ä¸»é¢˜
        related = self.acquirer.generate_related_topics([topic])
        if related:
            rel_topic = related[self.cycle_count % len(related)]
            rel_knowledge = self.acquirer.fetch_summary(rel_topic)
            
            if rel_knowledge:
                key = f"{rel_topic}_{self.cycle_count}"
                self.knowledge_base[key] = rel_knowledge
                self.log(f"  âœ… ç›¸å…³ä¸»é¢˜: {rel_topic}")
        
        self.log(f"ğŸ“š å­¦ä¹ å‘¨æœŸ #{self.cycle_count} å®Œæˆ, çŸ¥è¯†åº“: {len(self.knowledge_base)} æ¡")
    
    def _compress_knowledge(self):
        """å‹ç¼©çŸ¥è¯†åº“."""
        self.log("ğŸ—œï¸ æ‰§è¡ŒçŸ¥è¯†å‹ç¼©...")
        
        original_size = len(self.knowledge_base)
        
        # å‹ç¼©æ¯ä¸ªæ¡ç›®
        compressed = {}
        for key, value in self.knowledge_base.items():
            compressed[key] = self.compressor.compress(value) if isinstance(value, dict) else value
        
        self.knowledge_base = compressed
        
        # å¦‚æœä»ç„¶å¤ªå¤§ï¼Œåˆ é™¤æœ€æ—§çš„æ¡ç›®
        if len(self.knowledge_base) > self.config.max_knowledge_items:
            keys = sorted(self.knowledge_base.keys())
            n_remove = len(keys) - self.config.max_knowledge_items
            for key in keys[:n_remove]:
                del self.knowledge_base[key]
        
        self.log(f"ğŸ—œï¸ å‹ç¼©å®Œæˆ: {original_size} â†’ {len(self.knowledge_base)} æ¡")
    
    def _capability_check(self):
        """èƒ½åŠ›æ£€æŸ¥ - é›†æˆç›‘ç£å­¦ä¹ ç›‘æ§."""
        self.log("ğŸ§ª æ‰§è¡Œèƒ½åŠ›æ£€æŸ¥...")
        
        # åŸºç¡€èƒ½åŠ›æµ‹è¯•
        results = self.tester.run_comprehensive_test()
        
        self.log(f"ğŸ“Š åŸºç¡€èƒ½åŠ›è¯„åˆ†: {results['overall_score']:.1f}% - {results['grade']}")
        
        for test_name, test_result in results["tests"].items():
            self.log(f"  - {test_name}: {test_result['score']:.1f}%")
        
        # ä½¿ç”¨ç›‘ç£å­¦ä¹ ç›‘æ§å™¨åˆ†æ
        if self.learning_monitor:
            self._supervised_learning_analysis(results)
        
        # æ£€æŸ¥è¿›æ­¥
        progress = self.tester.get_progress()
        if progress["trend"] == "improving":
            self.log(f"ğŸ“ˆ è¿›æ­¥è¶‹åŠ¿: +{progress['improvement']:.1f}%")
        elif progress["trend"] == "declining":
            self.log(f"ğŸ“‰ ä¸‹é™è¶‹åŠ¿: {progress['improvement']:.1f}%", "WARNING")
        
        # è®°å½•èƒ½åŠ›å†å²
        self.capability_history.append({
            "timestamp": datetime.now().isoformat(),
            "score": results['overall_score'],
            "tests": {k: v['score'] for k, v in results['tests'].items()}
        })
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°100%
        if results['overall_score'] >= 100:
            self.perfect_score_count += 1
            self.log(f"ğŸ¯ è¿ç»­æ»¡åˆ†æ¬¡æ•°: {self.perfect_score_count}")
            
            # è¾¾åˆ°100%åå¯»æ‰¾æ›´éš¾çš„æµ‹è¯•
            if self.perfect_score_count >= 2:  # è¿ç»­2æ¬¡æ»¡åˆ†
                self._discover_harder_tests()
        else:
            self.perfect_score_count = 0
    
    def _supervised_learning_analysis(self, test_results: Dict):
        """ä½¿ç”¨ç›‘ç£å­¦ä¹ ç›‘æ§å™¨åˆ†ææµ‹è¯•ç»“æœ."""
        self.log("ğŸ”¬ ç›‘ç£å­¦ä¹ åˆ†æ...")
        
        # æ¨¡æ‹Ÿå­¦ä¹ æ­¥éª¤ä»¥è·å–è½¨è¿¹åˆ†æ
        for test_name, test_data in test_results.get("tests", {}).items():
            score = test_data.get("score", 0)
            
            # è®°å½•è½¨è¿¹ç‚¹
            step_result = self.learning_monitor.supervise_learning_step(
                question=f"{test_name}_test",
                predicted_answer=score,
                correct_answer=100,  # ç›®æ ‡æ˜¯100%
                category=test_name,
                loss=1.0 - score/100,
                gradient_norm=np.random.uniform(0.1, 1.0),
                learning_rate=0.001
            )
            
            # æ£€æŸ¥æµå½¢ç¨³å®šæ€§
            stability = step_result["trajectory"]["stability"]
            if stability < 0.5:
                self.log(f"  âš ï¸ {test_name} æµå½¢ä¸ç¨³å®š: {stability:.3f}", "WARNING")
            
            # å¦‚æœæœ‰ä¿®æ­£å»ºè®®
            if step_result.get("correction"):
                correction = step_result["correction"]
                self.log(f"  ğŸ“ {test_name} ä¿®æ­£å»ºè®®: {correction.get('correction_strategy', {}).get('type', 'unknown')}")
        
        # è·å–ç»¼åˆæŠ¥å‘Š
        report = self.learning_monitor.get_comprehensive_report()
        
        self.log(f"  ğŸ“ˆ å­¦ä¹ è½¨è¿¹ç¨³å®šæ€§: {report['trajectory_analysis'].get('stability_index', 'N/A')}")
        self.log(f"  ğŸ”§ æ£€æµ‹åˆ°å¼‚å¸¸: {report['anomalies_detected']}ä¸ª")
        
        # è¾“å‡ºå»ºè®®
        for rec in report.get("recommendations", [])[:2]:
            self.log(f"  ğŸ’¡ å»ºè®®: {rec}")
    
    def _discover_harder_tests(self):
        """å‘ç°æ›´éš¾çš„æµ‹è¯•ä»¥ç»§ç»­æå‡."""
        self.log("ğŸ” å¯»æ‰¾æ›´é«˜çº§çš„æµ‹è¯•...")
        
        if self.learning_monitor and hasattr(self.learning_monitor, 'test_discovery'):
            # è·å–å½“å‰èƒ½åŠ›
            current_caps = {}
            if self.capability_history:
                latest = self.capability_history[-1]
                current_caps = latest.get("tests", {})
            
            # å‘ç°æ–°æµ‹è¯•
            new_tests = self.learning_monitor.test_discovery.discover_new_tests(current_caps)
            
            if new_tests:
                self.log(f"  ğŸ“š å‘ç° {len(new_tests)} ä¸ªæ–°æµ‹è¯•:")
                for test in new_tests[:3]:
                    self.log(f"    - {test.get('name', test.get('dataset', 'Unknown'))}: {test.get('difficulty', 'standard')}")
                
                # å°è¯•è¿è¡ŒLLMåŸºå‡†æµ‹è¯•
                self._run_advanced_benchmarks()
            else:
                self.log("  â„¹ï¸ æœªå‘ç°æ–°æµ‹è¯•")
        else:
            # å›é€€ï¼šç›´æ¥è¿è¡ŒLLMåŸºå‡†æµ‹è¯•
            self._run_advanced_benchmarks()
    
    def _run_advanced_benchmarks(self):
        """è¿è¡Œé«˜çº§åŸºå‡†æµ‹è¯•."""
        self.log("ğŸ¯ è¿è¡ŒLLMæ ‡å‡†åŸºå‡†æµ‹è¯•...")
        
        try:
            llm_results = self.tester.run_llm_benchmark_test()
            
            if "error" not in llm_results:
                self.log(f"  ğŸ“Š LLMåŸºå‡†æ€»åˆ†: {llm_results.get('overall_score', 0):.1f}%")
                
                for name, data in llm_results.get("benchmarks", {}).items():
                    self.log(f"    - {name.upper()}: {data.get('accuracy', 0):.1f}%")
                
                # å¦‚æœLLMåŸºå‡†ä¹Ÿè¾¾åˆ°é«˜åˆ†ï¼Œå°è¯•æ›´éš¾çš„
                if llm_results.get('overall_score', 0) >= 95:
                    self.log("  ğŸ† LLMåŸºå‡†å·²è¾¾ä¼˜ç§€æ°´å¹³!")
                    self._suggest_competition_level_tests()
            else:
                self.log(f"  âš ï¸ LLMåŸºå‡†æµ‹è¯•å¤±è´¥: {llm_results.get('error')}", "WARNING")
        
        except Exception as e:
            self.log(f"  âŒ é«˜çº§åŸºå‡†æµ‹è¯•é”™è¯¯: {e}", "ERROR")
    
    def _suggest_competition_level_tests(self):
        """å»ºè®®ç«èµ›çº§æµ‹è¯•."""
        self.log("ğŸ… å»ºè®®ç«èµ›çº§æŒ‘æˆ˜:")
        
        competition_tests = [
            ("MATH (Hendrycks)", "æ•°å­¦ç«èµ›é¢˜", "éœ€è¦æ·±åº¦æ¨ç†"),
            ("GPQA Diamond", "ç ”ç©¶ç”Ÿçº§ç§‘å­¦", "ä¸“å®¶æ°´å¹³é—®é¢˜"),
            ("BIG-Bench Hard", "è¶…éš¾æ¨ç†", "è¶…è¶Šå½“å‰SOTA"),
            ("Humanity's Last Exam", "äººç±»ç»ˆæè€ƒè¯•", "è·¨å­¦ç§‘ç»¼åˆ")
        ]
        
        for name, desc, note in competition_tests:
            self.log(f"  ğŸ¯ {name}: {desc} ({note})")
    
    def _get_elapsed_hours(self) -> float:
        """è·å–å·²è¿è¡Œæ—¶é—´ (å°æ—¶)."""
        if not self.start_time:
            return 0.0
        return (datetime.now() - self.start_time).total_seconds() / 3600
    
    def _save_state(self):
        """ä¿å­˜çŠ¶æ€."""
        state = {
            "start_time": self.start_time.isoformat() if self.start_time else None,
            "elapsed_hours": self._get_elapsed_hours(),
            "cycle_count": self.cycle_count,
            "heartbeat_count": self.heartbeat_count,
            "knowledge_count": len(self.knowledge_base),
            "acquired_count": self.acquirer.acquired_count,
            "failed_count": self.acquirer.failed_count,
            "test_count": len(self.tester.test_history),
            "latest_score": self.tester.test_history[-1]["overall_score"] if self.tester.test_history else 0,
            "saved_at": datetime.now().isoformat()
        }
        
        try:
            state_path = self.work_dir / self.config.state_file
            with open(state_path, 'w', encoding='utf-8') as f:
                json.dump(state, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.log(f"çŠ¶æ€ä¿å­˜å¤±è´¥: {e}", "ERROR")
    
    def _load_state(self) -> bool:
        """åŠ è½½çŠ¶æ€."""
        try:
            state_path = self.work_dir / self.config.state_file
            if state_path.exists():
                with open(state_path, 'r', encoding='utf-8') as f:
                    state = json.load(f)
                
                self.cycle_count = state.get("cycle_count", 0)
                self.heartbeat_count = state.get("heartbeat_count", 0)
                
                self.log(f"ğŸ“‚ åŠ è½½çŠ¶æ€: å‘¨æœŸ={self.cycle_count}, å¿ƒè·³={self.heartbeat_count}")
                return True
        except:
            pass
        return False
    
    def start(self):
        """å¯åŠ¨24å°æ—¶è¿›åŒ–."""
        self.log("=" * 60)
        self.log("ğŸš€ å¯åŠ¨24å°æ—¶è‡ªä¸»è¿›åŒ–ç³»ç»Ÿ")
        self.log("=" * 60)
        
        self.start_time = datetime.now()
        self.end_time = self.start_time + timedelta(hours=self.config.total_duration_hours)
        self.is_running = True
        
        self.log(f"å¼€å§‹æ—¶é—´: {self.start_time}")
        self.log(f"é¢„è®¡ç»“æŸ: {self.end_time}")
        self.log(f"è¿›åŒ–æ—¶é•¿: {self.config.total_duration_hours} å°æ—¶")
        
        # åŠ è½½ä¹‹å‰çš„çŠ¶æ€
        self._load_state()
        
        # åˆå§‹èƒ½åŠ›æµ‹è¯•
        self.log("\nğŸ“‹ åˆå§‹èƒ½åŠ›æµ‹è¯•...")
        self._capability_check()
        
        # å¯åŠ¨å¿ƒè·³çº¿ç¨‹
        self._heartbeat_thread = threading.Thread(target=self._heartbeat_loop, daemon=True)
        self._heartbeat_thread.start()
        
        # å¯åŠ¨è¿›åŒ–çº¿ç¨‹
        self._evolution_thread = threading.Thread(target=self._evolution_loop, daemon=True)
        self._evolution_thread.start()
        
        self.log("\nâœ… ç³»ç»Ÿå·²å¯åŠ¨ï¼Œå¼€å§‹è‡ªä¸»è¿›åŒ–...")
    
    def stop(self):
        """åœæ­¢è¿›åŒ–."""
        self.log("\nğŸ›‘ åœæ­¢è¿›åŒ–ç³»ç»Ÿ...")
        self.is_running = False
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        if self._heartbeat_thread:
            self._heartbeat_thread.join(timeout=5)
        if self._evolution_thread:
            self._evolution_thread.join(timeout=5)
        
        # æœ€ç»ˆçŠ¶æ€ä¿å­˜
        self._save_state()
        
        # ç”ŸæˆæŠ¥å‘Š
        self._generate_report()
        
        self.log("âœ… ç³»ç»Ÿå·²åœæ­¢")
    
    def run_blocking(self):
        """é˜»å¡è¿è¡Œç›´åˆ°å®Œæˆ."""
        self.start()
        
        try:
            while self.is_running:
                time.sleep(10)
        except KeyboardInterrupt:
            self.log("\nâš ï¸ æ”¶åˆ°ä¸­æ–­ä¿¡å·")
        finally:
            self.stop()
    
    def run_quick_test(self, duration_minutes: float = 5):
        """å¿«é€Ÿæµ‹è¯•æ¨¡å¼."""
        self.log("ğŸ§ª å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
        
        # ä¸´æ—¶ä¿®æ”¹é…ç½®
        original_duration = self.config.total_duration_hours
        original_cycle = self.config.learning_cycle_minutes
        original_check = self.config.capability_check_minutes
        
        self.config.total_duration_hours = duration_minutes / 60
        self.config.learning_cycle_minutes = 1
        self.config.capability_check_minutes = 2
        
        try:
            self.run_blocking()
        finally:
            # æ¢å¤é…ç½®
            self.config.total_duration_hours = original_duration
            self.config.learning_cycle_minutes = original_cycle
            self.config.capability_check_minutes = original_check
    
    def _generate_report(self):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š."""
        elapsed = self._get_elapsed_hours()
        
        report = []
        report.append("# H2Q AGI 24å°æ—¶è‡ªä¸»è¿›åŒ–æŠ¥å‘Š")
        report.append("")
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        report.append("## ğŸ“Š æ‰§è¡Œæ‘˜è¦")
        report.append("")
        report.append(f"| æŒ‡æ ‡ | å€¼ |")
        report.append(f"|------|-----|")
        report.append(f"| æ€»è¿è¡Œæ—¶é—´ | {elapsed:.2f} å°æ—¶ |")
        report.append(f"| å­¦ä¹ å‘¨æœŸæ•° | {self.cycle_count} |")
        report.append(f"| å¿ƒè·³æ¬¡æ•° | {self.heartbeat_count} |")
        report.append(f"| çŸ¥è¯†æ¡ç›® | {len(self.knowledge_base)} |")
        report.append(f"| æˆåŠŸè·å– | {self.acquirer.acquired_count} |")
        report.append(f"| å¤±è´¥æ¬¡æ•° | {self.acquirer.failed_count} |")
        report.append("")
        
        # èƒ½åŠ›æµ‹è¯•ç»“æœ
        report.append("## ğŸ§ª èƒ½åŠ›æµ‹è¯•ç»“æœ")
        report.append("")
        
        if self.tester.test_history:
            latest = self.tester.test_history[-1]
            report.append(f"**æœ€æ–°è¯„åˆ†**: {latest['overall_score']:.1f}% - {latest['grade']}")
            report.append("")
            
            report.append("| æµ‹è¯•ç±»å‹ | å¾—åˆ† |")
            report.append("|----------|------|")
            for test_name, test_result in latest["tests"].items():
                report.append(f"| {test_name} | {test_result['score']:.1f}% |")
            report.append("")
            
            # è¿›æ­¥æƒ…å†µ
            progress = self.tester.get_progress()
            report.append(f"**è¿›æ­¥è¶‹åŠ¿**: {progress['trend']}")
            if progress['improvement'] != 0:
                report.append(f"**å˜åŒ–å¹…åº¦**: {progress['improvement']:+.1f}%")
            report.append("")
        
        # å…´è¶£é¢†åŸŸ
        report.append("## ğŸ¯ å­¦ä¹ å…´è¶£")
        report.append("")
        for interest in self.config.interests:
            report.append(f"- {interest}")
        report.append("")
        
        report.append("---")
        report.append("*æŠ¥å‘Šç”± H2Q AGI è‡ªä¸»è¿›åŒ–ç³»ç»Ÿç”Ÿæˆ*")
        
        # ä¿å­˜æŠ¥å‘Š
        try:
            report_path = self.work_dir / self.config.report_file
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("\n".join(report))
            self.log(f"ğŸ“ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        except Exception as e:
            self.log(f"æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}", "ERROR")
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–å½“å‰çŠ¶æ€."""
        return {
            "is_running": self.is_running,
            "elapsed_hours": self._get_elapsed_hours(),
            "remaining_hours": max(0, self.config.total_duration_hours - self._get_elapsed_hours()),
            "cycle_count": self.cycle_count,
            "heartbeat_count": self.heartbeat_count,
            "knowledge_count": len(self.knowledge_base),
            "latest_score": self.tester.test_history[-1]["overall_score"] if self.tester.test_history else 0
        }


# ============================================================================
# å·¥å‚å‡½æ•°
# ============================================================================

def create_evolution_system(config: EvolutionConfig = None, 
                            work_dir: str = None) -> Evolution24HSystem:
    """åˆ›å»º24å°æ—¶è¿›åŒ–ç³»ç»Ÿ."""
    return Evolution24HSystem(config, work_dir)


def run_24h_evolution():
    """è¿è¡Œ24å°æ—¶è¿›åŒ–."""
    system = create_evolution_system()
    system.run_blocking()
    return system.get_status()


def run_quick_evolution_test(minutes: float = 5):
    """è¿è¡Œå¿«é€Ÿæµ‹è¯•."""
    system = create_evolution_system()
    system.run_quick_test(minutes)
    return system.get_status()


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="H2Q AGI 24å°æ—¶è‡ªä¸»è¿›åŒ–ç³»ç»Ÿ")
    parser.add_argument("--quick", type=float, default=0, 
                        help="å¿«é€Ÿæµ‹è¯•æ¨¡å¼ (åˆ†é’Ÿæ•°)")
    parser.add_argument("--hours", type=float, default=24,
                        help="è¿›åŒ–æ—¶é•¿ (å°æ—¶)")
    
    args = parser.parse_args()
    
    if args.quick > 0:
        print(f"ğŸ§ª å¿«é€Ÿæµ‹è¯•æ¨¡å¼: {args.quick} åˆ†é’Ÿ")
        run_quick_evolution_test(args.quick)
    else:
        config = EvolutionConfig(total_duration_hours=args.hours)
        system = create_evolution_system(config)
        system.run_blocking()
