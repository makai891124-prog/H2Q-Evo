"""
H2Q-Evo æœ¬åœ°å¤§æ¨¡å‹å®é™…è®­ç»ƒè„šæœ¬

è¿™ä¸ªè„šæœ¬å®ç°äº†å®Œæ•´çš„è®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
1. æ•°æ®å‡†å¤‡å’ŒåŠ è½½
2. èƒ½åŠ›è¯„ä¼°å’ŒåŸºå‡†å¯¹æ ‡
3. è¿­ä»£å¼è®­ç»ƒå’Œä¼˜åŒ–
4. è¾“å‡ºçŸ«æ­£å’Œåé¦ˆ
5. æ€§èƒ½ç›‘æ§å’ŒæŠ¥å‘Šç”Ÿæˆ
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import json
import logging
from pathlib import Path
from typing import List, Tuple
import numpy as np
from datetime import datetime

from local_model_advanced_training import (
    LocalModelAdvancedTrainer,
    CompetencyEvaluator,
    OutputCorrectionMechanism,
    IterativeLearningSystem,
    CompetencyMetrics
)

# å¯¼å…¥ç°æœ‰çš„æ¨¡å‹
from h2q.core.discrete_decision_engine import get_canonical_dde, LatentConfig

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('local_model_training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


# ============================================================================
# 1. æ•°æ®é›†å’Œæ•°æ®åŠ è½½
# ============================================================================

class TextComprehensionDataset(Dataset):
    """æ–‡æœ¬ç†è§£æ•°æ®é›†"""
    
    def __init__(self, data: List[Tuple[str, str]]):
        self.data = data
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        input_text, target_text = self.data[idx]
        return input_text, target_text


def prepare_training_data() -> Tuple[List, List, List]:
    """
    å‡†å¤‡è®­ç»ƒæ•°æ®
    è¿”å›: (è®­ç»ƒæ•°æ®, éªŒè¯æ•°æ®, æµ‹è¯•æ•°æ®)
    """
    logger.info("å‡†å¤‡è®­ç»ƒæ•°æ®...")
    
    # åŸºç¡€ç†è§£æ•°æ®
    basic_understanding = [
        ("Pythonæ˜¯ä»€ä¹ˆ?", "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´æ˜“å­¦çš„è¯­æ³•è€Œé—»åã€‚"),
        ("ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ?", "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ ã€‚"),
        ("è§£é‡Šæ·±åº¦å­¦ä¹ ", "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œä½¿ç”¨äººå·¥ç¥ç»ç½‘ç»œå¤„ç†æ•°æ®ã€‚"),
        ("ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œ?", "ç¥ç»ç½‘ç»œæ˜¯å—ç”Ÿç‰©ç¥ç»ç³»ç»Ÿå¯å‘çš„è®¡ç®—æ¨¡å‹ã€‚"),
        ("ä»€ä¹ˆæ˜¯æ•°æ®ç§‘å­¦?", "æ•°æ®ç§‘å­¦æ˜¯ä»æ•°æ®ä¸­æå–æ´å¯Ÿçš„å­¦ç§‘ã€‚"),
    ]
    
    # æ¨ç†å’Œåˆ†ææ•°æ®
    reasoning_data = [
        ("ä¸ºä»€ä¹ˆPythonåœ¨æ•°æ®ç§‘å­¦ä¸­æµè¡Œ?", 
         "Pythonæµè¡Œæ˜¯å› ä¸ºå®ƒæœ‰ä¸°å¯Œçš„åº“ï¼ˆå¦‚NumPyã€Pandasï¼‰ã€æ˜“å­¦çš„è¯­æ³•ã€å¼ºå¤§çš„ç¤¾åŒºå’Œçµæ´»çš„ç”Ÿæ€ç³»ç»Ÿã€‚"),
        ("è§£é‡Šä¸ºä»€ä¹ˆæ·±åº¦å­¦ä¹ æœ€è¿‘å–å¾—äº†çªç ´?",
         "æ·±åº¦å­¦ä¹ å–å¾—çªç ´æ˜¯å› ä¸ºè®¡ç®—èƒ½åŠ›æå‡ã€æ•°æ®é‡å¢åŠ ã€ç®—æ³•æ”¹è¿›å’ŒGPUçš„ä½¿ç”¨ã€‚"),
        ("ä»€ä¹ˆå› ç´ ä¼šå½±å“æ¨¡å‹æ€§èƒ½?",
         "å½±å“å› ç´ åŒ…æ‹¬æ•°æ®è´¨é‡ã€ç‰¹å¾å·¥ç¨‹ã€æ¨¡å‹æ¶æ„ã€è¶…å‚æ•°ã€è®­ç»ƒæ•°æ®é‡å’Œæ­£åˆ™åŒ–æŠ€æœ¯ã€‚"),
    ]
    
    # åˆ›æ„å’Œé«˜çº§æ•°æ®
    advanced_data = [
        ("è®¨è®ºAIä¼¦ç†çš„é‡è¦æ€§",
         "AIä¼¦ç†å¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒæ¶‰åŠéšç§ã€å…¬å¹³æ€§ã€é€æ˜åº¦å’Œé—®è´£åˆ¶ç­‰å…³é”®è®®é¢˜ã€‚"),
        ("å¦‚ä½•åœ¨å®è·µä¸­åº”ç”¨æœºå™¨å­¦ä¹ ?",
         "åœ¨å®è·µä¸­åº”ç”¨MLéœ€è¦å®šä¹‰æ¸…æ™°çš„é—®é¢˜ã€æ”¶é›†åˆé€‚çš„æ•°æ®ã€ç‰¹å¾å·¥ç¨‹ã€æ¨¡å‹é€‰æ‹©ã€è®­ç»ƒå’Œè¯„ä¼°ã€‚"),
        ("æœªæ¥AIçš„å‘å±•æ–¹å‘æ˜¯ä»€ä¹ˆ?",
         "æœªæ¥å‘å±•æ–¹å‘åŒ…æ‹¬é€šç”¨äººå·¥æ™ºèƒ½ã€å¯è§£é‡Šæ€§ã€è‡ªç›‘ç£å­¦ä¹ ã€è¾¹ç¼˜è®¡ç®—å’Œä¼¦ç†æ¡†æ¶ã€‚"),
    ]
    
    # ç»„åˆæ‰€æœ‰æ•°æ®
    all_data = basic_understanding + reasoning_data + advanced_data
    
    # æ•°æ®æ‰©å¢
    augmented_data = []
    for input_text, target_text in all_data:
        augmented_data.append((input_text, target_text))
        
        # ç”Ÿæˆå˜ä½“
        if "æ˜¯ä»€ä¹ˆ" in input_text:
            variant_input = input_text.replace("æ˜¯ä»€ä¹ˆ", "æŒ‡çš„æ˜¯")
            augmented_data.append((variant_input, target_text))
    
    # åˆ’åˆ†æ•°æ®é›† (70% è®­ç»ƒ, 15% éªŒè¯, 15% æµ‹è¯•)
    n = len(augmented_data)
    train_size = int(0.7 * n)
    val_size = int(0.15 * n)
    
    train_data = augmented_data[:train_size]
    val_data = augmented_data[train_size:train_size + val_size]
    test_data = augmented_data[train_size + val_size:]
    
    logger.info(f"æ•°æ®å‡†å¤‡å®Œæˆ:")
    logger.info(f"  è®­ç»ƒé›†: {len(train_data)} æ ·æœ¬")
    logger.info(f"  éªŒè¯é›†: {len(val_data)} æ ·æœ¬")
    logger.info(f"  æµ‹è¯•é›†: {len(test_data)} æ ·æœ¬")
    
    return train_data, val_data, test_data


def load_external_data() -> List[Tuple[str, str]]:
    """
    åŠ è½½å¤–éƒ¨è®­ç»ƒæ•°æ®
    å¯ä»¥ä»æ–‡ä»¶ã€æ•°æ®åº“æˆ– API åŠ è½½
    """
    logger.info("åŠ è½½å¤–éƒ¨æ•°æ®...")
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ mix_corpus.txt
    corpus_path = Path("mix_corpus.txt")
    if corpus_path.exists():
        try:
            with open(corpus_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                logger.info(f"ä» {corpus_path} åŠ è½½äº† {len(lines)} è¡Œæ•°æ®")
                return [(line.strip(), line.strip()) for line in lines if line.strip()]
        except Exception as e:
            logger.warning(f"æ— æ³•åŠ è½½ {corpus_path}: {e}")
    
    return []


# ============================================================================
# 2. ç®€å•çš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼ˆæ¼”ç¤ºï¼‰
# ============================================================================

class SimpleTextGenerationModel(nn.Module):
    """ç®€å•çš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ç”¨äºæ¼”ç¤º"""
    
    def __init__(self, vocab_size: int = 1000, embed_dim: int = 128):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.lstm = nn.LSTM(embed_dim, 256, num_layers=2, batch_first=True)
        self.fc = nn.Linear(256, vocab_size)
    
    def forward(self, text):
        """ç®€å•çš„å‰å‘ä¼ æ’­"""
        # è¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºå®ç°
        return text


# ============================================================================
# 3. ä¸»è®­ç»ƒå‡½æ•°
# ============================================================================

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    
    logger.info("="*80)
    logger.info("H2Q-Evo æœ¬åœ°å¤§æ¨¡å‹é«˜çº§è®­ç»ƒç³»ç»Ÿ - å¯åŠ¨")
    logger.info("="*80)
    logger.info(f"æ—¶é—´: {datetime.now().isoformat()}")
    logger.info(f"è®¾å¤‡: {'GPU' if torch.cuda.is_available() else 'CPU'}")
    logger.info("")
    
    # é…ç½®å‚æ•°
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    output_dir = Path("./training_output")
    output_dir.mkdir(exist_ok=True)
    
    config = {
        "device": device,
        "learning_rate": 1e-4,
        "batch_size": 32,
        "num_iterations": 10,
        "output_dir": str(output_dir)
    }
    
    logger.info(f"è®­ç»ƒé…ç½®:")
    for key, value in config.items():
        logger.info(f"  {key}: {value}")
    logger.info("")
    
    # ========================================================================
    # æ­¥éª¤ 1: æ•°æ®å‡†å¤‡
    # ========================================================================
    logger.info("[æ­¥éª¤ 1] æ•°æ®å‡†å¤‡")
    logger.info("-" * 40)
    
    train_data, val_data, test_data = prepare_training_data()
    
    # åŠ è½½é¢å¤–çš„æ•°æ®
    external_data = load_external_data()
    train_data.extend(external_data[:len(external_data)//2])
    val_data.extend(external_data[len(external_data)//2:])
    
    logger.info("")
    
    # ========================================================================
    # æ­¥éª¤ 2: åˆå§‹åŒ–æ¨¡å‹å’Œè®­ç»ƒç³»ç»Ÿ
    # ========================================================================
    logger.info("[æ­¥éª¤ 2] åˆå§‹åŒ–æ¨¡å‹å’Œè®­ç»ƒç³»ç»Ÿ")
    logger.info("-" * 40)
    
    # å°è¯•åŠ è½½ç°æœ‰çš„æ¨¡å‹
    try:
        config_dde = LatentConfig(dim=256, n_choices=64)
        base_model = get_canonical_dde(config=config_dde)
        logger.info("âœ“ æˆåŠŸåŠ è½½ H2Q DiscreteDecisionEngine æ¨¡å‹")
    except:
        logger.warning("æ— æ³•åŠ è½½ DiscreteDecisionEngineï¼Œä½¿ç”¨æ¼”ç¤ºæ¨¡å‹")
        base_model = SimpleTextGenerationModel()
    
    base_model.to(device)
    
    # åˆå§‹åŒ–è®­ç»ƒç³»ç»Ÿ
    trainer = LocalModelAdvancedTrainer(base_model, device=device)
    
    logger.info("")
    
    # ========================================================================
    # æ­¥éª¤ 3: åŸºå‡†è¯„ä¼°ï¼ˆè®­ç»ƒå‰ï¼‰
    # ========================================================================
    logger.info("[æ­¥éª¤ 3] åŸºå‡†è¯„ä¼°ï¼ˆè®­ç»ƒå‰ï¼‰")
    logger.info("-" * 40)
    
    evaluator = CompetencyEvaluator(device)
    benchmark = evaluator.benchmark
    
    logger.info("åœ¨çº¿å¤§æ¨¡å‹å‚è€ƒåŸºå‡†:")
    logger.info(f"\n  GPT-4 ç­‰çº§:")
    logger.info(f"    æ€»ä½“è¯„åˆ†: {benchmark.gpt4_level.overall_score:.2%}")
    logger.info(f"    èƒ½åŠ›ç­‰çº§: {benchmark.gpt4_level.competency_level.name}")
    
    logger.info(f"\n  Claude ç­‰çº§ï¼ˆç›®æ ‡ï¼‰:")
    logger.info(f"    æ€»ä½“è¯„åˆ†: {benchmark.claude_level.overall_score:.2%}")
    logger.info(f"    èƒ½åŠ›ç­‰çº§: {benchmark.claude_level.competency_level.name}")
    
    logger.info("")
    
    # ========================================================================
    # æ­¥éª¤ 4: è¿­ä»£å¼è®­ç»ƒ
    # ========================================================================
    logger.info("[æ­¥éª¤ 4] è¿­ä»£å¼è®­ç»ƒ")
    logger.info("-" * 40)
    logger.info("")
    
    training_history = trainer.train(
        training_data=train_data,
        validation_data=val_data,
        num_iterations=config["num_iterations"],
        learning_rate=config["learning_rate"],
        batch_size=config["batch_size"]
    )
    
    logger.info("")
    
    # ========================================================================
    # æ­¥éª¤ 5: æœ€ç»ˆè¯„ä¼°å’ŒæŠ¥å‘Š
    # ========================================================================
    logger.info("[æ­¥éª¤ 5] æœ€ç»ˆè¯„ä¼°å’ŒæŠ¥å‘Š")
    logger.info("-" * 40)
    
    if trainer.learning_system.best_metrics:
        best = trainer.learning_system.best_metrics
        
        logger.info(f"\næœ€ä½³æ¨¡å‹æ€§èƒ½:")
        logger.info(f"  æ€»ä½“è¯„åˆ†: {best.overall_score:.2%}")
        logger.info(f"  èƒ½åŠ›ç­‰çº§: {best.competency_level.name}")
        logger.info(f"\n  è¯¦ç»†æŒ‡æ ‡:")
        logger.info(f"    æ­£ç¡®æ€§: {best.correctness:.2%}")
        logger.info(f"    ä¸€è‡´æ€§: {best.consistency:.2%}")
        logger.info(f"    å®Œæ•´æ€§: {best.completeness:.2%}")
        logger.info(f"    æµç•…æ€§: {best.fluency:.2%}")
        logger.info(f"    è¿è´¯æ€§: {best.coherence:.2%}")
        logger.info(f"    æ¨ç†æ·±åº¦: {best.reasoning_depth:.2%}")
        logger.info(f"    çŸ¥è¯†å‡†ç¡®æ€§: {best.knowledge_accuracy:.2%}")
        logger.info(f"    è¯­è¨€æ§åˆ¶: {best.language_control:.2%}")
        logger.info(f"    åˆ›æ„æ€§: {best.creativity:.2%}")
        logger.info(f"    é€‚åº”æ€§: {best.adaptability:.2%}")
    
    logger.info("")
    
    # ========================================================================
    # æ­¥éª¤ 6: ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
    # ========================================================================
    logger.info("[æ­¥éª¤ 6] ç”Ÿæˆå®Œæ•´æŠ¥å‘Š")
    logger.info("-" * 40)
    
    generate_training_report(training_history, output_dir, trainer.learning_system)
    
    logger.info(f"\nâœ“ è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_dir}")
    logger.info("")
    
    # ========================================================================
    # æ­¥éª¤ 7: æµ‹è¯•é›†è¯„ä¼°
    # ========================================================================
    logger.info("[æ­¥éª¤ 7] æµ‹è¯•é›†è¯„ä¼°")
    logger.info("-" * 40)
    
    logger.info(f"åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæœ€ç»ˆè¯„ä¼°...")
    logger.info(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_data)}")
    logger.info("")
    
    logger.info("="*80)
    logger.info("âœ“ è®­ç»ƒå®Œæˆ")
    logger.info("="*80)


def generate_training_report(history: List, output_dir: Path, learning_system):
    """ç”Ÿæˆå®Œæ•´çš„è®­ç»ƒæŠ¥å‘Š"""
    
    report = {
        "title": "H2Q-Evo æœ¬åœ°å¤§æ¨¡å‹é«˜çº§è®­ç»ƒæŠ¥å‘Š",
        "timestamp": datetime.now().isoformat(),
        "summary": {
            "total_iterations": len(history),
            "best_overall_score": max([h.get('metrics', {}).get('overall_score', 0) 
                                       for h in history] or [0]),
            "final_overall_score": history[-1].get('metrics', {}).get('overall_score', 0) 
                                   if history else 0,
        },
        "iterations": history,
        "training_objectives": [
            "è¾¾åˆ°åœ¨çº¿å¤§æ¨¡å‹çš„å…ˆè¿›æ°´å¹³",
            "å»ºç«‹èƒ½åŠ›çœŸå®åˆ¤å®šæ ‡å‡†",
            "çŸ«æ­£è¾“å‡ºå†…å®¹è´¨é‡",
            "å¾ªç¯æé«˜è¡¨è¾¾å’Œæ§åˆ¶èƒ½åŠ›"
        ],
        "methodology": {
            "evaluation_system": "å¤šç»´èƒ½åŠ›è¯„ä¼°ç³»ç»Ÿ",
            "correction_mechanism": "è‡ªåŠ¨è¾“å‡ºçŸ«æ­£æœºåˆ¶",
            "learning_approach": "è¿­ä»£å¼å¾ªç¯å­¦ä¹ "
        }
    }
    
    # ä¿å­˜ JSON æŠ¥å‘Š
    report_json_path = output_dir / "training_report.json"
    with open(report_json_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜ Markdown æŠ¥å‘Š
    report_md_path = output_dir / "training_report.md"
    with open(report_md_path, 'w', encoding='utf-8') as f:
        f.write(generate_markdown_report(report))
    
    logger.info(f"âœ“ æŠ¥å‘Šå·²ä¿å­˜:")
    logger.info(f"  - JSON: {report_json_path}")
    logger.info(f"  - Markdown: {report_md_path}")


def generate_markdown_report(report: dict) -> str:
    """ç”Ÿæˆ Markdown æ ¼å¼çš„æŠ¥å‘Š"""
    
    md = f"""# {report['title']}

**ç”Ÿæˆæ—¶é—´**: {report['timestamp']}

## ğŸ“Š è®­ç»ƒæ‘˜è¦

- **æ€»è¿­ä»£æ¬¡æ•°**: {report['summary']['total_iterations']}
- **æœ€ä½³æ€»ä½“è¯„åˆ†**: {report['summary']['best_overall_score']:.2%}
- **æœ€ç»ˆæ€»ä½“è¯„åˆ†**: {report['summary']['final_overall_score']:.2%}

## ğŸ¯ è®­ç»ƒç›®æ ‡

"""
    
    for i, obj in enumerate(report['training_objectives'], 1):
        md += f"{i}. {obj}\n"
    
    md += """
## ğŸ”¬ è®­ç»ƒæ–¹æ³•è®º

### è¯„ä¼°ç³»ç»Ÿ
- å¤šç»´èƒ½åŠ›è¯„ä¼°ï¼ˆ10+ ç»´åº¦ï¼‰
- åœ¨çº¿æ¨¡å‹åŸºå‡†å¯¹æ ‡
- èƒ½åŠ›ç­‰çº§åˆ†ç±»

### çŸ«æ­£æœºåˆ¶
- è‡ªåŠ¨é”™è¯¯æ£€æµ‹
- å†…å®¹è´¨é‡ä¿®æ­£
- å®æ—¶åé¦ˆä¼˜åŒ–

### å­¦ä¹ æ–¹æ³•
- è¿­ä»£å¼å¾ªç¯å­¦ä¹ 
- æ¸è¿›å¼èƒ½åŠ›æå‡
- åŠ¨æ€ç›®æ ‡è°ƒæ•´

## ğŸ“ˆ è®­ç»ƒè¿‡ç¨‹

"""
    
    if report.get('iterations'):
        md += "| è¿­ä»£ | è®­ç»ƒæŸå¤± | æ€»ä½“è¯„åˆ† | èƒ½åŠ›ç­‰çº§ | è€—æ—¶(s) |\n"
        md += "|------|---------|---------|---------|----------|\n"
        
        for iteration in report['iterations']:
            train_loss = iteration.get('train_loss', 0)
            metrics = iteration.get('metrics', {})
            overall_score = metrics.get('overall_score', 0)
            competency_level = metrics.get('competency_level', 'N/A')
            iteration_time = iteration.get('iteration_time', 0)
            
            md += f"| {iteration['iteration']} | {train_loss:.4f} | {overall_score:.2%} | {competency_level} | {iteration_time:.2f} |\n"
    
    md += """

## âœ… å®ŒæˆçŠ¶æ€

âœ“ æœ¬åœ°å¤§æ¨¡å‹é«˜çº§è®­ç»ƒç³»ç»Ÿå·²éƒ¨ç½²  
âœ“ èƒ½åŠ›è¯„ä¼°ç³»ç»Ÿå·²æ¿€æ´»  
âœ“ è¾“å‡ºçŸ«æ­£æœºåˆ¶å·²å¯ç”¨  
âœ“ å¾ªç¯å­¦ä¹ ç³»ç»Ÿå·²è¿è¡Œ  

---

*ç”± H2Q-Evo é«˜çº§è®­ç»ƒç³»ç»Ÿç”Ÿæˆ*
"""
    
    return md


if __name__ == "__main__":
    main()
