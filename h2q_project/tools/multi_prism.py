# tools/multi_prism.py

import torch
import torch.nn.functional as F
from transformers import AutoModel
import os

# --- [ä¸­å›½åŒºåŠ é€Ÿ] ---
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

def generate_crystals():
    model_name = "gpt2"
    dims = [256, 64, 16] # æˆ‘ä»¬è¦æµ‹è¯•çš„ä¸‰ä¸ªç»´åº¦
    
    print(f"ğŸ”® æ­£åœ¨åŠ è½½åŸºåº§æ¨¡å‹: {model_name} ...")
    hf_model = AutoModel.from_pretrained(model_name)
    embeddings = hf_model.get_input_embeddings().weight.detach()
    
    print("ğŸ“‰ å¼€å§‹å¤šç»´ SVD æå–...")
    # ä¸€æ¬¡æ€§è®¡ç®—æœ€å¤§çš„ SVD (256)ï¼Œç„¶ååˆ‡ç‰‡å³å¯
    U, S, V = torch.svd_lowrank(embeddings, q=256)
    
    for d in dims:
        print(f"   âš¡ï¸ å¤„ç†ç»´åº¦: {d} ...")
        # åˆ‡ç‰‡æå–å‰ d ä¸ªç‰¹å¾
        compressed = U[:, :d] @ torch.diag(S[:d])
        
        # å°„å½±å½’ä¸€åŒ–
        projected = F.normalize(compressed, p=2, dim=-1)
        
        crystal = {
            "source_model": model_name,
            "dim": d,
            "geometric_embeddings": projected,
            "projection_matrix": V[:, :d]
        }
        
        save_path = f"h2q_memory_{d}.pt"
        torch.save(crystal, save_path)
        print(f"      âœ… å·²ä¿å­˜: {save_path}")

if __name__ == "__main__":
    generate_crystals()