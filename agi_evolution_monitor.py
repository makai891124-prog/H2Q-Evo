#!/usr/bin/env python3
"""
H2Q-Evo AGIè¿›åŒ–ç›‘æ§å’Œå¯è§†åŒ–ç³»ç»Ÿ
å®æ—¶ç›‘æ§AGIç³»ç»Ÿçš„è¿›åŒ–è¿‡ç¨‹å’Œæ€§èƒ½æŒ‡æ ‡
"""

import os
import sys
import json
import time
import logging
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timedelta
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from matplotlib.figure import Figure
from matplotlib.axes import Axes
import seaborn as sns
import pandas as pd
import psutil
import threading
from collections import deque
import warnings
warnings.filterwarnings('ignore')

logger = logging.getLogger('AGI-EvolutionMonitor')

class AGIEvolutionMonitor:
    """AGIè¿›åŒ–ç›‘æ§å™¨"""

    def __init__(self, config_path: str = "./agi_training_config.ini"):
        self.config = self._load_config(config_path)

        # ç›‘æ§æ•°æ®å­˜å‚¨
        self.metrics_history = {
            'generation': [],
            'loss': [],
            'accuracy': [],
            'compression_ratio': [],
            'training_time': [],
            'memory_usage': [],
            'cpu_usage': [],
            'gpu_memory': [],
            'fitness_score': [],
            'diversity_score': [],
            'timestamp': []
        }

        # å®æ—¶æ•°æ®ç¼“å†²åŒº
        self.realtime_buffer = deque(maxlen=1000)

        # å¯è§†åŒ–è®¾ç½®
        self.fig_size = (15, 10)
        self.update_interval = 5  # ç§’

        # ç›‘æ§çŠ¶æ€
        self.is_monitoring = False
        self.monitor_thread = None

        # æ•°æ®æ–‡ä»¶è·¯å¾„
        self.metrics_file = Path("./agi_persistent_training/metrics/evolution_metrics.jsonl")
        self.metrics_file.parent.mkdir(parents=True, exist_ok=True)

        logger.info("AGIè¿›åŒ–ç›‘æ§å™¨åˆå§‹åŒ–å®Œæˆ")

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®"""
        config = {}

        if os.path.exists(config_path):
            try:
                import configparser
                parser = configparser.ConfigParser()
                parser.read(config_path)

                # è¯»å–ç›‘æ§ç›¸å…³é…ç½®
                if 'monitoring' in parser:
                    config.update(dict(parser['monitoring']))

            except Exception as e:
                logger.warning(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

        # é»˜è®¤é…ç½®
        config.setdefault('metrics_update_interval', 5)
        config.setdefault('max_history_points', 1000)
        config.setdefault('alert_thresholds', {
            'loss': 10.0,
            'memory_usage': 90.0,
            'cpu_usage': 95.0
        })

        return config

    def start_monitoring(self, background: bool = True):
        """å¼€å§‹ç›‘æ§"""
        if self.is_monitoring:
            logger.warning("ç›‘æ§å·²åœ¨è¿è¡Œ")
            return

        self.is_monitoring = True
        logger.info("å¼€å§‹AGIè¿›åŒ–ç›‘æ§...")

        if background:
            self.monitor_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
            self.monitor_thread.start()
        else:
            self._monitoring_loop()

    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.is_monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)
        logger.info("AGIè¿›åŒ–ç›‘æ§å·²åœæ­¢")

    def _monitoring_loop(self):
        """ç›‘æ§ä¸»å¾ªç¯"""
        while self.is_monitoring:
            try:
                # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
                system_metrics = self._collect_system_metrics()

                # æ”¶é›†è®­ç»ƒæŒ‡æ ‡
                training_metrics = self._collect_training_metrics()

                # åˆå¹¶æŒ‡æ ‡
                metrics = {**system_metrics, **training_metrics}
                metrics['timestamp'] = datetime.now().isoformat()

                # æ·»åŠ åˆ°å†å²è®°å½•
                self._add_metrics_to_history(metrics)

                # ä¿å­˜åˆ°æ–‡ä»¶
                self._save_metrics(metrics)

                # æ£€æŸ¥å‘Šè­¦
                self._check_alerts(metrics)

                # ç­‰å¾…ä¸‹æ¬¡æ›´æ–°
                time.sleep(self.update_interval)

            except Exception as e:
                logger.error(f"ç›‘æ§å¾ªç¯é”™è¯¯: {e}")
                time.sleep(10)  # å‡ºé”™æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´

    def _collect_system_metrics(self) -> Dict[str, float]:
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        metrics = {}

        try:
            # CPUä½¿ç”¨ç‡
            metrics['cpu_usage'] = psutil.cpu_percent(interval=1)

            # å†…å­˜ä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            metrics['memory_usage'] = memory.percent
            metrics['memory_used_gb'] = memory.used / (1024**3)

            # ç£ç›˜ä½¿ç”¨ç‡
            disk = psutil.disk_usage('/')
            metrics['disk_usage'] = disk.percent

            # ç½‘ç»œI/O (å¯é€‰)
            try:
                net = psutil.net_io_counters()
                metrics['network_bytes_sent'] = net.bytes_sent
                metrics['network_bytes_recv'] = net.bytes_recv
            except:
                pass

            # GPUä¿¡æ¯ (å¦‚æœå¯ç”¨)
            try:
                import torch
                if torch.cuda.is_available():
                    gpu_memory = torch.cuda.get_device_properties(0).total_memory
                    gpu_used = torch.cuda.memory_allocated(0)
                    metrics['gpu_memory_usage'] = (gpu_used / gpu_memory) * 100
                    metrics['gpu_memory_used_gb'] = gpu_used / (1024**3)
            except:
                pass

        except Exception as e:
            logger.warning(f"æ”¶é›†ç³»ç»ŸæŒ‡æ ‡å¤±è´¥: {e}")

        return metrics

    def _collect_training_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†è®­ç»ƒæŒ‡æ ‡"""
        metrics = {}

        try:
            # å°è¯•ä»è®­ç»ƒçŠ¶æ€æ–‡ä»¶è¯»å–
            state_files = [
                "./evo_state.json",
                "./agi_persistent_training/training_state.json",
                "./evolution_24h_state.json"
            ]

            for state_file in state_files:
                if os.path.exists(state_file):
                    with open(state_file, 'r') as f:
                        state = json.load(f)

                    # æå–è®­ç»ƒæŒ‡æ ‡
                    if 'generation' in state:
                        metrics['generation'] = state['generation']
                    if 'current_loss' in state:
                        metrics['loss'] = state['current_loss']
                    if 'fitness_score' in state:
                        metrics['fitness_score'] = state['fitness_score']
                    if 'compression_ratio' in state:
                        metrics['compression_ratio'] = state['compression_ratio']

                    break  # åªè¯»å–ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„æ–‡ä»¶

            # å¦‚æœæ²¡æœ‰çŠ¶æ€æ–‡ä»¶ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤º
            if not metrics:
                metrics.update(self._generate_demo_metrics())

        except Exception as e:
            logger.warning(f"æ”¶é›†è®­ç»ƒæŒ‡æ ‡å¤±è´¥: {e}")
            metrics.update(self._generate_demo_metrics())

        return metrics

    def _generate_demo_metrics(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ¼”ç¤ºæŒ‡æ ‡ (ç”¨äºæµ‹è¯•)"""
        base_generation = len(self.metrics_history['generation']) + 1

        return {
            'generation': base_generation,
            'loss': max(0.1, 2.0 * np.exp(-base_generation / 50) + np.random.normal(0, 0.1)),
            'accuracy': min(0.95, 0.5 + base_generation / 200 + np.random.normal(0, 0.02)),
            'compression_ratio': 0.85 + np.random.normal(0, 0.05),
            'fitness_score': 0.1 + base_generation / 100 + np.random.normal(0, 0.05),
            'diversity_score': 0.3 + np.random.normal(0, 0.1)
        }

    def _add_metrics_to_history(self, metrics: Dict[str, Any]):
        """æ·»åŠ åˆ°å†å²è®°å½•"""
        for key in self.metrics_history.keys():
            if key in metrics:
                self.metrics_history[key].append(metrics[key])
            elif key == 'timestamp':
                self.metrics_history[key].append(metrics.get('timestamp', datetime.now().isoformat()))

        # é™åˆ¶å†å²è®°å½•é•¿åº¦
        max_points = self.config.get('max_history_points', 1000)
        for key in self.metrics_history:
            if len(self.metrics_history[key]) > max_points:
                self.metrics_history[key] = self.metrics_history[key][-max_points:]

    def _save_metrics(self, metrics: Dict[str, Any]):
        """ä¿å­˜æŒ‡æ ‡åˆ°æ–‡ä»¶"""
        try:
            with open(self.metrics_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(metrics, ensure_ascii=False) + '\n')
        except Exception as e:
            logger.error(f"ä¿å­˜æŒ‡æ ‡å¤±è´¥: {e}")

    def _check_alerts(self, metrics: Dict[str, Any]):
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        thresholds = self.config.get('alert_thresholds', {})

        alerts = []

        # æ£€æŸ¥æŸå¤±é˜ˆå€¼
        if 'loss' in metrics and metrics['loss'] > thresholds.get('loss', 10.0):
            alerts.append(f"æŸå¤±è¿‡é«˜: {metrics['loss']:.3f}")

        # æ£€æŸ¥å†…å­˜ä½¿ç”¨ç‡
        if 'memory_usage' in metrics and metrics['memory_usage'] > thresholds.get('memory_usage', 90.0):
            alerts.append(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {metrics['memory_usage']:.1f}%")

        # æ£€æŸ¥CPUä½¿ç”¨ç‡
        if 'cpu_usage' in metrics and metrics['cpu_usage'] > thresholds.get('cpu_usage', 95.0):
            alerts.append(f"CPUä½¿ç”¨ç‡è¿‡é«˜: {metrics['cpu_usage']:.1f}%")

        if alerts:
            logger.warning("ğŸš¨ ç›‘æ§å‘Šè­¦: " + "; ".join(alerts))

    def create_dashboard(self, save_path: str = "./agi_persistent_training/metrics/dashboard.png") -> str:
        """åˆ›å»ºç›‘æ§ä»ªè¡¨æ¿"""
        logger.info("ç”Ÿæˆè¿›åŒ–ç›‘æ§ä»ªè¡¨æ¿...")

        # è®¾ç½®matplotlibæ ·å¼
        plt.style.use('seaborn-v0_8')
        sns.set_palette("husl")

        # åˆ›å»ºå¤§å›¾
        fig, axes = plt.subplots(3, 3, figsize=self.fig_size)
        fig.suptitle('H2Q-Evo AGIè¿›åŒ–ç›‘æ§ä»ªè¡¨æ¿', fontsize=16, fontweight='bold')

        # è½¬æ¢æ•°æ®ä¸ºDataFrame
        df = pd.DataFrame(self.metrics_history)

        # ç»˜åˆ¶å„ä¸ªæŒ‡æ ‡
        self._plot_training_metrics(axes[0, 0], df, 'loss', 'è®­ç»ƒæŸå¤±', 'red')
        self._plot_training_metrics(axes[0, 1], df, 'accuracy', 'å‡†ç¡®ç‡', 'green')
        self._plot_training_metrics(axes[0, 2], df, 'compression_ratio', 'å‹ç¼©ç‡', 'blue')

        self._plot_system_metrics(axes[1, 0], df, 'cpu_usage', 'CPUä½¿ç”¨ç‡ (%)', 'orange')
        self._plot_system_metrics(axes[1, 1], df, 'memory_usage', 'å†…å­˜ä½¿ç”¨ç‡ (%)', 'purple')
        self._plot_training_metrics(axes[1, 2], df, 'fitness_score', 'é€‚åº”åº¦åˆ†æ•°', 'cyan')

        self._plot_training_metrics(axes[2, 0], df, 'diversity_score', 'å¤šæ ·æ€§åˆ†æ•°', 'magenta')
        self._plot_generation_progress(axes[2, 1], df)
        self._plot_correlation_matrix(axes[2, 2], df)

        plt.tight_layout()

        # ä¿å­˜å›¾åƒ
        save_path = Path(save_path)
        save_path.parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()

        logger.info(f"ä»ªè¡¨æ¿å·²ä¿å­˜: {save_path}")
        return str(save_path)

    def _plot_training_metrics(self, ax: Axes, df: pd.DataFrame, column: str, title: str, color: str):
        """ç»˜åˆ¶è®­ç»ƒæŒ‡æ ‡"""
        if column in df.columns and not df[column].empty:
            ax.plot(df['generation'], df[column], color=color, linewidth=2, marker='o', markersize=3)
            ax.set_title(title, fontsize=12, fontweight='bold')
            ax.set_xlabel('è¿›åŒ–ä»£æ•°')
            ax.grid(True, alpha=0.3)

            # æ·»åŠ æœ€æ–°å€¼æ ‡æ³¨
            if len(df[column]) > 0:
                latest_val = df[column].iloc[-1]
                ax.annotate(f'{latest_val:.3f}', xy=(df['generation'].iloc[-1], latest_val),
                           xytext=(5, 5), textcoords='offset points', fontsize=10,
                           bbox=dict(boxstyle='round,pad=0.3', facecolor=color, alpha=0.7))

    def _plot_system_metrics(self, ax: Axes, df: pd.DataFrame, column: str, title: str, color: str):
        """ç»˜åˆ¶ç³»ç»ŸæŒ‡æ ‡"""
        if column in df.columns and not df[column].empty:
            ax.plot(df.index, df[column], color=color, linewidth=2)
            ax.set_title(title, fontsize=12, fontweight='bold')
            ax.set_xlabel('æ—¶é—´ç‚¹')
            ax.grid(True, alpha=0.3)

            # æ·»åŠ æœ€æ–°å€¼æ ‡æ³¨
            if len(df[column]) > 0:
                latest_val = df[column].iloc[-1]
                ax.annotate(f'{latest_val:.1f}', xy=(len(df)-1, latest_val),
                           xytext=(5, 5), textcoords='offset points', fontsize=10,
                           bbox=dict(boxstyle='round,pad=0.3', facecolor=color, alpha=0.7))

    def _plot_generation_progress(self, ax: Axes, df: pd.DataFrame):
        """ç»˜åˆ¶è¿›åŒ–è¿›åº¦"""
        if 'generation' in df.columns and not df['generation'].empty:
            generations = df['generation'].values
            progress = np.arange(len(generations)) / max(1, len(generations) - 1)

            ax.plot(generations, progress, 'g-', linewidth=3, marker='s', markersize=5)
            ax.set_title('è¿›åŒ–è¿›åº¦', fontsize=12, fontweight='bold')
            ax.set_xlabel('å½“å‰ä»£æ•°')
            ax.set_ylabel('å®Œæˆç™¾åˆ†æ¯”')
            ax.grid(True, alpha=0.3)

            # æ·»åŠ è¿›åº¦æ ‡æ³¨
            current_gen = generations[-1] if len(generations) > 0 else 0
            ax.text(0.7, 0.3, f'å½“å‰ä»£æ•°: {current_gen}', transform=ax.transAxes,
                   fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))

    def _plot_correlation_matrix(self, ax: Axes, df: pd.DataFrame):
        """ç»˜åˆ¶ç›¸å…³æ€§çŸ©é˜µ"""
        numeric_cols = ['loss', 'accuracy', 'compression_ratio', 'fitness_score', 'cpu_usage', 'memory_usage']
        available_cols = [col for col in numeric_cols if col in df.columns and not df[col].empty]

        if len(available_cols) > 1:
            corr_matrix = df[available_cols].corr()

            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,
                       square=True, ax=ax, cbar_kws={'shrink': 0.8})
            ax.set_title('æŒ‡æ ‡ç›¸å…³æ€§çŸ©é˜µ', fontsize=12, fontweight='bold')
        else:
            ax.text(0.5, 0.5, 'æ•°æ®ä¸è¶³\næ— æ³•è®¡ç®—ç›¸å…³æ€§', ha='center', va='center', transform=ax.transAxes)
            ax.set_title('ç›¸å…³æ€§çŸ©é˜µ', fontsize=12, fontweight='bold')

    def create_realtime_animation(self, save_path: str = "./agi_persistent_training/metrics/realtime_animation.gif") -> str:
        """åˆ›å»ºå®æ—¶åŠ¨ç”»"""
        logger.info("ç”Ÿæˆå®æ—¶è¿›åŒ–åŠ¨ç”»...")

        # è®¾ç½®åŠ¨ç”»
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        fig.suptitle('H2Q-Evo AGIå®æ—¶è¿›åŒ–ç›‘æ§', fontsize=14, fontweight='bold')

        def animate(frame):
            # æ¸…é™¤ä¹‹å‰çš„ç»˜å›¾
            for ax in axes.flat:
                ax.clear()

            # è·å–æœ€æ–°æ•°æ®
            df = pd.DataFrame(self.metrics_history)

            if not df.empty:
                # ç»˜åˆ¶å®æ—¶æŒ‡æ ‡
                self._plot_training_metrics(axes[0, 0], df, 'loss', 'è®­ç»ƒæŸå¤±', 'red')
                self._plot_training_metrics(axes[0, 1], df, 'accuracy', 'å‡†ç¡®ç‡', 'green')
                self._plot_system_metrics(axes[1, 0], df, 'cpu_usage', 'CPUä½¿ç”¨ç‡ (%)', 'orange')
                self._plot_system_metrics(axes[1, 1], df, 'memory_usage', 'å†…å­˜ä½¿ç”¨ç‡ (%)', 'purple')

            return axes.flat

        # åˆ›å»ºåŠ¨ç”»
        anim = animation.FuncAnimation(fig, animate, frames=50, interval=1000, blit=False)

        # ä¿å­˜åŠ¨ç”»
        save_path = Path(save_path)
        save_path.parent.mkdir(parents=True, exist_ok=True)
        anim.save(save_path, writer='pillow', fps=2)

        plt.close()
        logger.info(f"å®æ—¶åŠ¨ç”»å·²ä¿å­˜: {save_path}")
        return str(save_path)

    def generate_report(self, output_file: str = "./agi_persistent_training/metrics/evolution_report.md") -> str:
        """ç”Ÿæˆè¿›åŒ–æŠ¥å‘Š"""
        logger.info("ç”Ÿæˆè¿›åŒ–æŠ¥å‘Š...")

        df = pd.DataFrame(self.metrics_history)

        report = f"""# H2Q-Evo AGIè¿›åŒ–ç›‘æ§æŠ¥å‘Š

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ¦‚è¿°

- ç›‘æ§æ€»æ—¶é•¿: {len(df)} ä¸ªæ•°æ®ç‚¹
- å½“å‰è¿›åŒ–ä»£æ•°: {df['generation'].iloc[-1] if not df.empty else 0}
- ç³»ç»Ÿè¿è¡ŒçŠ¶æ€: {'æ­£å¸¸' if self.is_monitoring else 'å·²åœæ­¢'}

## æ€§èƒ½æŒ‡æ ‡æ€»ç»“

"""

        if not df.empty:
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            numeric_cols = ['loss', 'accuracy', 'compression_ratio', 'fitness_score', 'cpu_usage', 'memory_usage']
            for col in numeric_cols:
                if col in df.columns and not df[col].empty:
                    latest = df[col].iloc[-1]
                    mean_val = df[col].mean()
                    min_val = df[col].min()
                    max_val = df[col].max()

                    report += f"### {col.replace('_', ' ').title()}\n"
                    report += f"- å½“å‰å€¼: {latest:.3f}\n"
                    report += f"- å¹³å‡å€¼: {mean_val:.3f}\n"
                    report += f"- æœ€å°å€¼: {min_val:.3f}\n"
                    report += f"- æœ€å¤§å€¼: {max_val:.3f}\n\n"

        # ä¿å­˜æŠ¥å‘Š
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report)

        logger.info(f"è¿›åŒ–æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
        return str(output_path)

    def get_current_status(self) -> Dict[str, Any]:
        """è·å–å½“å‰çŠ¶æ€"""
        df = pd.DataFrame(self.metrics_history)

        status = {
            'is_monitoring': self.is_monitoring,
            'total_data_points': len(df),
            'current_generation': df['generation'].iloc[-1] if not df.empty else 0,
            'latest_metrics': {}
        }

        if not df.empty:
            latest = df.iloc[-1]
            for col in ['loss', 'accuracy', 'compression_ratio', 'fitness_score', 'cpu_usage', 'memory_usage']:
                if col in latest.index:
                    status['latest_metrics'][col] = latest[col]

        return status

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='H2Q-Evo AGIè¿›åŒ–ç›‘æ§å·¥å…·')
    parser.add_argument('--mode', choices=['monitor', 'dashboard', 'animation', 'report', 'status'],
                       default='monitor', help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--background', action='store_true', help='åå°è¿è¡Œç›‘æ§')
    parser.add_argument('--output-dir', default='./agi_persistent_training/metrics',
                       help='è¾“å‡ºç›®å½•')

    args = parser.parse_args()

    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(name)s: %(message)s'
    )

    # åˆ›å»ºç›‘æ§å™¨
    monitor = AGIEvolutionMonitor()

    try:
        if args.mode == 'monitor':
            print("ğŸš€ å¯åŠ¨AGIè¿›åŒ–ç›‘æ§...")
            monitor.start_monitoring(background=args.background)

            if not args.background:
                # å‰å°è¿è¡Œï¼Œç­‰å¾…ç”¨æˆ·ä¸­æ–­
                try:
                    while True:
                        time.sleep(1)
                except KeyboardInterrupt:
                    print("\nğŸ›‘ åœæ­¢ç›‘æ§...")
                    monitor.stop_monitoring()

        elif args.mode == 'dashboard':
            dashboard_path = monitor.create_dashboard(f"{args.output_dir}/dashboard.png")
            print(f"âœ… ä»ªè¡¨æ¿å·²ç”Ÿæˆ: {dashboard_path}")

        elif args.mode == 'animation':
            animation_path = monitor.create_realtime_animation(f"{args.output_dir}/realtime_animation.gif")
            print(f"âœ… å®æ—¶åŠ¨ç”»å·²ç”Ÿæˆ: {animation_path}")

        elif args.mode == 'report':
            report_path = monitor.generate_report(f"{args.output_dir}/evolution_report.md")
            print(f"âœ… è¿›åŒ–æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

        elif args.mode == 'status':
            status = monitor.get_current_status()
            print("ğŸ“Š å½“å‰çŠ¶æ€:")
            print(json.dumps(status, indent=2, ensure_ascii=False))

    except Exception as e:
        logger.error(f"ç›‘æ§å·¥å…·è¿è¡Œå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()