#!/usr/bin/env python3
"""
H2Q-Evo åˆ†å±‚æ¦‚å¿µç¼–ç å™¨
åŸºäºå››å…ƒæ•°çƒé¢æ˜ å°„å’Œåˆ†å½¢ç»“æ„çš„è‡ªåŠ¨åˆ†å±‚å­—ç¬¦ç¼–ç ç³»ç»Ÿ
é›†æˆå¼€æºè‹±æ–‡å­—å…¸å®ç°è‡ªæˆ‘ç»„ç»‡çš„æ¦‚å¿µå±‚
"""

import torch
import numpy as np
import json
import os
import sys
from typing import Dict, List, Any, Tuple, Optional
from collections import defaultdict, deque
import nltk
from nltk.corpus import wordnet as wn
from nltk.stem import WordNetLemmatizer

sys.path.append('/Users/imymm/H2Q-Evo')

from h2q_project.src.h2q.tokenizer_simple import default_tokenizer
from final_integration_system import FinalIntegratedSystem, FinalIntegrationConfig


class HierarchicalConceptEncoder:
    """
    åˆ†å±‚æ¦‚å¿µç¼–ç å™¨
    å®ç°è‡ªåŠ¨åˆ†å±‚å­—ç¬¦ç¼–ç é“¾æ¥å’Œå±‚çº§æ ‡å¿—
    ä½¿ç”¨WordNetå½¢æˆè‡ªæˆ‘ç»„ç»‡çš„æ¦‚å¿µå±‚
    """

    def __init__(self, max_depth: int = 5, compression_ratio: float = 46.0):
        self.max_depth = max_depth
        self.compression_ratio = compression_ratio

        # åˆå§‹åŒ–ç»„ä»¶
        self.tokenizer = default_tokenizer
        self.lemmatizer = WordNetLemmatizer()

        # æ¦‚å¿µå±‚çº§ç»“æ„
        self.concept_layers: Dict[str, Dict] = {}
        self.layer_mappings: Dict[int, Dict] = {}
        self.abstraction_cache: Dict[str, Any] = {}

        # å››å…ƒæ•°çƒé¢æ˜ å°„å‚æ•°
        self.quaternion_basis = self._init_quaternion_basis()

        # ç»´åº¦æ§åˆ¶å‚æ•°
        self.dimension_control = {
            'max_concepts_per_layer': 1000,
            'abstraction_threshold': 0.7,
            'recursion_limit': 10,
            'compression_factor': compression_ratio
        }

        # åˆå§‹åŒ–236Bæ¨ç†ç³»ç»Ÿ
        self.inference_system = self._init_inference_system()

        # æ„å»ºåŸºç¡€æ¦‚å¿µå±‚
        self._build_base_concept_layers()

    def _init_quaternion_basis(self) -> torch.Tensor:
        """åˆå§‹åŒ–å››å…ƒæ•°çƒé¢æ˜ å°„åŸº"""
        # å››å…ƒæ•°åŸº: 1, i, j, k
        basis = torch.tensor([
            [1.0, 0.0, 0.0, 0.0],  # 1
            [0.0, 1.0, 0.0, 0.0],  # i
            [0.0, 0.0, 1.0, 0.0],  # j
            [0.0, 0.0, 0.0, 1.0],  # k
        ], dtype=torch.float32)

        return basis

    def _init_inference_system(self) -> FinalIntegratedSystem:
        """åˆå§‹åŒ–236Bæ¨ç†ç³»ç»Ÿ"""
        config = FinalIntegrationConfig(
            model_compression_ratio=self.compression_ratio,
            enable_mathematical_core=True,
            device="cpu"
        )

        system = FinalIntegratedSystem(config)

        # å°è¯•åŠ è½½æƒé‡
        weight_paths = [
            "/Users/imymm/H2Q-Evo/h2q_project/h2q_full_l1.pth",
            "/Users/imymm/H2Q-Evo/h2q_project/h2q_qwen_crystal.pt",
            "/Users/imymm/H2Q-Evo/h2q_project/h2q_model_hierarchy.pth"
        ]

        for weight_path in weight_paths:
            if os.path.exists(weight_path):
                if system.initialize_from_236b_weights(weight_path):
                    break

        return system

    def _build_base_concept_layers(self):
        """æ„å»ºåŸºç¡€æ¦‚å¿µå±‚"""
        print("ğŸ—ï¸ æ„å»ºåŸºç¡€æ¦‚å¿µå±‚...")

        # å±‚çº§0: åŸå§‹å­—ç¬¦
        self.layer_mappings[0] = {
            'type': 'character',
            'vocabulary': {chr(i): i for i in range(32, 127)},
            'encoding_dim': 1
        }

        # å±‚çº§1: è¯ç´ /è¯æ ¹
        self.layer_mappings[1] = {
            'type': 'morpheme',
            'vocabulary': {},
            'encoding_dim': 4  # å››å…ƒæ•°ç»´åº¦
        }

        # å±‚çº§2: å•è¯
        self.layer_mappings[2] = {
            'type': 'word',
            'vocabulary': {},
            'encoding_dim': 16
        }

        # å±‚çº§3: çŸ­è¯­/æ¦‚å¿µ
        self.layer_mappings[3] = {
            'type': 'phrase',
            'vocabulary': {},
            'encoding_dim': 64
        }

        # å±‚çº§4: å¥å­/æŠ½è±¡æ¦‚å¿µ
        self.layer_mappings[4] = {
            'type': 'sentence',
            'vocabulary': {},
            'encoding_dim': 256
        }

        # å±‚çº§5: æ–‡æ¡£/å…ƒæ¦‚å¿µ
        self.layer_mappings[5] = {
            'type': 'document',
            'vocabulary': {},
            'encoding_dim': 1024
        }

        print("âœ… åŸºç¡€æ¦‚å¿µå±‚æ„å»ºå®Œæˆ")

    def quaternion_sphere_mapping(self, input_tensor: torch.Tensor) -> torch.Tensor:
        """å››å…ƒæ•°çƒé¢æ˜ å°„"""
        # å°†è¾“å…¥æ˜ å°„åˆ°å››å…ƒæ•°çƒé¢ä¸Š
        # ä½¿ç”¨çƒé¢åæ ‡ç³»è¿›è¡Œæ˜ å°„

        if input_tensor.dim() == 1:
            input_tensor = input_tensor.unsqueeze(0)

        batch_size, seq_len = input_tensor.shape

        # å½’ä¸€åŒ–åˆ°å•ä½çƒé¢
        norms = torch.norm(input_tensor, dim=-1, keepdim=True)
        normalized = input_tensor / (norms + 1e-8)

        # æ‰©å±•åˆ°å››å…ƒæ•°ç»´åº¦
        quaternion_coords = torch.zeros(batch_size, seq_len, 4, dtype=torch.float32)

        # ä½¿ç”¨çƒé¢åæ ‡æ˜ å°„
        theta = torch.acos(normalized[..., 0])  # æè§’
        phi = torch.atan2(normalized[..., 1], normalized[..., 2])  # æ–¹ä½è§’

        quaternion_coords[..., 0] = torch.cos(theta / 2)  # å®éƒ¨
        quaternion_coords[..., 1] = torch.sin(theta / 2) * torch.cos(phi)  # iåˆ†é‡
        quaternion_coords[..., 2] = torch.sin(theta / 2) * torch.sin(phi)  # jåˆ†é‡
        quaternion_coords[..., 3] = torch.sin(theta / 2) * torch.cos(theta)  # kåˆ†é‡

        return quaternion_coords

    def encode_hierarchical(self, text: str, target_depth: int = None) -> Dict[str, Any]:
        """åˆ†å±‚ç¼–ç æ–‡æœ¬"""
        if target_depth is None:
            target_depth = self.max_depth

        result = {
            'original_text': text,
            'layers': {},
            'final_encoding': None,
            'concept_path': []
        }

        current_input = text

        for depth in range(min(target_depth + 1, self.max_depth + 1)):
            layer_result = self._encode_single_layer(current_input, depth)
            result['layers'][depth] = layer_result

            # æ›´æ–°è¾“å…¥ä¸ºä¸‹ä¸€å±‚çš„æŠ½è±¡è¡¨ç¤º
            if depth < target_depth:
                current_input = self._abstract_to_next_layer(layer_result)

        # ç”Ÿæˆæœ€ç»ˆç¼–ç 
        result['final_encoding'] = self._generate_final_encoding(result['layers'])

        return result

    def _encode_single_layer(self, input_text: str, depth: int) -> Dict[str, Any]:
        """ç¼–ç å•å±‚"""
        layer_config = self.layer_mappings.get(depth, {})

        if layer_config.get('type') == 'character':
            # å­—ç¬¦çº§ç¼–ç 
            tokens = [ord(c) for c in input_text if 32 <= ord(c) <= 126]
            encoding = torch.tensor(tokens, dtype=torch.long)

        elif layer_config.get('type') == 'word':
            # å•è¯çº§ç¼–ç ï¼Œä½¿ç”¨WordNetæ¦‚å¿µ
            words = input_text.split()
            encoding = self._encode_words_to_concepts(words)

        else:
            # å…¶ä»–å±‚çº§çš„é€šç”¨ç¼–ç 
            encoding = self._encode_generic(input_text, depth)

        # åº”ç”¨å››å…ƒæ•°çƒé¢æ˜ å°„
        if encoding.dtype == torch.long:
            encoding = encoding.float()

        quaternion_encoding = self.quaternion_sphere_mapping(encoding)

        return {
            'input': input_text,
            'encoding': quaternion_encoding,
            'layer_type': layer_config.get('type', 'unknown'),
            'dimension': quaternion_encoding.shape[-1]
        }

    def _encode_words_to_concepts(self, words: List[str]) -> torch.Tensor:
        """å°†å•è¯ç¼–ç ä¸ºæ¦‚å¿µå‘é‡"""
        concept_vectors = []

        for word in words:
            # è¯å½¢è¿˜åŸ
            lemma = self.lemmatizer.lemmatize(word.lower())

            # è·å–WordNetåŒä¹‰è¯é›†
            synsets = wn.synsets(lemma)
            if synsets:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªåŒä¹‰è¯é›†çš„å®šä¹‰ä½œä¸ºæ¦‚å¿µè¡¨ç¤º
                definition = synsets[0].definition()
                # ç®€å•ç¼–ç ï¼šå­—ç¬¦çº§ç¼–ç å®šä¹‰
                concept_vec = torch.tensor([ord(c) for c in definition[:50]], dtype=torch.float32)
            else:
                # å›é€€åˆ°å­—ç¬¦ç¼–ç 
                concept_vec = torch.tensor([ord(c) for c in lemma], dtype=torch.float32)

            concept_vectors.append(concept_vec.mean(dim=0, keepdim=True))

        if concept_vectors:
            return torch.cat(concept_vectors, dim=0)
        else:
            return torch.tensor([], dtype=torch.float32)

    def _encode_generic(self, text: str, depth: int) -> torch.Tensor:
        """é€šç”¨ç¼–ç æ–¹æ³•"""
        # ç®€å•å­—ç¬¦çº§ç¼–ç ä½œä¸ºåŸºç¡€
        chars = [ord(c) for c in text if 32 <= ord(c) <= 126]
        encoding = torch.tensor(chars, dtype=torch.float32)

        # æ ¹æ®æ·±åº¦åº”ç”¨ä¸åŒçº§åˆ«çš„æŠ½è±¡
        if depth > 2 and len(chars) >= 4:
            # æ›´é«˜å±‚çº§ï¼šåº”ç”¨å¹³å‡æ± åŒ–è¿›è¡ŒæŠ½è±¡
            # ç¡®ä¿å¯ä»¥è¢«4æ•´é™¤
            remainder = len(chars) % 4
            if remainder > 0:
                # å¡«å……åˆ°å¯ä»¥è¢«4æ•´é™¤
                padding_size = 4 - remainder
                padding = torch.full((padding_size,), encoding.mean().item())
                encoding = torch.cat([encoding, padding])

            encoding = encoding.view(-1, 4).mean(dim=1)

        return encoding

    def _abstract_to_next_layer(self, layer_result: Dict) -> str:
        """å°†å½“å‰å±‚æŠ½è±¡åˆ°ä¸‹ä¸€å±‚"""
        encoding = layer_result['encoding']

        # ç®€å•ç­–ç•¥ï¼šå°†ç¼–ç è½¬æ¢ä¸ºå­—ç¬¦ä¸²è¡¨ç¤º
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥ä½¿ç”¨æ›´å¤æ‚çš„æŠ½è±¡æœºåˆ¶
        abstract_text = f"layer_{layer_result['layer_type']}_abstract_{encoding.shape}"

        return abstract_text

    def _generate_final_encoding(self, layers: Dict) -> torch.Tensor:
        """ç”Ÿæˆæœ€ç»ˆç¼–ç """
        # ç»„åˆæ‰€æœ‰å±‚çš„ç¼–ç 
        final_encodings = []

        for depth in range(len(layers)):
            layer_encoding = layers[depth]['encoding']
            # å‹ç¼©åˆ°ç»Ÿä¸€ç»´åº¦ï¼Œå¹¶ç¡®ä¿æ‰¹æ¬¡ç»´åº¦ä¸€è‡´
            compressed = self._compress_encoding(layer_encoding, target_dim=256)

            # å¦‚æœæ˜¯2D tensorï¼Œç¡®ä¿ç¬¬ä¸€ä¸ªç»´åº¦æ˜¯1 (batch_size)
            if compressed.dim() == 1:
                compressed = compressed.unsqueeze(0)
            elif compressed.dim() == 2 and compressed.shape[0] != 1:
                compressed = compressed.mean(dim=0, keepdim=True)

            print(f"  å±‚{depth}å‹ç¼©åå½¢çŠ¶: {compressed.shape}")  # è°ƒè¯•ä¿¡æ¯
            final_encodings.append(compressed)

        # è¿æ¥æ‰€æœ‰å±‚ç¼–ç 
        if final_encodings:
            # ç¡®ä¿æ‰€æœ‰tensoræœ‰ç›¸åŒçš„å½¢çŠ¶
            shapes = [enc.shape for enc in final_encodings]
            print(f"  å„å±‚å½¢çŠ¶: {shapes}")  # è°ƒè¯•ä¿¡æ¯

            if len(set(shapes)) == 1:  # æ‰€æœ‰å½¢çŠ¶ç›¸åŒ
                combined = torch.cat(final_encodings, dim=-1)
            else:
                # å¦‚æœå½¢çŠ¶ä¸åŒï¼Œä½¿ç”¨æœ€å¤§å½¢çŠ¶è¿›è¡Œå¡«å……
                max_shape = torch.tensor(shapes).max(dim=0)[0]
                padded_encodings = []
                for enc in final_encodings:
                    if enc.shape != tuple(max_shape.tolist()):
                        padding = torch.zeros(*max_shape.tolist(), dtype=enc.dtype)
                        padding[:enc.shape[0], :enc.shape[1]] = enc
                        padded_encodings.append(padding)
                    else:
                        padded_encodings.append(enc)
                combined = torch.cat(padded_encodings, dim=-1)

            # æœ€ç»ˆå‹ç¼©
            final_encoding = self._compress_encoding(combined, target_dim=1024)
            return final_encoding

        return torch.tensor([], dtype=torch.float32)

    def _compress_encoding(self, encoding: torch.Tensor, target_dim: int) -> torch.Tensor:
        """å‹ç¼©ç¼–ç åˆ°ç›®æ ‡ç»´åº¦"""
        if encoding.numel() == 0:
            return torch.zeros(1, target_dim, dtype=torch.float32)

        # ç¡®ä¿è‡³å°‘æ˜¯2D
        if encoding.dim() == 1:
            encoding = encoding.unsqueeze(0)

        current_dim = encoding.shape[-1]

        if current_dim == target_dim:
            return encoding
        elif current_dim < target_dim:
            # å¡«å……
            padding = torch.zeros(*encoding.shape[:-1], target_dim - current_dim, dtype=encoding.dtype)
            return torch.cat([encoding, padding], dim=-1)
        else:
            # å‹ç¼©ï¼šæˆªæ–­æˆ–å¹³å‡
            if target_dim == 1:
                return encoding.mean(dim=-1, keepdim=True)
            else:
                # ç®€å•æˆªæ–­åˆ°ç›®æ ‡ç»´åº¦
                return encoding[..., :target_dim]

    def generate_code_completion(self, prompt: str, max_length: int = 1000) -> str:
        """ä½¿ç”¨236Bæ¨¡å‹è¿›è¡Œä»£ç è¡¥å…¨"""
        print(f"ğŸ”§ ç”Ÿæˆä»£ç è¡¥å…¨: {prompt[:50]}...")

        # é¦–å…ˆè¿›è¡Œåˆ†å±‚ç¼–ç 
        hierarchical_encoding = self.encode_hierarchical(prompt, target_depth=3)

        # å‡†å¤‡è¾“å…¥
        final_encoding = hierarchical_encoding['final_encoding']
        if final_encoding.numel() == 0:
            # å›é€€åˆ°ç®€å•ç¼–ç 
            encoded = self.tokenizer.encode(prompt, add_specials=True, max_length=100)
            input_tensor = torch.tensor(encoded, dtype=torch.long).view(1, -1)
        else:
            # ä½¿ç”¨åˆ†å±‚ç¼–ç 
            input_tensor = final_encoding.view(1, -1).long()

        generated_tokens = []
        current_input = input_tensor.clone()

        try:
            for i in range(max_length):
                # æ¨ç†
                output = self.inference_system.perform_local_inference(current_input)

                # è·å–ä¸‹ä¸€ä¸ªtoken
                if output.dim() > 1:
                    next_token_logits = output[0, -1, :]
                else:
                    next_token_logits = output[0, :]

                probs = torch.softmax(next_token_logits, dim=-1)
                next_token = torch.multinomial(probs, 1).item()

                # é™åˆ¶èŒƒå›´
                vocab_size = self.tokenizer.vocab_size
                if next_token >= vocab_size:
                    next_token = next_token % vocab_size

                generated_tokens.append(next_token)

                # æ›´æ–°è¾“å…¥
                next_token_tensor = torch.tensor([[next_token]], dtype=torch.long)
                current_input = torch.cat([current_input, next_token_tensor], dim=1)

                # æ£€æŸ¥åœæ­¢æ¡ä»¶
                if next_token == self.tokenizer.eos_token_id:
                    break

                if current_input.shape[1] > 2000:  # é˜²æ­¢è¿‡é•¿
                    break

        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆå¤±è´¥: {e}")
            return f"# Error: {e}"

        # è§£ç 
        generated_text = self.tokenizer.decode(generated_tokens, skip_specials=True)

        return generated_text

    def analyze_concept_hierarchy(self, text: str) -> Dict[str, Any]:
        """åˆ†ææ¦‚å¿µå±‚çº§ç»“æ„"""
        encoding_result = self.encode_hierarchical(text)

        analysis = {
            'text': text,
            'layer_count': len(encoding_result['layers']),
            'total_concepts': sum(len(layer.get('vocabulary', {})) for layer in self.layer_mappings.values()),
            'encoding_shapes': {depth: layer['encoding'].shape for depth, layer in encoding_result['layers'].items()},
            'abstraction_levels': [layer['layer_type'] for layer in encoding_result['layers'].values()]
        }

        return analysis

    def save_concept_layers(self, filepath: str):
        """ä¿å­˜æ¦‚å¿µå±‚"""
        data = {
            'layer_mappings': self.layer_mappings,
            'concept_layers': self.concept_layers,
            'abstraction_cache': dict(list(self.abstraction_cache.items())[:1000])  # é™åˆ¶ç¼“å­˜å¤§å°
        }

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, default=str)

        print(f"ğŸ’¾ æ¦‚å¿µå±‚å·²ä¿å­˜åˆ°: {filepath}")

    def load_concept_layers(self, filepath: str):
        """åŠ è½½æ¦‚å¿µå±‚"""
        if os.path.exists(filepath):
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)

            self.layer_mappings = data.get('layer_mappings', {})
            self.concept_layers = data.get('concept_layers', {})
            self.abstraction_cache = data.get('abstraction_cache', {})

            print(f"ğŸ“¥ æ¦‚å¿µå±‚å·²åŠ è½½: {filepath}")


def test_hierarchical_encoder():
    """æµ‹è¯•åˆ†å±‚ç¼–ç å™¨"""
    print("ğŸ§ª æµ‹è¯•åˆ†å±‚æ¦‚å¿µç¼–ç å™¨")
    print("=" * 50)

    encoder = HierarchicalConceptEncoder()

    # æµ‹è¯•æ–‡æœ¬ - åªç”¨ä¸€ä¸ªç®€å•çš„
    test_text = "def fib(n):"

    print(f"\nğŸ“ æµ‹è¯•æ–‡æœ¬: {test_text}")

    # åˆ†å±‚ç¼–ç  - åªç”¨2å±‚
    result = encoder.encode_hierarchical(test_text, target_depth=2)
    print(f"  å±‚æ•°: {len(result['layers'])}")
    print(f"  ç¼–ç å½¢çŠ¶: {result['final_encoding'].shape if result['final_encoding'] is not None else 'None'}")

    # æ¦‚å¿µåˆ†æ
    analysis = encoder.analyze_concept_hierarchy(test_text)
    print(f"  æ¦‚å¿µå±‚çº§: {analysis['abstraction_levels']}")

    # ä»£ç è¡¥å…¨æµ‹è¯•
    completion = encoder.generate_code_completion(test_text, max_length=50)
    print(f"  è¡¥å…¨ç»“æœ: {completion[:100]}...")

    # ä¿å­˜æ¦‚å¿µå±‚
    encoder.save_concept_layers("/Users/imymm/H2Q-Evo/hierarchical_concept_layers.json")

    print("\nâœ… åˆ†å±‚ç¼–ç å™¨æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    test_hierarchical_encoder()