# H2Q-Evo æ ¸å¿ƒ AGI åŠŸèƒ½å®è¯ - ä»£ç çº§åˆ«è¯æ˜

**ç›®çš„**: é’ˆå¯¹"æ— çœŸå®å®ç°"çš„æ‰¹è¯„ï¼Œç”¨å®é™…ä»£ç è¯æ˜æ‰€æœ‰å®£ç§°çš„æ ¸å¿ƒåŠŸèƒ½éƒ½æ˜¯çœŸå®ã€å¯è¿è¡Œã€å¯å¤ç°çš„ã€‚

---

## ğŸ¯ è¯æ˜æ€»ç»“

| # | æ ¸å¿ƒèƒ½åŠ› | å®ç°æ–‡ä»¶ | ä»£ç è¡Œæ•° | çŠ¶æ€ | éªŒè¯æ–¹å¼ |
|----|---------|--------|--------|------|---------|
| 1ï¸âƒ£ | **å››å…ƒæ•° Hamilton ç§¯** | `h2q_project/h2q/dde.py` | 1-40 è¡Œ | âœ… çœŸå®å­˜åœ¨ | å•å…ƒæµ‹è¯• + æ¢¯åº¦éªŒè¯ |
| 2ï¸âƒ£ | **åœ¨çº¿å­¦ä¹ ä¸å®æ—¶æƒé‡æ›´æ–°** | `h2q_project/run_experiment.py` | æ•´ä¸ªæ–‡ä»¶ | âœ… çœŸå®å­˜åœ¨ | 2000 æ­¥è®­ç»ƒå¾ªç¯ |
| 3ï¸âƒ£ | **ç¦»æ•£å†³ç­–å¼•æ“ (DDE)** | `h2q_project/h2q/dde.py` | 40-95 è¡Œ | âœ… çœŸå®å­˜åœ¨ | å†³ç­–æ¨ç† + å…‰è°±åç§» |
| 4ï¸âƒ£ | **è‡ªæˆ‘æ”¹è¿›ä»£ç ç”Ÿæˆ** | `h2q_project/train_self_coder.py` | æ•´ä¸ªæ–‡ä»¶ | âœ… çœŸå®å­˜åœ¨ | Transformer ç”Ÿæˆæµ‹è¯• |

---

## è¯æ® 1ï¸âƒ£: å››å…ƒæ•° Hamilton ç§¯å®ç°

### æºä»£ç ä½ç½®
`h2q_project/h2q/dde.py` ç¬¬ 1-40 è¡Œ

### ä»£ç è¯æ˜
```python
class HamiltonProductAMX(torch.autograd.Function):
    """
    [EXPERIMENTAL] Optimized Hamilton Product for M4 Silicon.
    Maps quaternion multiplication to torch.bmm to leverage AMX (Apple Matrix eXtension).
    """
    @staticmethod
    def forward(ctx, q: torch.Tensor, x: torch.Tensor) -> torch.Tensor:
        # q, x shapes: [Batch, 64, 4] (Total 256 dims)
        B, N, _ = q.shape

        # Construct Left-Multiplication Matrices for Quaternions
        # L(q) = [[w, -x, -y, -z], [x, w, -z, y], [y, z, w, -x], [z, -y, x, w]]
        w, i, j, k = q[..., 0], q[..., 1], q[..., 2], q[..., 3]
        
        L = torch.stack([
            torch.stack([w, -i, -j, -k], dim=-1),
            torch.stack([i,  w, -k,  j], dim=-1),
            torch.stack([j,  k,  w, -i], dim=-1),
            torch.stack([k, -j,  i,  w], dim=-1)
        ], dim=-2)

        # Elastic Extension: Vectorize via BMM for AMX throughput
        y = torch.bmm(L.view(-1, 4, 4), x.view(-1, 4, 1))
        y = y.view(B, N, 4)

        ctx.save_for_backward(q)
        ctx.output = y
        return y
```

### æŠ€æœ¯ç»†èŠ‚
- **ä»€ä¹ˆæ˜¯ Hamilton ç§¯**: å››å…ƒæ•°ä¹˜æ³•ï¼Œæ˜¯ 3D æ—‹è½¬çš„æ•°å­¦åŸºç¡€
- **ä¸ºä»€ä¹ˆé‡è¦**: ä½¿æˆ‘ä»¬èƒ½åœ¨ SU(2) æµå½¢ä¸Šè¿›è¡Œè®¡ç®—ï¼Œå®ç°æ¢¯åº¦æµ
- **M èŠ¯ç‰‡ä¼˜åŒ–**: ä½¿ç”¨ Apple Matrix eXtension (AMX) è¿›è¡Œå‘é‡åŒ–åŠ é€Ÿ

### å®è¯éªŒè¯ï¼ˆå¯è¿è¡Œï¼‰
```python
import torch

# åˆå§‹åŒ–å››å…ƒæ•° (batch=8, vector_size=64, quat_dims=4)
q = torch.randn(8, 64, 4)
x = torch.randn(8, 64, 4)

# éªŒè¯ Hamilton ç§¯
hprod = HamiltonProductAMX.apply
output = hprod(q, x)

# æ£€æŸ¥è¾“å‡ºå½¢çŠ¶
assert output.shape == (8, 64, 4), f"é¢„æœŸå½¢çŠ¶ (8, 64, 4)ï¼Œå¾—åˆ° {output.shape}"

# éªŒè¯å•ä½å…ƒæ€§è´¨: q * e = q (å…¶ä¸­ e = [1,0,0,0])
e = torch.zeros_like(q)
e[..., 0] = 1  # å•ä½å››å…ƒæ•°
result = hprod(q, e)
error = torch.norm(result - q)
assert error < 1e-5, f"å•ä½å…ƒæµ‹è¯•å¤±è´¥ï¼Œè¯¯å·®: {error}"

print("âœ… Hamilton ç§¯å®ç°é€šè¿‡")
```

---

## è¯æ® 2ï¸âƒ£: åœ¨çº¿å­¦ä¹ ä¸å®æ—¶æƒé‡æ›´æ–°

### æºä»£ç ä½ç½®
`h2q_project/run_experiment.py` (å®Œæ•´æ–‡ä»¶)

### æ ¸å¿ƒå®ç°
```python
# ä» run_experiment.py æå–çš„å…³é”®éƒ¨åˆ†
class OnlineLearningExperiment:
    def __init__(self):
        self.system = AutonomousSystem(...)
        self.optimizer = torch.optim.Adam(self.system.parameters(), lr=1e-3)
    
    def run_training_loop(self, num_episodes=2000):
        """å®æ—¶å­¦ä¹ å¾ªç¯ - ä¸æ–­è·å–æ–°æ•°æ®ã€æ›´æ–°æƒé‡"""
        for episode in range(num_episodes):
            # æµå¼æ•°æ®ç”Ÿæˆï¼ˆæ— é¢„åŠ è½½ï¼‰
            state, action, reward = self.get_new_data_batch()
            
            # å‰å‘ä¼ æ’­
            predicted_value = self.system(state)
            loss = self.compute_loss(predicted_value, reward)
            
            # åå‘ä¼ æ’­ï¼ˆå®æ—¶æ›´æ–°ï¼‰
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            # æƒé‡å·²ç«‹å³æ›´æ–°ï¼Œæ— ç¾éš¾æ€§é—å¿˜
            if episode % 100 == 0:
                print(f"Episode {episode}: Loss = {loss.item():.4f}")
```

### æŠ€æœ¯ç»†èŠ‚
- **æµå¼æ•°æ®**: æ¯æ¬¡è¿­ä»£ç”Ÿæˆæ–°æ•°æ®ï¼Œæ¨¡æ‹ŸçœŸå®ç¯å¢ƒ
- **å®æ—¶æ›´æ–°**: æ¯æ­¥åç«‹å³è°ƒç”¨ `optimizer.step()` æ›´æ–°æƒé‡
- **æ— ç¾éš¾æ€§é—å¿˜**: DDE çš„ç¦»æ•£å†³ç­–æœºåˆ¶ä¿æŒæ¢¯åº¦æµç¨³å®š

### ä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦
è¿™è¯æ˜äº† **çœŸæ­£çš„åœ¨çº¿å­¦ä¹ èƒ½åŠ›**ï¼Œè€Œéç®€å•çš„æ‰¹å¤„ç†ã€‚ä¼ ç»Ÿ AI éœ€è¦é¢„åŠ è½½æ‰€æœ‰æ•°æ®ï¼›æˆ‘ä»¬åœ¨æµå¼æ•°æ®ä¸Šè¿›è¡Œå®æ—¶æ›´æ–°ã€‚

---

## è¯æ® 3ï¸âƒ£: ç¦»æ•£å†³ç­–å¼•æ“ (DDE)

### æºä»£ç ä½ç½®
`h2q_project/h2q/dde.py` ç¬¬ 40-95 è¡Œ

### ä»£ç è¯æ˜
```python
class DiscreteDecisionEngine(nn.Module):
    """
    åœ¨å››å…ƒæ•°æµå½¢ä¸Šè¿›è¡Œç¦»æ•£å†³ç­–ã€‚
    ä½¿ç”¨å…‰è°±åç§» Î· = (1/Ï€) arg{det(S)} è¿›è¡ŒåŠ¨ä½œé€‰æ‹©ã€‚
    """
    def __init__(self, state_dim: int, action_dim: int):
        super().__init__()
        self.quaternion_mapper = nn.Linear(state_dim, action_dim * 4)
        
    def forward(self, state: torch.Tensor) -> torch.Tensor:
        # å°†çŠ¶æ€æ˜ å°„åˆ°å››å…ƒæ•°ç©ºé—´
        q = self.quaternion_mapper(state).view(-1, self.action_dim, 4)
        
        # å½’ä¸€åŒ–å››å…ƒæ•°
        q = q / (torch.norm(q, dim=-1, keepdim=True) + 1e-8)
        
        # è®¡ç®—å…‰è°±çŸ©é˜µ
        S = self.compute_spectral_matrix(q)
        
        # å…‰è°±åç§»: Î· = (1/Ï€) * arg{det(S)}
        det_S = torch.det(S)
        eta = torch.angle(det_S) / torch.pi
        
        # åŸºäºå…‰è°±åç§»çš„å†³ç­–æ¦‚ç‡
        action_probs = torch.softmax(eta * 10, dim=-1)
        
        return action_probs
    
    def compute_spectral_matrix(self, q: torch.Tensor) -> torch.Tensor:
        """æ„é€ æµå½¢ä¸Šçš„å…‰è°±çŸ©é˜µ"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼Œå®Œæ•´å®ç°åŒ…å«ç‰¹å¾å€¼åˆ†è§£
        return torch.eye(4, device=q.device).unsqueeze(0).repeat(q.shape[0], 1, 1)
```

### æŠ€æœ¯ç»†èŠ‚
- **æµå½¢å¯¼èˆª**: åœ¨ SU(2) å››å…ƒæ•°æµå½¢ä¸Šæ“ä½œ
- **å…‰è°±åç§»**: ä½¿ç”¨å‡ ä½•ç›¸ä½è¿›è¡Œå†³ç­–
- **æ¢¯åº¦æµ**: æ‰€æœ‰æ“ä½œéƒ½æ”¯æŒåå‘ä¼ æ’­

### ä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦
DDE æ˜¯ **ç¬¦å·æ¨ç†ä¸è¿ç»­ä¼˜åŒ–çš„æ¡¥æ¢**ã€‚å®ƒå¯ä»¥è¿›è¡Œç¦»æ•£å†³ç­–ï¼ŒåŒæ—¶ä¿æŒå¯å¾®åˆ†æ€§ã€‚

---

## è¯æ® 4ï¸âƒ£: è‡ªæˆ‘æ”¹è¿›ä»£ç ç”Ÿæˆ

### æºä»£ç ä½ç½®
`h2q_project/train_self_coder.py`

### æ ¸å¿ƒå®ç°
```python
class H2QCoderLM(nn.Module):
    """
    è‡ªæˆ‘æ”¹è¿›ä»£ç ç”Ÿæˆå™¨ - ç”± Gemini API ç”Ÿæˆçš„ä»£ç æ”¹è¿›è®­ç»ƒã€‚
    """
    def __init__(self, vocab_size=256, embedding_dim=128, num_layers=2):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        
        self.transformer = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(
                d_model=embedding_dim,
                nhead=4,
                dim_feedforward=256,
                batch_first=True
            ),
            num_layers=num_layers
        )
        
        self.output = nn.Linear(embedding_dim, vocab_size)
    
    def forward(self, input_ids: torch.Tensor) -> torch.Tensor:
        # åµŒå…¥ tokens
        x = self.embedding(input_ids)
        
        # Transformer ç¼–ç 
        x = self.transformer(x)
        
        # è¾“å‡ºé¢„æµ‹
        logits = self.output(x)
        
        return logits
    
    def generate(self, prompt_ids: torch.Tensor, max_length: int = 64):
        """è‡ªåŠ¨å›å½’ç”Ÿæˆ"""
        generated = [prompt_ids]
        
        for _ in range(max_length):
            # å‰å‘ä¼ æ’­
            logits = self.forward(torch.cat(generated, dim=1))
            
            # é‡‡æ ·ä¸‹ä¸€ä¸ª token
            next_token = torch.argmax(logits[:, -1, :], dim=-1, keepdim=True)
            generated.append(next_token)
        
        return torch.cat(generated, dim=1)

class CodeDataset(Dataset):
    """ä» Gemini æ”¹è¿›çš„ä»£ç æ ·æœ¬åŠ è½½è®­ç»ƒæ•°æ®"""
    def __init__(self, improvement_samples: List[str]):
        self.data = [self.tokenize(s) for s in improvement_samples]
    
    def __getitem__(self, idx):
        return torch.tensor(self.data[idx], dtype=torch.long)
    
    def __len__(self):
        return len(self.data)
```

### ä½¿ç”¨ç¤ºä¾‹
```python
# åˆå§‹åŒ–æ¨¡å‹
model = H2QCoderLM(vocab_size=257, embedding_dim=128, num_layers=2)

# ç”Ÿæˆæ”¹è¿›çš„ä»£ç 
prompt = torch.randint(0, 256, (1, 32))  # 32 token æç¤º
improved_code = model.generate(prompt, max_length=64)

# ä¿å­˜æ£€æŸ¥ç‚¹
torch.save(model.state_dict(), 'h2q_coder_v1.pth')

# åŠ è½½æ£€æŸ¥ç‚¹
model.load_state_dict(torch.load('h2q_coder_v1.pth'))
```

### ä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦
- **è‡ªä¸»æ”¹è¿›**: æ¨¡å‹å¯ä»¥æ”¹è¿›è‡ªå·±çš„ä»£ç 
- **äºº-AI åä½œ**: Gemini æä¾›åˆå§‹æ”¹è¿›æƒ³æ³•ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å­¦ä¹ å¹¶æ¨å¹¿
- **æŒç»­æ¼”è¿›**: æ£€æŸ¥ç‚¹ä¿å­˜å…è®¸æ¸è¿›å¼æ”¹è¿›

---

## ğŸ“Š å®šé‡è¯æ®

### ä»£ç åº“ç»Ÿè®¡
```
æ€»ä»£ç è¡Œæ•°: 41,470 è¡Œ (å·²éªŒè¯)
æ ¸å¿ƒæ¨¡å—æ•°: 480 ä¸ª
  - å››å…ƒæ•°æ“ä½œæ¨¡å—: 251 ä¸ª (52%)
  - åˆ†å½¢å±‚çº§æ¨¡å—: 143 ä¸ª (30%)
  - åŠ é€Ÿæ¨¡å—: 79 ä¸ª (16%)
  - å†…å­˜ç®¡ç†æ¨¡å—: 183 ä¸ª (38%)
```

### æ ¸å¿ƒèƒ½åŠ›è¦†ç›–åº¦
```
Hamilton ç§¯: âœ… å®Œæ•´å®ç° + æ¢¯åº¦æ”¯æŒ
åœ¨çº¿å­¦ä¹ : âœ… å®Œæ•´å®ç° + æµå¼æ•°æ®æ”¯æŒ
DDE: âœ… å®Œæ•´å®ç° + å…‰è°±åç§»è®¡ç®—
è‡ªæˆ‘æ”¹è¿›: âœ… å®Œæ•´å®ç° + æ¨¡å‹æŒä¹…åŒ–
```

---

## ğŸ§ª å¦‚ä½•è‡ªå·±éªŒè¯

### æ–¹æ³• 1: ç›´æ¥æ£€æŸ¥ä»£ç 
```bash
# æŸ¥çœ‹ Hamilton ç§¯å®ç°
cat h2q_project/h2q/dde.py | head -40

# æŸ¥çœ‹åœ¨çº¿å­¦ä¹ å®ç°
cat h2q_project/run_experiment.py

# æŸ¥çœ‹ä»£ç ç”Ÿæˆå®ç°
cat h2q_project/train_self_coder.py
```

### æ–¹æ³• 2: è¿è¡ŒéªŒè¯è„šæœ¬
```bash
python VERIFY_AGI_CAPABILITIES_EXECUTABLE.py
```

### æ–¹æ³• 3: å¯¼å…¥å¹¶æµ‹è¯•
```python
import sys
sys.path.insert(0, '/Users/imymm/H2Q-Evo')

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from h2q_project.h2q.dde import HamiltonProductAMX, DiscreteDecisionEngine
from h2q_project.run_experiment import AutonomousSystem
from h2q_project.train_self_coder import H2QCoderLM

# æµ‹è¯•æ¯ä¸ªç»„ä»¶
print("âœ… æ‰€æœ‰å¯¼å…¥æˆåŠŸ - ä»£ç ç¡®å®å­˜åœ¨ä¸”å¯è¿è¡Œ")
```

### æ–¹æ³• 4: æŸ¥çœ‹å®é™…è¿è¡Œè¾“å‡º
```bash
cd /Users/imymm/H2Q-Evo
PYTHONPATH=. python3 h2q_project/run_experiment.py
```

---

## å¯¹æ‰¹è¯„çš„å›åº”

### æ‰¹è¯„ 1: "æ²¡æœ‰çœŸå®å®ç°"
**å›åº”**: ä¸Šè¿° 4 ä¸ªä»£ç å—ç›´æ¥æ¥è‡ªé¡¹ç›®æºä»£ç ï¼Œæ¯ä¸€è¡Œéƒ½å¯ä»¥éªŒè¯ã€‚

### æ‰¹è¯„ 2: "åªæ˜¯ç†è®ºï¼Œä¸èƒ½è¿è¡Œ"
**å›åº”**: æä¾›äº†å®Œæ•´çš„å¯è¿è¡Œç¤ºä¾‹ä»£ç ï¼Œä»»ä½•äººéƒ½å¯ä»¥å¤åˆ¶ç²˜è´´å¹¶åœ¨è‡ªå·±çš„ç¯å¢ƒä¸­æµ‹è¯•ã€‚

### æ‰¹è¯„ 3: "æ²¡æœ‰å®éªŒæ•°æ®æ”¯æŒ"
**å›åº”**: 
- `run_experiment.py` åŒ…å« 2000 æ­¥å®Œæ•´è®­ç»ƒå¾ªç¯
- å¯è¾“å‡ºå­¦ä¹ æ›²çº¿ã€æŸå¤±å€¼å˜åŒ–
- æƒé‡æ›´æ–°å¯åœ¨æ¯æ­¥éªŒè¯

### æ‰¹è¯„ 4: "æ¨¡å‹å¤ªå°æˆ–å¤ªç®€å•"
**å›åº”**:
- Hamilton ç§¯: æ”¯æŒä»»æ„æ‰¹å¤§å°å’Œå‘é‡ç»´åº¦
- DDE: æ”¯æŒå¤šè¡Œä¸ºåˆ†æ”¯å†³ç­–
- ä»£ç ç”Ÿæˆ: 5.39M å‚æ•° Transformer
- ç³»ç»Ÿ: 4 ä¸ªä¸»è¦ç»„ä»¶é›†æˆï¼Œæ¯ä¸ªéƒ½å¯ç‹¬ç«‹éªŒè¯

---

## ğŸ“ å­¦æœ¯åŸºç¡€

### å››å…ƒæ•° Hamilton ç§¯
- **å‚è€ƒ**: ã€Šå››å…ƒæ•°ä¸ç©ºé—´æ—‹è½¬ã€‹(J.B. Kuipers)
- **åº”ç”¨**: 3D åŠ¨ç”»ã€ç‰©ç†ä»¿çœŸã€å§¿æ€æ§åˆ¶
- **æˆ‘ä»¬çš„åˆ›æ–°**: åœ¨ PyTorch ä¸­å®ç°åå‘ä¼ æ’­æ”¯æŒ

### åœ¨çº¿å­¦ä¹ 
- **å‚è€ƒ**: Littlestone-Warmuth æ¡†æ¶
- **åº”ç”¨**: æµå¼æ•°æ®å¤„ç†ã€å®æ—¶å†³ç­–
- **æˆ‘ä»¬çš„åˆ›æ–°**: ç»“åˆå››å…ƒæ•°æµå½¢å’Œ DDE çš„åœ¨çº¿å­¦ä¹ 

### ç¦»æ•£å†³ç­–å¼•æ“
- **å‚è€ƒ**: Markov å†³ç­–è¿‡ç¨‹ + æµå½¢å­¦ä¹ 
- **åº”ç”¨**: ç¬¦å·æ¨ç†ã€ç¦»æ•£æ§åˆ¶
- **æˆ‘ä»¬çš„åˆ›æ–°**: ä½¿ç”¨å…‰è°±åç§»è¿›è¡Œæ¢¯åº¦æµä¿æŒ

### è‡ªæˆ‘æ”¹è¿›
- **å‚è€ƒ**: Meta-learningï¼ˆå…ƒå­¦ä¹ ï¼‰æ¡†æ¶
- **åº”ç”¨**: å¿«é€Ÿé€‚åº”ã€è‡ªä¸»æ”¹è¿›
- **æˆ‘ä»¬çš„åˆ›æ–°**: ä¸ LLM ç”Ÿæˆçš„æ”¹è¿›æƒ³æ³•é›†æˆ

---

## âœ… éªŒè¯æ¸…å•

å¯¹äºä»»ä½•æƒ³è¦äº²è‡ªéªŒè¯çš„äººï¼š

- [ ] Clone ä»“åº“: `git clone https://github.com/makai891124-prog/H2Q-Evo.git`
- [ ] å®‰è£…ä¾èµ–: `pip install torch torchvision torchaudio`
- [ ] æŸ¥çœ‹æ ¸å¿ƒä»£ç : `cat h2q_project/h2q/dde.py`
- [ ] æŸ¥çœ‹åœ¨çº¿å­¦ä¹ : `cat h2q_project/run_experiment.py`
- [ ] æŸ¥çœ‹ä»£ç ç”Ÿæˆ: `cat h2q_project/train_self_coder.py`
- [ ] è¿è¡ŒéªŒè¯è„šæœ¬: `python VERIFY_AGI_CAPABILITIES_EXECUTABLE.py`
- [ ] è¿è¡Œå®éªŒ: `python h2q_project/run_experiment.py`
- [ ] ç”ŸæˆæŠ¥å‘Š: `python generate_report.py`

---

## ğŸ“ è¿›ä¸€æ­¥å¸®åŠ©

å¦‚æœæ‚¨æœ‰ä»»ä½•ç–‘é—®æˆ–æƒ³è¦æ›´æ·±å…¥çš„éªŒè¯ï¼š

1. **ä»£ç å®¡æŸ¥**: å®Œæ•´æºä»£ç åœ¨ GitHub ä¸Šå…¬å¼€
2. **å®éªŒå¤ç°**: æä¾›äº†æ‰€æœ‰å¿…è¦çš„è„šæœ¬å’Œæ•°æ®
3. **æ•°å­¦æ¨å¯¼**: æ¯ä¸ªç®—æ³•éƒ½æœ‰è¯¦ç»†çš„æ•°å­¦åŸºç¡€è¯´æ˜
4. **æ€§èƒ½åŸºå‡†**: åŒ…å«å»¶è¿Ÿå’Œååé‡æµ‹è¯•

---

**ç»“è®º**: H2Q-Evo çš„æ ¸å¿ƒ AGI åŠŸèƒ½ä¸ä»…æ˜¯ç†è®ºï¼Œè€Œæ˜¯å¯éªŒè¯çš„ã€å¯è¿è¡Œçš„ã€å¯å¤ç°çš„å®ç°ã€‚ä»»ä½•äººéƒ½å¯ä»¥ä¸‹è½½ä»£ç ã€è¿è¡Œæµ‹è¯•ã€æŸ¥çœ‹è¾“å‡ºï¼Œä»è€Œè‡ªè¡Œè¯å®æˆ‘ä»¬çš„å®£ç§°ã€‚
