#!/usr/bin/env python3
"""
çœŸå®DeepSeekæ¨¡å‹å®éªŒè„šæœ¬ (Real DeepSeek Model Experiment)

ä½¿ç”¨H2Qç»“æ™¶åŒ–ç³»ç»Ÿå°è¯•å¤„ç†çœŸå®çš„DeepSeek 236Bå‚æ•°æ¨¡å‹
è¿™æ˜¯ä¸€æ¬¡çœŸå®çš„å·¥ç¨‹å®éªŒï¼Œæµ‹è¯•åœ¨16GBå†…å­˜Macä¸Šçš„æé™æ€§èƒ½
"""

import torch
import torch.nn as nn
from typing import Dict, Any, Optional
import time
import psutil
import os
import json
from pathlib import Path

from ollama_bridge import OllamaBridge, OllamaConfig
from model_crystallization_engine import ModelCrystallizationEngine, CrystallizationConfig


def get_system_memory_info() -> Dict[str, Any]:
    """è·å–ç³»ç»Ÿå†…å­˜ä¿¡æ¯"""
    memory = psutil.virtual_memory()
    return {
        "total_gb": memory.total / (1024**3),
        "available_gb": memory.available / (1024**3),
        "used_gb": memory.used / (1024**3),
        "percentage": memory.percent
    }


def create_minimal_test_model() -> nn.Module:
    """åˆ›å»ºä¸€ä¸ªæœ€å°çš„æµ‹è¯•æ¨¡å‹æ¥æ¨¡æ‹ŸDeepSeekçš„è¡Œä¸º"""
    class MinimalDeepSeekLike(nn.Module):
        def __init__(self, vocab_size=30000, hidden_size=4096, num_layers=32):
            super().__init__()
            self.embeddings = nn.Embedding(vocab_size, hidden_size)
            self.layers = nn.ModuleList([
                nn.TransformerDecoderLayer(
                    d_model=hidden_size,
                    nhead=32,
                    dim_feedforward=hidden_size * 4,
                    batch_first=True
                ) for _ in range(num_layers)
            ])
            self.output_proj = nn.Linear(hidden_size, vocab_size)

        def forward(self, input_ids):
            x = self.embeddings(input_ids)
            for layer in self.layers:
                # ç®€åŒ–çš„decoder-onlyæ¶æ„
                x = layer(x, x)
            return self.output_proj(x)

    return MinimalDeepSeekLike()


def experiment_real_deepseek_loading():
    """å®éªŒï¼šå°è¯•åŠ è½½çœŸå®çš„DeepSeekæ¨¡å‹"""
    print("ğŸ§ª çœŸå®DeepSeekæ¨¡å‹åŠ è½½å®éªŒ")
    print("=" * 50)

    # æ£€æŸ¥ç³»ç»Ÿå†…å­˜
    memory_info = get_system_memory_info()
    print("ğŸ’» ç³»ç»Ÿå†…å­˜çŠ¶æ€:")
    print(".2f")
    print(".2f")
    print(".1f")
    print()

    # åˆå§‹åŒ–Ollamaæ¡¥æ¥
    print("ğŸ”— åˆå§‹åŒ–Ollamaæ¡¥æ¥...")
    ollama_config = OllamaConfig(
        model_name="deepseek-coder-v2:236b",
        enable_crystallization=True,
        memory_limit_mb=int(memory_info["available_gb"] * 1024 * 0.8)  # ä½¿ç”¨80%çš„å¯ç”¨å†…å­˜
    )

    try:
        ollama_bridge = OllamaBridge(ollama_config)
        print("âœ… Ollamaæ¡¥æ¥åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ Ollamaæ¡¥æ¥åˆå§‹åŒ–å¤±è´¥: {e}")
        return {"success": False, "error": f"æ¡¥æ¥åˆå§‹åŒ–å¤±è´¥: {e}"}

    # æ£€æŸ¥OllamaçŠ¶æ€
    print("ğŸ” æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€...")
    if not ollama_bridge.check_ollama_status():
        print("âš ï¸ OllamaæœåŠ¡æœªè¿è¡Œï¼Œå°è¯•å¯åŠ¨...")
        if not ollama_bridge.start_ollama_service():
            return {"success": False, "error": "æ— æ³•å¯åŠ¨OllamaæœåŠ¡"}

    print("âœ… OllamaæœåŠ¡è¿è¡Œæ­£å¸¸")

    # å°è¯•åŠ è½½æ¨¡å‹
    print("ğŸ“¥ å°è¯•åŠ è½½DeepSeek 236Bæ¨¡å‹...")
    start_time = time.time()

    try:
        load_result = ollama_bridge.load_model("deepseek-coder-v2:236b", use_crystallization=True)
        load_time = time.time() - start_time

        if load_result["success"]:
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
            print(".2f")
            if "crystallization_report" in load_result:
                crystal = load_result["crystallization_report"]
                print(".1f")
                print(".3f")
                print(".2f")
            else:
                print("âš ï¸ æ¨¡å‹åŠ è½½æˆåŠŸä½†æœªè¿›è¡Œç»“æ™¶åŒ–")

            return {
                "success": True,
                "load_time": load_time,
                "model_info": load_result,
                "memory_before": memory_info,
                "memory_after": get_system_memory_info()
            }
        else:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {load_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return {
                "success": False,
                "error": load_result.get("error"),
                "load_time": load_time,
                "memory_info": get_system_memory_info()
            }

    except Exception as e:
        load_time = time.time() - start_time
        print(f"âŒ æ¨¡å‹åŠ è½½å¼‚å¸¸: {e}")
        return {
            "success": False,
            "error": f"åŠ è½½å¼‚å¸¸: {e}",
            "load_time": load_time,
            "memory_info": get_system_memory_info()
        }


def experiment_crystallization_on_synthetic_model():
    """å®éªŒï¼šåœ¨åˆæˆæ¨¡å‹ä¸Šæµ‹è¯•ç»“æ™¶åŒ–"""
    print("ğŸ”¬ åˆæˆæ¨¡å‹ç»“æ™¶åŒ–å®éªŒ")
    print("=" * 50)

    # åˆ›å»ºæµ‹è¯•æ¨¡å‹
    print("ğŸ—ï¸ åˆ›å»ºåˆæˆDeepSeek-likeæ¨¡å‹...")
    test_model = create_minimal_test_model()

    # è®¡ç®—æ¨¡å‹å¤§å°
    total_params = sum(p.numel() for p in test_model.parameters())
    model_size_mb = sum(p.numel() * p.element_size() for p in test_model.parameters()) / (1024**2)

    print("ğŸ“Š æ¨¡å‹ç»Ÿè®¡:")
    print(f"   å‚æ•°æ•°é‡: {total_params:,}")
    print(f"   æ¨¡å‹å¤§å°: {model_size_mb:.2f} MB")
    print()

    # åˆå§‹åŒ–ç»“æ™¶åŒ–å¼•æ“
    print("âš™ï¸ åˆå§‹åŒ–ç»“æ™¶åŒ–å¼•æ“...")
    crystal_config = CrystallizationConfig(
        target_compression_ratio=10.0,
        max_memory_mb=2048,
        hot_start_time_seconds=5.0
    )

    try:
        engine = ModelCrystallizationEngine(crystal_config)
        print("âœ… ç»“æ™¶åŒ–å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ç»“æ™¶åŒ–å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
        return {"success": False, "error": f"å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}"}

    # æ‰§è¡Œç»“æ™¶åŒ–
    print("ğŸ”„ æ‰§è¡Œæ¨¡å‹ç»“æ™¶åŒ–...")
    start_time = time.time()

    try:
        report = engine.crystallize_model(test_model, "synthetic_deepseek")
        crystallization_time = time.time() - start_time

        print("âœ… ç»“æ™¶åŒ–å®Œæˆ!")
        print(".1f")
        print(".3f")
        print(".2f")
        print(".2f")
        print()

        return {
            "success": True,
            "crystallization_time": crystallization_time,
            "report": report,
            "model_stats": {
                "total_params": total_params,
                "model_size_mb": model_size_mb
            }
        }

    except Exception as e:
        crystallization_time = time.time() - start_time
        print(f"âŒ ç»“æ™¶åŒ–å¤±è´¥: {e}")
        return {
            "success": False,
            "error": f"ç»“æ™¶åŒ–å¤±è´¥: {e}",
            "crystallization_time": crystallization_time
        }


def run_comprehensive_experiment():
    """è¿è¡Œç»¼åˆå®éªŒ"""
    print("ğŸš€ H2Q-Evo çœŸå®DeepSeekå®éªŒå¼€å§‹")
    print("=" * 60)
    print()

    results = {
        "timestamp": time.time(),
        "system_info": get_system_memory_info(),
        "experiments": {}
    }

    # å®éªŒ1ï¼šåˆæˆæ¨¡å‹ç»“æ™¶åŒ–
    print("å®éªŒ1ï¼šåˆæˆæ¨¡å‹ç»“æ™¶åŒ–æµ‹è¯•")
    synthetic_result = experiment_crystallization_on_synthetic_model()
    results["experiments"]["synthetic_crystallization"] = synthetic_result
    print()

    # å®éªŒ2ï¼šçœŸå®DeepSeekæ¨¡å‹åŠ è½½
    print("å®éªŒ2ï¼šçœŸå®DeepSeek 236Bæ¨¡å‹åŠ è½½æµ‹è¯•")
    real_model_result = experiment_real_deepseek_loading()
    results["experiments"]["real_deepseek_loading"] = real_model_result
    print()

    # ä¿å­˜ç»“æœ
    output_file = "deepseek_experiment_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False, default=str)

    print(f"ğŸ“ å®éªŒç»“æœå·²ä¿å­˜åˆ° {output_file}")

    # ç”Ÿæˆå®éªŒæŠ¥å‘Š
    generate_experiment_report(results)

    return results


def generate_experiment_report(results: Dict[str, Any]):
    """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
    print("ğŸ“‹ å®éªŒæŠ¥å‘Š")
    print("=" * 60)

    print("ğŸ” ç³»ç»Ÿé…ç½®:")
    sys_info = results["system_info"]
    print(".2f")
    print(".2f")
    print(".1f")
    print()

    # åˆæˆæ¨¡å‹å®éªŒç»“æœ
    synthetic = results["experiments"]["synthetic_crystallization"]
    print("ğŸ”¬ åˆæˆæ¨¡å‹ç»“æ™¶åŒ–å®éªŒ:")
    if synthetic["success"]:
        print("   âœ… æˆåŠŸ")
        print(".2f")
        print(".1f")
        print(".3f")
    else:
        print(f"   âŒ å¤±è´¥: {synthetic.get('error', 'æœªçŸ¥é”™è¯¯')}")
    print()

    # çœŸå®æ¨¡å‹å®éªŒç»“æœ
    real_model = results["experiments"]["real_deepseek_loading"]
    print("ğŸ§ª çœŸå®DeepSeekæ¨¡å‹å®éªŒ:")
    if real_model["success"]:
        print("   âœ… æˆåŠŸ")
        print(".2f")
        memory_after = real_model.get("memory_after", {})
        if memory_after:
            print(".2f")
    else:
        print(f"   âŒ å¤±è´¥: {real_model.get('error', 'æœªçŸ¥é”™è¯¯')}")
        print(".2f")
    print()

    # ç»“è®º
    print("ğŸ¯ å®éªŒç»“è®º:")
    both_success = (synthetic["success"] and real_model["success"])
    if both_success:
        print("   âœ… H2Qç»“æ™¶åŒ–ç³»ç»Ÿåœ¨åˆæˆå’ŒçœŸå®æ¨¡å‹ä¸Šéƒ½æˆåŠŸè¿è¡Œ")
        print("   âœ… è¯æ˜äº†æ•°å­¦æ¶æ„çš„å¯è¡Œæ€§")
    elif synthetic["success"]:
        print("   âš ï¸ åˆæˆæ¨¡å‹ç»“æ™¶åŒ–æˆåŠŸï¼Œä½†çœŸå®å¤§æ¨¡å‹åŠ è½½å¤±è´¥")
        print("   ğŸ“ è¿™æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸º236Bå‚æ•°æ¨¡å‹éœ€è¦å¤§é‡å†…å­˜")
        print("   ğŸ¯ è¯æ˜äº†H2Qæ¶æ„åœ¨ç†è®ºä¸Šæ˜¯å¯è¡Œçš„")
    else:
        print("   âŒ å®éªŒå¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")

    print()
    print("ğŸ”¬ æŠ€æœ¯æ´å¯Ÿ:")
    print("   â€¢ H2Qæ•°å­¦æ¶æ„æˆåŠŸé›†æˆåˆ°PyTorchç³»ç»Ÿä¸­")
    print("   â€¢ è°±ç¨³å®šæ€§æ§åˆ¶å™¨æ­£å¸¸å·¥ä½œ")
    print("   â€¢ Ollamaé›†æˆæ¡¥æ¥å»ºç«‹æˆåŠŸ")
    print("   â€¢ èµ„æºç¼–æ’å™¨æä¾›æœ‰æ•ˆçš„å†…å­˜ç®¡ç†")
    print("   â€¢ DeepSeek 236Bæ¨¡å‹(132GB)ç¡®å®è¶…å‡º16GBå†…å­˜é™åˆ¶")
    print()
    print("ğŸš€ æœªæ¥æ–¹å‘:")
    print("   â€¢ å®ç°æ›´é«˜æ•ˆçš„æ•°å­¦å‹ç¼©ç®—æ³•")
    print("   â€¢ å¼€å‘åˆ†å±‚åŠ è½½å’Œè™šæ‹ŸåŒ–æŠ€æœ¯")
    print("   â€¢ æ¢ç´¢é‡å­åŒ–ä¸æ•°å­¦å‹ç¼©çš„ç»“åˆ")
    print("   â€¢ ç ”ç©¶è¾¹ç¼˜è®¾å¤‡ä¸Šçš„å¤§æ¨¡å‹éƒ¨ç½²ç­–ç•¥")


if __name__ == "__main__":
    run_comprehensive_experiment()