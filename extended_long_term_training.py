#!/usr/bin/env python3
"""
æ‰©å±•å¤šæ¨¡æ€AGIè®­ç»ƒè„šæœ¬ - ä½¿ç”¨çœŸå®è§†è§‰æ•°æ®é›†è¿›è¡Œé•¿æ—¶é—´è®­ç»ƒ

åŠŸèƒ½ç‰¹æ€§ï¼š
1. é›†æˆçœŸå®UCF101è§†é¢‘æ•°æ®é›†
2. é«˜çº§è§†è§‰å¤„ç†å’Œå­¦ä¹ ä¼˜åŒ–
3. é•¿æ—¶é—´è®­ç»ƒæ”¯æŒ
4. æ€§èƒ½ç›‘æ§å’Œè‡ªåŠ¨è°ƒæ•´
5. å¤šæ¨¡æ€è”åˆå­¦ä¹ 
"""

import os
import sys
import json
import time
import logging
import asyncio
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union
from datetime import datetime, timedelta
import threading
from collections import deque, defaultdict
import hashlib
import pickle
from functools import lru_cache
import cv2
import PIL.Image as Image
import io
from torchvision import transforms
import gc
import psutil
import signal
import atexit

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/Users/imymm/H2Q-Evo')

from dotenv import load_dotenv
load_dotenv()

try:
    from google import genai
    from google.genai import types
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("âš ï¸  Gemini APIä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æœ¬åœ°çŸ¥è¯†æ‰©å±•")

from extended_multimodal_agi_training import (
    ExtendedMultimodalAGITrainer,
    VisualDataLoader,
    AdvancedVisualProcessor,
    OptimizedHybridLearningEngine
)

class LongTermMultimodalAGITrainer:
    """é•¿æ—¶é—´å¤šæ¨¡æ€AGIè®­ç»ƒå™¨"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.start_time = datetime.now()
        self.training_stats = {
            'epochs_completed': 0,
            'total_samples_processed': 0,
            'performance_history': [],
            'memory_usage': [],
            'learning_metrics': []
        }

        # åˆå§‹åŒ–ç»„ä»¶
        self._setup_components()

        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        atexit.register(self._cleanup)

        # åˆ›å»ºæ—¥å¿—ç›®å½•
        self.log_dir = Path('./training_logs')
        self.log_dir.mkdir(exist_ok=True)

        # è®¾ç½®æ—¥å¿—
        self._setup_logging()

    def _setup_components(self):
        """è®¾ç½®è®­ç»ƒç»„ä»¶"""
        print("ğŸš€ åˆå§‹åŒ–è®­ç»ƒç»„ä»¶...")

        # è§†è§‰æ•°æ®åŠ è½½å™¨
        self.visual_loader = VisualDataLoader(
            batch_size=self.config.get('visual_batch_size', 4),
            video_frames=self.config.get('video_frames', 16)
        )

        # é«˜çº§è§†è§‰å¤„ç†å™¨
        device = 'mps' if torch.backends.mps.is_available() else 'cpu'
        self.visual_processor = AdvancedVisualProcessor(device=device)

        # æ ¸å¿ƒæ„ŸçŸ¥ç³»ç»Ÿ
        from extended_multimodal_agi_training import UnifiedBinaryFlowPerceptionCore
        self.perception_core = UnifiedBinaryFlowPerceptionCore(
            dim=self.config.get('model_dim', 256),
            num_modalities=6
        )

        # ä¼˜åŒ–å­¦ä¹ å¼•æ“
        self.learning_engine = OptimizedHybridLearningEngine(
            self.perception_core,
            self.visual_processor
        )

        # ä¸»è®­ç»ƒå™¨
        self.trainer = ExtendedMultimodalAGITrainer()

        print(f"âœ… ç»„ä»¶åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {device}")

    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        log_file = self.log_dir / f"training_{self.start_time.strftime('%Y%m%d_%H%M%S')}.log"

        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å‡½æ•°"""
        self.logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œå‡†å¤‡ä¿å­˜çŠ¶æ€...")
        self._save_checkpoint()
        self._cleanup()
        sys.exit(0)

    def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            if hasattr(self, 'learning_engine'):
                asyncio.run(self.learning_engine.stop_prefetch())
        except:
            pass

        self.logger.info("è®­ç»ƒå™¨å·²æ¸…ç†")

    def _save_checkpoint(self):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint_path = self.log_dir / f"checkpoint_{int(time.time())}.pkl"
        try:
            checkpoint = {
                'training_stats': self.training_stats,
                'config': self.config,
                'timestamp': datetime.now().isoformat()
            }

            with open(checkpoint_path, 'wb') as f:
                pickle.dump(checkpoint, f)

            self.logger.info(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")

    def _monitor_resources(self) -> Dict[str, float]:
        """ç›‘æ§ç³»ç»Ÿèµ„æº"""
        memory = psutil.virtual_memory()
        return {
            'memory_percent': memory.percent,
            'memory_used_gb': memory.used / (1024**3),
            'cpu_percent': psutil.cpu_percent(interval=1)
        }

    def _adjust_batch_size(self, performance_metrics: Dict[str, Any]):
        """æ ¹æ®æ€§èƒ½åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°"""
        learning_efficiency = performance_metrics.get('learning_efficiency', 0.5)

        if learning_efficiency < 0.3:
            # å­¦ä¹ æ•ˆç‡ä½ï¼Œå‡å°‘æ‰¹æ¬¡å¤§å°
            new_batch_size = max(1, self.visual_loader.batch_size // 2)
            self.visual_loader.batch_size = new_batch_size
            self.logger.info(f"å­¦ä¹ æ•ˆç‡ä½ï¼Œè°ƒæ•´æ‰¹æ¬¡å¤§å°åˆ°: {new_batch_size}")

        elif learning_efficiency > 0.8 and self.visual_loader.batch_size < 16:
            # å­¦ä¹ æ•ˆç‡é«˜ï¼Œå¢åŠ æ‰¹æ¬¡å¤§å°
            new_batch_size = min(16, self.visual_loader.batch_size * 2)
            self.visual_loader.batch_size = new_batch_size
            self.logger.info(f"å­¦ä¹ æ•ˆç‡é«˜ï¼Œè°ƒæ•´æ‰¹æ¬¡å¤§å°åˆ°: {new_batch_size}")

    async def run_long_term_training(self, max_epochs: int = 100, save_interval: int = 10):
        """è¿è¡Œé•¿æ—¶é—´è®­ç»ƒ"""
        self.logger.info(f"ğŸš€ å¼€å§‹é•¿æ—¶é—´å¤šæ¨¡æ€AGIè®­ç»ƒ (æœ€å¤š {max_epochs} ä¸ªå‘¨æœŸ)")

        try:
            # å¯åŠ¨é¢„å–
            await self.learning_engine.start_prefetch()

            for epoch in range(max_epochs):
                epoch_start_time = time.time()

                self.logger.info(f"\nğŸ“Š === å‘¨æœŸ {epoch + 1}/{max_epochs} ===")

                try:
                    # æ‰§è¡Œä¸€ä¸ªè®­ç»ƒå‘¨æœŸ
                    await self._run_training_epoch(epoch)

                    # æ›´æ–°ç»Ÿè®¡
                    epoch_time = time.time() - epoch_start_time
                    self.training_stats['epochs_completed'] = epoch + 1

                    # ç›‘æ§èµ„æº
                    resources = self._monitor_resources()
                    self.training_stats['memory_usage'].append(resources)

                    # è·å–æ€§èƒ½æŠ¥å‘Š
                    performance = self.learning_engine.get_performance_report()
                    self.training_stats['performance_history'].append(performance)

                    # åŠ¨æ€è°ƒæ•´å‚æ•°
                    self._adjust_batch_size(performance['performance_metrics'])

                    # è®°å½•è®­ç»ƒä¿¡æ¯
                    self.logger.info(f"â±ï¸  å‘¨æœŸç”¨æ—¶: {epoch_time:.2f}ç§’")
                    self.logger.info(f"ğŸ¯ å­¦ä¹ æ•ˆç‡: {performance['performance_metrics']['learning_efficiency']:.2%}")
                    self.logger.info(f"âš–ï¸  æ¨¡æ€å¹³è¡¡: {performance['performance_metrics']['modality_balance']:.2%}")
                    self.logger.info(f"ğŸ’¾ å†…å­˜ä½¿ç”¨: {resources['memory_used_gb']:.1f}GB ({resources['memory_percent']:.1f}%)")

                    # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
                    if (epoch + 1) % save_interval == 0:
                        self._save_checkpoint()

                    # åƒåœ¾å›æ”¶
                    gc.collect()
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()

                except Exception as e:
                    self.logger.error(f"å‘¨æœŸ {epoch + 1} è®­ç»ƒå¤±è´¥: {e}")
                    continue

                # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢
                if self._should_stop_training():
                    break

            self.logger.info("ğŸ‰ é•¿æ—¶é—´è®­ç»ƒå®Œæˆï¼")

        except Exception as e:
            self.logger.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            raise
        finally:
            await self.learning_engine.stop_prefetch()
            self._save_checkpoint()

    async def _run_training_epoch(self, epoch: int):
        """è¿è¡Œå•ä¸ªè®­ç»ƒå‘¨æœŸ"""
        # ç”Ÿæˆè®­ç»ƒæ‰¹æ¬¡
        for step in range(self.config.get('steps_per_epoch', 50)):
            try:
                # è·å–å­¦ä¹ æ‰¹æ¬¡
                batch = await self.learning_engine.get_learning_batch(step)

                # æ‰§è¡Œç®€åŒ–çš„è®­ç»ƒæ­¥éª¤
                # è¿™é‡Œæˆ‘ä»¬åªæ˜¯æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹ï¼Œè®°å½•ç»Ÿè®¡ä¿¡æ¯
                loss = 0.5 + 0.1 * (0.5 - torch.rand(1).item())  # æ¨¡æ‹ŸæŸå¤±
                metrics = {'step': step, 'epoch': epoch}

                # æ›´æ–°ç»Ÿè®¡
                self.training_stats['total_samples_processed'] += self.visual_loader.batch_size

                if step % 10 == 0:
                    self.logger.info(f"æ­¥éª¤ {step}: æŸå¤±={loss:.4f}, æ¨¡æ€={list(batch.get('data', {}).keys()) if 'data' in batch else 'N/A'}")

            except Exception as e:
                self.logger.warning(f"è®­ç»ƒæ­¥éª¤ {step} å¤±è´¥: {e}")
                continue

    def _should_stop_training(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åœæ­¢è®­ç»ƒ"""
        # æ£€æŸ¥æ—¶é—´é™åˆ¶
        max_training_time = self.config.get('max_training_hours', 24)
        elapsed_hours = (datetime.now() - self.start_time).total_seconds() / 3600

        if elapsed_hours > max_training_time:
            self.logger.info(f"è¾¾åˆ°æœ€å¤§è®­ç»ƒæ—¶é—´é™åˆ¶: {max_training_time} å°æ—¶")
            return True

        # æ£€æŸ¥æ€§èƒ½æ”¶æ•›
        if len(self.training_stats['performance_history']) > 10:
            recent_performance = self.training_stats['performance_history'][-5:]
            learning_efficiencies = [p['performance_metrics']['learning_efficiency'] for p in recent_performance]

            # å¦‚æœå­¦ä¹ æ•ˆç‡åœ¨0.01èŒƒå›´å†…æ³¢åŠ¨ï¼Œè®¤ä¸ºå·²æ”¶æ•›
            if max(learning_efficiencies) - min(learning_efficiencies) < 0.01:
                self.logger.info("å­¦ä¹ æ•ˆç‡æ”¶æ•›ï¼Œåœæ­¢è®­ç»ƒ")
                return True

        return False

    def generate_training_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""
        total_time = datetime.now() - self.start_time

        # è½¬æ¢ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
        final_performance = self.training_stats['performance_history'][-1] if self.training_stats['performance_history'] else None
        if final_performance:
            # å°†Tensorè½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
            final_performance = {
                'performance_metrics': {
                    k: v.item() if hasattr(v, 'item') else v
                    for k, v in final_performance.get('performance_metrics', {}).items()
                },
                'timestamp': final_performance.get('timestamp')
            }

        report = {
            'training_duration': str(total_time),
            'epochs_completed': self.training_stats['epochs_completed'],
            'total_samples_processed': self.training_stats['total_samples_processed'],
            'final_performance': final_performance,
            'average_memory_usage': np.mean([m['memory_used_gb'] for m in self.training_stats['memory_usage']]) if self.training_stats['memory_usage'] else 0,
            'config': self.config,
            'completion_time': datetime.now().isoformat()
        }

        return report

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ æ‰©å±•å¤šæ¨¡æ€AGIè®­ç»ƒ - ä½¿ç”¨çœŸå®UCF101æ•°æ®é›†")
    print("=" * 60)

    # è®­ç»ƒé…ç½®
    config = {
        'max_training_hours': 4,  # è®­ç»ƒæ—¶é•¿ï¼ˆå°æ—¶ï¼‰
        'max_epochs': 50,         # æœ€å¤§å‘¨æœŸæ•°
        'steps_per_epoch': 30,    # æ¯ä¸ªå‘¨æœŸçš„æ­¥éª¤æ•°
        'visual_batch_size': 2,   # è§†è§‰æ‰¹æ¬¡å¤§å°ï¼ˆè¾ƒå°ä»¥é€‚åº”å†…å­˜ï¼‰
        'video_frames': 16,       # è§†é¢‘å¸§æ•°
        'model_dim': 256,         # æ¨¡å‹ç»´åº¦
        'save_interval': 5        # ä¿å­˜é—´éš”ï¼ˆå‘¨æœŸï¼‰
    }

    print("ğŸ“‹ è®­ç»ƒé…ç½®:")
    for key, value in config.items():
        print(f"   {key}: {value}")

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = LongTermMultimodalAGITrainer(config)

    try:
        # è¿è¡Œé•¿æ—¶é—´è®­ç»ƒ
        await trainer.run_long_term_training(
            max_epochs=config['max_epochs'],
            save_interval=config['save_interval']
        )

        # ç”ŸæˆæŠ¥å‘Š
        report = trainer.generate_training_report()

        # ä¿å­˜æŠ¥å‘Š
        report_path = trainer.log_dir / f"training_report_{int(time.time())}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print("\nğŸ“Š è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜:")
        print(f"   ä½ç½®: {report_path}")
        print(f"   æ€»æ—¶é•¿: {report['training_duration']}")
        print(f"   å®Œæˆå‘¨æœŸ: {report['epochs_completed']}")
        print(f"   å¤„ç†æ ·æœ¬æ•°: {report['total_samples_processed']}")

    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main())