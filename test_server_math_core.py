#!/usr/bin/env python3
"""
æµ‹è¯•h2q_serveré‡æ„çš„æ ¸å¿ƒæ•°å­¦ç»„ä»¶ï¼ˆä¸éœ€è¦FastAPIï¼‰
"""
import sys
import torch
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent / "h2q_project"))

def test_unified_architecture_integration():
    """æµ‹è¯•ç»Ÿä¸€æ¶æ„é›†æˆ"""
    try:
        from h2q.core.unified_architecture import (
            UnifiedH2QMathematicalArchitecture,
            get_unified_h2q_architecture
        )
        from h2q.core.evolution_integration import MathematicalArchitectureEvolutionBridge
        
        print("ğŸ“ æµ‹è¯•ç»Ÿä¸€æ¶æ„...")
        
        # åˆ›å»ºæ¶æ„
        unified = get_unified_h2q_architecture(dim=128, action_dim=32, device='cpu')
        print(f"   âœ… åˆ›å»ºæˆåŠŸ: {type(unified).__name__}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        x = torch.randn(4, 128)
        output, info = unified(x)
        
        print(f"   âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"      è¾“å…¥: {x.shape}")
        print(f"      è¾“å‡º: {output.shape}")
        print(f"      å¯ç”¨æ¨¡å—: {info.get('enabled_modules', [])}")
        print(f"      å…¨å±€å®Œæ•´æ€§: {info.get('global_integrity', 0.0):.4f}")
        
        return True, info
        
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, None

def test_evolution_bridge():
    """æµ‹è¯•è¿›åŒ–æ¡¥æ¥å™¨"""
    try:
        from h2q.core.evolution_integration import MathematicalArchitectureEvolutionBridge
        
        print("\nğŸŒ‰ æµ‹è¯•è¿›åŒ–æ¡¥æ¥å™¨...")
        
        # åˆ›å»ºæ¡¥æ¥å™¨
        bridge = MathematicalArchitectureEvolutionBridge(dim=128, action_dim=32, device='cpu')
        print(f"   âœ… åˆ›å»ºæˆåŠŸ")
        
        # è¿è¡Œè¿›åŒ–æ­¥éª¤
        x = torch.randn(4, 128)
        learning_signal = torch.tensor([0.5])
        
        generations = 3
        history = []
        
        for gen in range(generations):
            results = bridge(x, learning_signal)
            history.append(results)
            print(f"   ä¸–ä»£ {gen+1}: norm={results['evolution_metrics']['output_norm']:.4f}")
        
        print(f"   âœ… å®Œæˆ{generations}ä»£è¿›åŒ–")
        print(f"      æœ€ç»ˆä¸–ä»£æ•°: {bridge.generation_count}")
        print(f"      å†å²è®°å½•: {len(bridge.evolution_history)} æ¡")
        
        return True, history
        
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, None

def simulate_chat_processing():
    """æ¨¡æ‹ŸèŠå¤©å¤„ç†æµç¨‹"""
    try:
        from h2q.core.unified_architecture import get_unified_h2q_architecture
        
        print("\nğŸ’¬ æ¨¡æ‹ŸèŠå¤©å¤„ç†...")
        
        # åˆ›å»ºæ¶æ„
        unified = get_unified_h2q_architecture(dim=256, action_dim=64, device='cpu')
        
        # æ¨¡æ‹Ÿç”¨æˆ·è¾“å…¥
        prompt = "Hello, H2Q!"
        
        # æ–‡æœ¬åˆ°å¼ é‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
        tokens = [ord(c) for c in prompt[:256]]
        tokens += [0] * (256 - len(tokens))
        input_tensor = torch.tensor(tokens, dtype=torch.float32).view(1, -1)
        
        print(f"   è¾“å…¥: '{prompt}'")
        print(f"   å¼ é‡: {input_tensor.shape}")
        
        # é€šè¿‡æ•°å­¦æ¶æ„å¤„ç†
        with torch.no_grad():
            output, info = unified(input_tensor)
        
        # æå–æ•°å­¦æ€§è´¨
        fueter_curvature = info.get('holomorphic_consistency', {}).get('fueter_gradient_norm', 0.0)
        spectral_shift = info.get('lie_group_properties', {}).get('lie_exponential_norm', 0.0)
        integrity = info.get('global_integrity', 1.0)
        
        print(f"   âœ… å¤„ç†æˆåŠŸ")
        print(f"      Fueteræ›²ç‡: {fueter_curvature:.6f}")
        print(f"      è°±ç§»: {spectral_shift:.6f}")
        print(f"      å®Œæ•´æ€§: {integrity:.6f}")
        print(f"      çŠ¶æ€: {'Analytic' if fueter_curvature <= 0.05 else 'Pruned/Healed'}")
        
        return True, info
        
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, None

def simulate_generate_processing():
    """æ¨¡æ‹Ÿç”Ÿæˆå¤„ç†æµç¨‹"""
    try:
        from h2q.core.unified_architecture import get_unified_h2q_architecture
        
        print("\nğŸ”® æ¨¡æ‹Ÿæ–‡æœ¬ç”Ÿæˆ...")
        
        unified = get_unified_h2q_architecture(dim=256, action_dim=64, device='cpu')
        
        prompt = "Generate:"
        max_new_tokens = 64
        
        # åˆå§‹åŒ–
        tokens = [ord(c) for c in prompt[:256]]
        tokens += [0] * (256 - len(tokens))
        input_tensor = torch.tensor(tokens, dtype=torch.float32).view(1, -1)
        
        print(f"   è¾“å…¥: '{prompt}'")
        print(f"   æœ€å¤§æ–°token: {max_new_tokens}")
        
        # ç”Ÿæˆ
        with torch.no_grad():
            output, info = unified(input_tensor)
        
        # æå–å‰max_new_tokensä¸ªå€¼
        generated = output[0, :max_new_tokens]
        
        print(f"   âœ… ç”ŸæˆæˆåŠŸ")
        print(f"      è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"      ç”Ÿæˆtokens: {generated.shape}")
        print(f"      å®Œæ•´æ€§: {info.get('global_integrity', 1.0):.6f}")
        
        return True, output
        
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, None

def main():
    print("=" * 60)
    print("H2Q Server æ ¸å¿ƒæ•°å­¦ç»„ä»¶æµ‹è¯•")
    print("=" * 60)
    print()
    
    results = {}
    
    # æµ‹è¯•1: ç»Ÿä¸€æ¶æ„
    success, data = test_unified_architecture_integration()
    results['unified_architecture'] = success
    
    # æµ‹è¯•2: è¿›åŒ–æ¡¥æ¥
    success, data = test_evolution_bridge()
    results['evolution_bridge'] = success
    
    # æµ‹è¯•3: èŠå¤©å¤„ç†
    success, data = simulate_chat_processing()
    results['chat_processing'] = success
    
    # æµ‹è¯•4: æ–‡æœ¬ç”Ÿæˆ
    success, data = simulate_generate_processing()
    results['generate_processing'] = success
    
    # æ±‡æ€»
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    for test_name, passed in results.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"{status}: {test_name}")
    
    total_pass = sum(results.values())
    total_tests = len(results)
    
    print(f"\né€šè¿‡ç‡: {total_pass}/{total_tests} ({total_pass/total_tests*100:.1f}%)")
    
    if total_pass == total_tests:
        print("\nğŸ† æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼h2q_serveré‡æ„çš„æ ¸å¿ƒæ•°å­¦ç»„ä»¶å®Œå…¨æ­£å¸¸ã€‚")
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("   1. å®‰è£…FastAPI: pip3 install fastapi uvicorn")
        print("   2. å¤‡ä»½åŸæœåŠ¡å™¨: mv h2q_project/h2q_server.py h2q_project/h2q_server_backup.py")
        print("   3. åº”ç”¨é‡æ„: mv h2q_project/h2q_server_refactored.py h2q_project/h2q_server.py")
        print("   4. å¯åŠ¨æœåŠ¡: cd h2q_project && python3 -m uvicorn h2q_server:app --reload")
        return True
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤ã€‚")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
