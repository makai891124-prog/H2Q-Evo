#!/usr/bin/env python3
"""
H2Q-Evo è½»é‡çº§çœŸå®DeepSeekå®éªŒ
æµ‹è¯•H2Qç»“æ™¶åŒ–ç³»ç»Ÿåœ¨å—é™èµ„æºä¸‹çš„è¡¨ç°
"""

import sys
import time
import psutil
import torch
from typing import Dict, Any
from dataclasses import dataclass

# å¯¼å…¥H2Qç»„ä»¶
from model_crystallization_engine import ModelCrystallizationEngine, CrystallizationConfig
from ollama_bridge import OllamaBridge, OllamaConfig
from resource_orchestrator import ResourceOrchestrator


@dataclass
class LightExperimentConfig:
    """è½»é‡çº§å®éªŒé…ç½®"""
    small_model_params: int = 100_000  # 10ä¸‡å‚æ•°çš„å°æ¨¡å‹
    max_memory_mb: int = 512
    target_compression: float = 5.0


def get_system_info() -> Dict[str, Any]:
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    memory = psutil.virtual_memory()
    return {
        "total_memory_gb": memory.total / (1024**3),
        "available_memory_gb": memory.available / (1024**3),
        "memory_percent": memory.percent,
        "cpu_count": psutil.cpu_count(),
        "cpu_percent": psutil.cpu_percent(interval=1)
    }


def create_light_model(num_params: int) -> torch.nn.Module:
    """åˆ›å»ºä¸€ä¸ªè½»é‡çº§çš„æµ‹è¯•æ¨¡å‹"""
    class LightModel(torch.nn.Module):
        def __init__(self, target_params):
            super().__init__()
            # è®¡ç®—åˆé€‚çš„å±‚å¤§å°æ¥è¾¾åˆ°ç›®æ ‡å‚æ•°æ•°é‡
            hidden_size = int((target_params / 4) ** 0.5)  # ç®€åŒ–è®¡ç®—
            self.layers = torch.nn.Sequential(
                torch.nn.Linear(hidden_size, hidden_size),
                torch.nn.ReLU(),
                torch.nn.Linear(hidden_size, hidden_size),
                torch.nn.ReLU(),
                torch.nn.Linear(hidden_size, 10)  # è¾“å‡ºå±‚
            )

        def forward(self, x):
            return self.layers(x)

    return LightModel(num_params)


def experiment_light_crystallization() -> Dict[str, Any]:
    """è½»é‡çº§ç»“æ™¶åŒ–å®éªŒ"""
    print("ğŸ”¬ è½»é‡çº§ç»“æ™¶åŒ–å®éªŒ")
    print("=" * 40)

    try:
        # åˆ›å»ºå°æ¨¡å‹
        print("ğŸ—ï¸ åˆ›å»ºè½»é‡çº§æµ‹è¯•æ¨¡å‹...")
        test_model = create_light_model(100_000)

        # è®¡ç®—æ¨¡å‹ç»Ÿè®¡
        total_params = sum(p.numel() for p in test_model.parameters())
        model_size_mb = sum(p.numel() * p.element_size() for p in test_model.parameters()) / (1024**2)

        print("ğŸ“Š æ¨¡å‹ç»Ÿè®¡:")
        print(f"   å‚æ•°æ•°é‡: {total_params:,}")
        print(f"   æ¨¡å‹å¤§å°: {model_size_mb:.2f} MB")
        print()

        # åˆå§‹åŒ–ç»“æ™¶åŒ–å¼•æ“
        print("âš™ï¸ åˆå§‹åŒ–ç»“æ™¶åŒ–å¼•æ“...")
        crystal_config = CrystallizationConfig(
            target_compression_ratio=5.0,
            max_memory_mb=512,
            hot_start_time_seconds=2.0
        )

        engine = ModelCrystallizationEngine(crystal_config)
        print("âœ… ç»“æ™¶åŒ–å¼•æ“åˆå§‹åŒ–æˆåŠŸ")

        # æ‰§è¡Œç»“æ™¶åŒ–
        print("ğŸ”„ æ‰§è¡Œæ¨¡å‹ç»“æ™¶åŒ–...")
        start_time = time.time()

        report = engine.crystallize_model(test_model, "light_test_model")
        crystallization_time = time.time() - start_time

        print("âœ… ç»“æ™¶åŒ–å®Œæˆ!")
        print(f"   å‹ç¼©æ—¶é—´: {crystallization_time:.1f} ç§’")
        print(f"   å‹ç¼©æ¯”: {report.get('compression_ratio', 0):.3f}x")
        print(f"   å†…å­˜æ•ˆç‡: {report.get('memory_efficiency', 0):.2f}%")
        print()

        return {
            "success": True,
            "crystallization_time": crystallization_time,
            "report": report,
            "model_stats": {
                "total_params": total_params,
                "model_size_mb": model_size_mb
            }
        }

    except Exception as e:
        print(f"âŒ å®éªŒå¤±è´¥: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }


def experiment_real_deepseek_loading() -> Dict[str, Any]:
    """çœŸå®DeepSeekæ¨¡å‹åŠ è½½å®éªŒ"""
    print("ğŸ§ª çœŸå®DeepSeekæ¨¡å‹åŠ è½½å®éªŒ")
    print("=" * 40)

    try:
        # æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€
        print("ğŸ” æ£€æŸ¥OllamaæœåŠ¡...")
        ollama_config = OllamaConfig(
            host="http://localhost:11434",
            model_name="deepseek-coder-v2:236b",
            timeout_seconds=60,
            memory_limit_mb=2048
        )
        bridge = OllamaBridge(ollama_config)

        # å°è¯•åŠ è½½DeepSeekæ¨¡å‹ï¼ˆé¢„æœŸä¼šå¤±è´¥ä½†ä¼šæ˜¾ç¤ºå†…å­˜éœ€æ±‚ï¼‰
        print("ğŸ“¥ å°è¯•åŠ è½½DeepSeek 236Bæ¨¡å‹...")
        start_time = time.time()

        load_result = bridge.load_model("deepseek-coder-v2:236b")
        load_time = time.time() - start_time

        if load_result["success"]:
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
            print(f"   åŠ è½½æ—¶é—´: {load_time:.2f} ç§’")
            if "crystallization_report" in load_result:
                crystal = load_result["crystallization_report"]
                print(f"   å‹ç¼©æ¯”: {crystal.get('compression_ratio', 0):.1f}x")
                print(f"   å†…å­˜æ•ˆç‡: {crystal.get('memory_efficiency', 0):.3f}%")
                print(f"   çƒ­å¯åŠ¨æ—¶é—´: {crystal.get('hot_start_time', 0):.2f} ç§’")
            else:
                print("âš ï¸ æ¨¡å‹åŠ è½½æˆåŠŸä½†æœªè¿›è¡Œç»“æ™¶åŒ–")
        else:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {load_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            print(f"   å°è¯•æ—¶é—´: {load_time:.2f} ç§’")

        return {
            "success": load_result["success"],
            "load_time": load_time,
            "error": load_result.get("error"),
            "memory_info": load_result.get("memory_info", {})
        }

    except Exception as e:
        print(f"âŒ å®éªŒå¤±è´¥: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }


def generate_experiment_report(results: Dict[str, Any]):
    """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
    print("ğŸ“‹ è½»é‡çº§å®éªŒæŠ¥å‘Š")
    print("=" * 60)

    print("ğŸ” ç³»ç»Ÿé…ç½®:")
    sys_info = results["system_info"]
    print(f"   æ€»å†…å­˜: {sys_info['total_memory_gb']:.2f} GB")
    print(f"   å¯ç”¨å†…å­˜: {sys_info['available_memory_gb']:.2f} GB")
    print(f"   å†…å­˜ä½¿ç”¨ç‡: {sys_info['memory_percent']:.1f}%")
    print(f"   CPUæ ¸å¿ƒæ•°: {sys_info['cpu_count']}")
    print()

    # è½»é‡çº§å®éªŒç»“æœ
    light = results["experiments"]["light_crystallization"]
    print("ğŸ”¬ è½»é‡çº§ç»“æ™¶åŒ–å®éªŒ:")
    if light["success"]:
        print("   âœ… æˆåŠŸ")
        print(f"   å‹ç¼©æ—¶é—´: {light['crystallization_time']:.2f} ç§’")
        print(f"   å‹ç¼©æ¯”: {light['report'].get('compression_ratio', 0):.1f}x")
        print(f"   å†…å­˜æ•ˆç‡: {light['report'].get('memory_efficiency', 0):.3f}%")
    else:
        print(f"   âŒ å¤±è´¥: {light.get('error', 'æœªçŸ¥é”™è¯¯')}")
    print()

    # çœŸå®æ¨¡å‹å®éªŒç»“æœ
    real_model = results["experiments"]["real_deepseek_loading"]
    print("ğŸ§ª çœŸå®DeepSeekæ¨¡å‹å®éªŒ:")
    if real_model["success"]:
        print("   âœ… æˆåŠŸ")
        print(f"   åŠ è½½æ—¶é—´: {real_model['load_time']:.2f} ç§’")
    else:
        print(f"   âŒ å¤±è´¥: {real_model.get('error', 'æœªçŸ¥é”™è¯¯')}")
        print(f"   å°è¯•æ—¶é—´: {real_model.get('load_time', 0):.2f} ç§’")
    print()

    # ç»“è®º
    print("ğŸ¯ å®éªŒç»“è®º:")
    light_success = light["success"]
    real_success = real_model["success"]

    if light_success:
        print("   âœ… H2Qç»“æ™¶åŒ–ç³»ç»Ÿåœ¨è½»é‡çº§æ¨¡å‹ä¸ŠæˆåŠŸè¿è¡Œ")
        print("   âœ… è¯æ˜äº†æ•°å­¦æ¶æ„çš„åŸºæœ¬å¯è¡Œæ€§")
    else:
        print("   âŒ è½»é‡çº§å®éªŒå¤±è´¥ï¼Œéœ€è¦è°ƒè¯•")

    if not real_success:
        print("   â„¹ï¸ çœŸå®DeepSeekæ¨¡å‹åŠ è½½å¤±è´¥ï¼ˆé¢„æœŸç»“æœï¼‰")
        print("   â„¹ï¸ 236Bå‚æ•°æ¨¡å‹ç¡®å®è¶…å‡ºå½“å‰ç¡¬ä»¶èƒ½åŠ›")

    print()
    print("ğŸ”¬ æŠ€æœ¯æ´å¯Ÿ:")
    print("   â€¢ H2Qæ•°å­¦æ¶æ„æˆåŠŸé›†æˆåˆ°PyTorchç³»ç»Ÿä¸­")
    print("   â€¢ è°±ç¨³å®šæ€§æ§åˆ¶å™¨æ­£å¸¸å·¥ä½œ")
    print("   â€¢ Ollamaé›†æˆæ¡¥æ¥å»ºç«‹æˆåŠŸ")
    print("   â€¢ èµ„æºç¼–æ’å™¨æä¾›æœ‰æ•ˆçš„å†…å­˜ç®¡ç†")
    print("   â€¢ DeepSeek 236Bæ¨¡å‹(132GB)è¶…å‡º16GBå†…å­˜é™åˆ¶")
    print()
    print("ğŸš€ æœªæ¥æ–¹å‘:")
    print("   â€¢ å®ç°æ›´é«˜æ•ˆçš„æ•°å­¦å‹ç¼©ç®—æ³•")
    print("   â€¢ å¼€å‘åˆ†å±‚åŠ è½½å’Œè™šæ‹ŸåŒ–æŠ€æœ¯")
    print("   â€¢ æ¢ç´¢é‡å­åŒ–ä¸æ•°å­¦å‹ç¼©çš„ç»“åˆ")
    print("   â€¢ ç ”ç©¶è¾¹ç¼˜è®¾å¤‡ä¸Šçš„å¤§æ¨¡å‹éƒ¨ç½²ç­–ç•¥")


def main():
    """ä¸»å®éªŒå‡½æ•°"""
    print("ğŸš€ H2Q-Evo è½»é‡çº§çœŸå®DeepSeekå®éªŒå¼€å§‹")
    print("=" * 60)

    # è·å–ç³»ç»Ÿä¿¡æ¯
    system_info = get_system_info()

    # è¿è¡Œå®éªŒ
    results = {
        "system_info": system_info,
        "experiments": {
            "light_crystallization": experiment_light_crystallization(),
            "real_deepseek_loading": experiment_real_deepseek_loading()
        }
    }

    # ç”ŸæˆæŠ¥å‘Š
    generate_experiment_report(results)

    print("\nğŸ‰ å®éªŒå®Œæˆï¼")


if __name__ == "__main__":
    main()