#!/usr/bin/env python3
"""
H2Q-Evo AGIè®­ç»ƒç›‘æ§å’Œç®¡ç†å·¥å…·
æä¾›è®­ç»ƒçŠ¶æ€ç›‘æ§ã€æ§åˆ¶å’Œåˆ†æåŠŸèƒ½
"""

import os
import sys
import json
import time
import signal
import psutil
import argparse
import logging
from pathlib import Path
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import numpy as np
from typing import Dict, Any, Optional

# é…ç½®æ—¥å¿—
logger = logging.getLogger('AGITrainingMonitor')

class AGITrainingMonitor:
    """AGIè®­ç»ƒç›‘æ§å™¨"""

    def __init__(self, project_root: str = "./agi_persistent_training"):
        self.project_root = Path(project_root)
        self.state_file = self.project_root / "evolution_state.json"
        self.log_file = self.project_root / "logs" / "training.log"
        self.checkpoint_dir = self.project_root / "checkpoints"

        # ç›‘æ§çŠ¶æ€
        self.is_monitoring = False
        self.last_update = None

    def get_training_status(self) -> Dict[str, Any]:
        """è·å–è®­ç»ƒçŠ¶æ€"""
        status = {
            'timestamp': datetime.now().isoformat(),
            'is_running': False,
            'process_info': None,
            'memory_usage': None,
            'gpu_usage': None,
            'evolution_state': {},
            'recent_logs': [],
            'checkpoints': []
        }

        # æ£€æŸ¥è®­ç»ƒè¿›ç¨‹
        training_processes = self._find_training_processes()
        if training_processes:
            status['is_running'] = True
            status['process_info'] = {
                'pid': training_processes[0].pid,
                'cpu_percent': training_processes[0].cpu_percent(),
                'memory_mb': training_processes[0].memory_info().rss / (1024**2),
                'create_time': datetime.fromtimestamp(training_processes[0].create_time()).isoformat()
            }

        # è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory = psutil.virtual_memory()
        status['memory_usage'] = {
            'total_gb': memory.total / (1024**3),
            'used_gb': memory.used / (1024**3),
            'available_gb': memory.available / (1024**3),
            'usage_percent': memory.percent
        }

        # è·å–GPUä½¿ç”¨æƒ…å†µ (å¦‚æœå¯ç”¨)
        try:
            import torch
            if torch.cuda.is_available():
                gpu_memory = torch.cuda.get_device_properties(0).total_memory
                gpu_used = torch.cuda.memory_allocated(0)
                status['gpu_usage'] = {
                    'total_gb': gpu_memory / (1024**3),
                    'used_gb': gpu_used / (1024**3),
                    'usage_percent': (gpu_used / gpu_memory) * 100
                }
        except:
            pass

        # åŠ è½½è¿›åŒ–çŠ¶æ€
        if self.state_file.exists():
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    status['evolution_state'] = json.load(f)
            except Exception as e:
                status['evolution_state'] = {'error': str(e)}

        # è·å–æœ€è¿‘æ—¥å¿—
        if self.log_file.exists():
            try:
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()[-20:]  # æœ€è¿‘20è¡Œ
                    status['recent_logs'] = [line.strip() for line in lines]
            except Exception as e:
                status['recent_logs'] = [f'Error reading logs: {e}']

        # è·å–æ£€æŸ¥ç‚¹åˆ—è¡¨
        if self.checkpoint_dir.exists():
            checkpoints = []
            for cp_dir in self.checkpoint_dir.iterdir():
                if cp_dir.is_dir():
                    checkpoints.append({
                        'name': cp_dir.name,
                        'path': str(cp_dir),
                        'size_mb': sum(f.stat().st_size for f in cp_dir.rglob('*') if f.is_file()) / (1024**2),
                        'modified': datetime.fromtimestamp(cp_dir.stat().st_mtime).isoformat()
                    })
            status['checkpoints'] = sorted(checkpoints, key=lambda x: x['modified'], reverse=True)

        return status

    def _find_training_processes(self) -> list:
        """æŸ¥æ‰¾è®­ç»ƒè¿›ç¨‹"""
        training_processes = []
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                if proc.info['name'] == 'python3' or proc.info['name'] == 'python':
                    cmdline = proc.info['cmdline']
                    if cmdline and 'agi_persistent_evolution.py' in ' '.join(cmdline):
                        training_processes.append(proc)
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue
        return training_processes

    def stop_training(self) -> bool:
        """åœæ­¢è®­ç»ƒ"""
        training_processes = self._find_training_processes()
        if not training_processes:
            print("âŒ æœªæ‰¾åˆ°æ­£åœ¨è¿è¡Œçš„è®­ç»ƒè¿›ç¨‹")
            return False

        for proc in training_processes:
            try:
                proc.terminate()
                print(f"âœ… å‘é€ç»ˆæ­¢ä¿¡å·åˆ°è¿›ç¨‹ {proc.pid}")
                # ç­‰å¾…è¿›ç¨‹ç»“æŸ
                proc.wait(timeout=10)
                print(f"âœ… è¿›ç¨‹ {proc.pid} å·²åœæ­¢")
            except psutil.TimeoutExpired:
                print(f"âš ï¸ è¿›ç¨‹ {proc.pid} æœªåœ¨é¢„æœŸæ—¶é—´å†…åœæ­¢ï¼Œå¼ºåˆ¶ç»ˆæ­¢")
                proc.kill()
            except Exception as e:
                print(f"âŒ åœæ­¢è¿›ç¨‹ {proc.pid} æ—¶å‡ºé”™: {e}")
                return False

        return True

    def show_training_stats(self):
        """æ˜¾ç¤ºè®­ç»ƒç»Ÿè®¡"""
        status = self.get_training_status()

        print("ğŸš€ H2Q-Evo AGIè®­ç»ƒçŠ¶æ€")
        print("=" * 50)

        # è¿è¡ŒçŠ¶æ€
        if status['is_running']:
            print("âœ… çŠ¶æ€: è¿è¡Œä¸­")
            proc_info = status['process_info']
            print(f"   PID: {proc_info['pid']}")
            print(f"   CPUä½¿ç”¨: {proc_info['cpu_percent']:.1f}%")
            print(f"   å†…å­˜ä½¿ç”¨: {proc_info['memory_mb']:.1f} MB")
            print(f"   å¯åŠ¨æ—¶é—´: {proc_info['create_time']}")
        else:
            print("âŒ çŠ¶æ€: æœªè¿è¡Œ")
        print()

        # å†…å­˜ä½¿ç”¨
        mem = status['memory_usage']
        print("ğŸ’¾ å†…å­˜ä½¿ç”¨:")
        print(f"   å·²ç”¨: {mem['used_gb']:.1f} GB")
        print(f"   å¯ç”¨: {mem['available_gb']:.1f} GB")
        print(f"   ä½¿ç”¨ç‡: {mem['percent']:.1f}%")
        print(f"   è¿›ç¨‹æ•°: {mem['process_count']}")
        print()

        # GPUä½¿ç”¨ (å¦‚æœå¯ç”¨)
        if status['gpu_usage']:
            gpu = status['gpu_usage']
            print("ğŸ® GPUä½¿ç”¨:")
            print(f"   GPUå†…å­˜ä½¿ç”¨: {gpu['gpu_memory_used']:.1f} MB")
            print(f"   GPUå†…å­˜æ€»é‡: {gpu['gpu_memory_total']:.1f} MB")
            print(f"   GPUåˆ©ç”¨ç‡: {gpu['gpu_utilization']:.1f}%")
            print()

        # è¿›åŒ–çŠ¶æ€
        evo_state = status['evolution_state']
        if evo_state and 'generation' in evo_state:
            print("ğŸ§¬ è¿›åŒ–çŠ¶æ€:")
            print(f"   å½“å‰ä»£æ•°: {evo_state['generation']}")
            print(f"   æœ€ä½³é€‚åº”åº¦: {evo_state.get('best_fitness', 0):.4f}")
            print(f"   å½“å‰é€‚åº”åº¦: {evo_state.get('current_fitness', 0):.4f}")
            print(f"   å¹³å‡æŸå¤±: {evo_state.get('average_loss', 0):.4f}")
            print(f"   æ€»è®­ç»ƒæ­¥æ•°: {evo_state.get('total_training_steps', 0)}")
            print(f"   æ¨¡å‹ç‰ˆæœ¬æ•°: {len(evo_state.get('model_versions', []))}")
        else:
            print("ğŸ§¬ è¿›åŒ–çŠ¶æ€: æœªæ‰¾åˆ°çŠ¶æ€æ–‡ä»¶")
        print()

        # æœ€è¿‘æ£€æŸ¥ç‚¹
        checkpoints = status['checkpoints']
        if checkpoints:
            print("ğŸ’¾ æœ€è¿‘æ£€æŸ¥ç‚¹:")
            for i, cp in enumerate(checkpoints[:3]):  # æ˜¾ç¤ºå‰3ä¸ª
                print(f"   {i+1}. {cp['name']} ({cp['size_mb']:.1f} MB) - {cp['modified']}")
        else:
            print("ğŸ’¾ æ£€æŸ¥ç‚¹: æ— ")
        print()

        # æœ€è¿‘æ—¥å¿—
        logs = status['recent_logs']
        if logs:
            print("ğŸ“ æœ€è¿‘æ—¥å¿—:")
            for log in logs[-5:]:  # æ˜¾ç¤ºæœ€å5æ¡
                print(f"   {log}")
        else:
            print("ğŸ“ æ—¥å¿—: æ— ")

    def plot_training_progress(self, save_path: Optional[str] = None):
        """ç»˜åˆ¶è®­ç»ƒè¿›åº¦å›¾"""
        status = self.get_training_status()
        evo_state = status['evolution_state']

        if not evo_state or 'learning_curve' not in evo_state:
            print("âŒ æœªæ‰¾åˆ°å­¦ä¹ æ›²çº¿æ•°æ®")
            return

        learning_curve = evo_state['learning_curve']
        if not learning_curve:
            print("âŒ å­¦ä¹ æ›²çº¿æ•°æ®ä¸ºç©º")
            return

        # æå–æ•°æ®
        steps = [point['step'] for point in learning_curve]
        losses = [point['loss'] for point in learning_curve]
        generations = [point['generation'] for point in learning_curve]

        # åˆ›å»ºå›¾è¡¨
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))

        # æŸå¤±æ›²çº¿
        ax1.plot(steps, losses, 'b-', linewidth=2, label='Training Loss')
        ax1.set_xlabel('Training Steps')
        ax1.set_ylabel('Loss')
        ax1.set_title('AGI Training Loss Curve')
        ax1.grid(True, alpha=0.3)
        ax1.legend()

        # ä»£æ•°åˆ†å¸ƒ
        unique_gens = list(set(generations))
        gen_counts = [generations.count(gen) for gen in unique_gens]
        ax2.bar(unique_gens, gen_counts, alpha=0.7, color='green')
        ax2.set_xlabel('Generation')
        ax2.set_ylabel('Number of Steps')
        ax2.set_title('Training Steps per Generation')
        ax2.grid(True, alpha=0.3)

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… å›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        else:
            plt.show()

    def export_training_report(self, output_file: str):
        """å¯¼å‡ºè®­ç»ƒæŠ¥å‘Š"""
        status = self.get_training_status()

        report = {
            'generated_at': datetime.now().isoformat(),
            'training_status': status,
            'summary': {
                'is_running': status['is_running'],
                'current_generation': status['evolution_state'].get('generation', 0),
                'best_fitness': status['evolution_state'].get('best_fitness', 0),
                'total_training_steps': status['evolution_state'].get('total_training_steps', 0),
                'memory_usage_percent': status['memory_usage']['usage_percent'],
                'num_checkpoints': len(status['checkpoints'])
            }
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print(f"âœ… è®­ç»ƒæŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {output_file}")

    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§è®­ç»ƒè¿‡ç¨‹"""
        if self.is_monitoring:
            logger.warning("ç›‘æ§å·²åœ¨è¿è¡Œ")
            return False

        self.is_monitoring = True
        self.last_update = datetime.now()
        logger.info("AGIè®­ç»ƒç›‘æ§å™¨å·²å¯åŠ¨")
        return True

    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        if not self.is_monitoring:
            logger.warning("ç›‘æ§æœªåœ¨è¿è¡Œ")
            return False

        self.is_monitoring = False
        logger.info("AGIè®­ç»ƒç›‘æ§å™¨å·²åœæ­¢")
        return True

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='H2Q-Evo AGIè®­ç»ƒç›‘æ§å’Œç®¡ç†å·¥å…·')
    parser.add_argument('action', choices=['status', 'stop', 'plot', 'report'],
                       help='æ‰§è¡Œçš„æ“ä½œ')
    parser.add_argument('--project-root', default='./agi_persistent_training',
                       help='é¡¹ç›®æ ¹ç›®å½•')
    parser.add_argument('--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    monitor = AGITrainingMonitor(args.project_root)

    if args.action == 'status':
        monitor.show_training_stats()

    elif args.action == 'stop':
        if monitor.stop_training():
            print("âœ… è®­ç»ƒå·²åœæ­¢")
        else:
            print("âŒ åœæ­¢è®­ç»ƒå¤±è´¥")

    elif args.action == 'plot':
        output_path = args.output or './training_progress.png'
        monitor.plot_training_progress(output_path)

    elif args.action == 'report':
        output_path = args.output or './training_report.json'
        monitor.export_training_report(output_path)

if __name__ == "__main__":
    main()