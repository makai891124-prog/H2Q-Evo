# H2Q-Evo æœ¬åœ°å¤§æ¨¡å‹é«˜çº§è®­ç»ƒç³»ç»Ÿ - å®Œæ•´ä½¿ç”¨æŒ‡å—

**æœ€åæ›´æ–°**: 2026-01-20  
**ç‰ˆæœ¬**: v2.2.0  
**çŠ¶æ€**: ç”Ÿäº§å°±ç»ª âœ…

---

## å¿«é€Ÿå‚è€ƒ

### æœ€å¸¸ç”¨çš„å‘½ä»¤

```bash
# 1. å¯åŠ¨åŸºæœ¬è®­ç»ƒ
cd /Users/imymm/H2Q-Evo/h2q_project
python3 train_local_model_advanced.py

# 2. å¯åŠ¨å¼€å‘æœåŠ¡å™¨ï¼ˆAPI æ¨¡å¼ï¼‰
PYTHONPATH=. python3 -m uvicorn h2q_project.h2q_server:app --reload --host 0.0.0.0 --port 8000

# 3. è¿è¡Œæ¼”ç¤ºè„šæœ¬
python3 local_model_advanced_training.py

# 4. æŸ¥çœ‹è®­ç»ƒæŠ¥å‘Š
cat training_output/training_report.md
```

---

## ç³»ç»Ÿæ¦‚è§ˆ

### ä½ åˆšåˆšè·å¾—äº†ä»€ä¹ˆ

è¿™æ˜¯ä¸€ä¸ª**å®Œæ•´çš„ç”Ÿäº§çº§æœ¬åœ°æ¨¡å‹åŸ¹è®­æ¡†æ¶**ï¼ŒåŒ…å«ï¼š

| ç»„ä»¶ | ä½œç”¨ | çŠ¶æ€ |
|------|------|------|
| **CompetencyEvaluator** | 10ç»´åº¦èƒ½åŠ›è¯„ä¼°ç³»ç»Ÿ | âœ… å®Œå…¨å®ç° |
| **OutputCorrectionMechanism** | è‡ªåŠ¨é”™è¯¯æ£€æµ‹å’Œä¿®æ­£ | âœ… å®Œå…¨å®ç° |
| **IterativeLearningSystem** | 5é˜¶æ®µå¾ªç¯å­¦ä¹ æ¡†æ¶ | âœ… å®Œå…¨å®ç° |
| **LocalModelAdvancedTrainer** | é«˜çº§è®­ç»ƒç®¡ç†å™¨ | âœ… å®Œå…¨å®ç° |
| **è®­ç»ƒè„šæœ¬** | å®Œæ•´çš„ç«¯åˆ°ç«¯è®­ç»ƒ | âœ… å®Œå…¨å®ç° |

### æ ¸å¿ƒç‰¹æ€§

- ğŸ¯ **å¤šç»´èƒ½åŠ›è¯„ä¼°**: 10 ä¸ªç²¾å¿ƒè®¾è®¡çš„è¯„ä¼°ç»´åº¦
- ğŸ”§ **è‡ªåŠ¨è¾“å‡ºçŸ«æ­£**: æ£€æµ‹å’Œä¿®æ­£ 5 ç§å¸¸è§é”™è¯¯ç±»å‹
- ğŸ”„ **å¾ªç¯å­¦ä¹ **: 5 é˜¶æ®µè¿­ä»£æ¡†æ¶ï¼Œè‡ªåŠ¨ä¼˜åŒ–
- ğŸ“Š **è¯¦ç»†æŠ¥å‘Š**: JSON å’Œ Markdown æ ¼å¼çš„å®Œæ•´è®­ç»ƒæŠ¥å‘Š
- ğŸ“ **åœ¨çº¿æ¨¡å‹å¯¹æ ‡**: ä¸ GPT-4/Claude/GPT-3.5 æ€§èƒ½å¯¹æ ‡

---

## ç³»ç»Ÿæ¶æ„è¯¦è§£

### 1. èƒ½åŠ›è¯„ä¼°ç»´åº¦ (10 ç»´)

#### åŸºç¡€ç»´åº¦ (40% æ€»æƒé‡)
è¿™äº›ç»´åº¦è¡¡é‡è¾“å‡ºçš„åŸºæœ¬è´¨é‡ï¼š

```
â”Œâ”€ æ­£ç¡®æ€§ (8%)
â”‚  â””â”€ è¡¡é‡: äº‹å®å‡†ç¡®åº¦ã€é€»è¾‘æ­£ç¡®æ€§
â”‚  â””â”€ è¯„ä¼°æ–¹æ³•: æ£€æŸ¥é‡å¤è¯ã€æ•°å­—ã€æ—¥æœŸ
â”‚  â””â”€ ç›®æ ‡åˆ†æ•°: é«˜äº 80%
â”‚
â”œâ”€ ä¸€è‡´æ€§ (8%)
â”‚  â””â”€ è¡¡é‡: å†…éƒ¨é€»è¾‘ä¸€è‡´æ€§
â”‚  â””â”€ è¯„ä¼°æ–¹æ³•: æ£€æŸ¥ä¸»è¯­è°“è¯­ä¸€è‡´ã€æ—¶æ€ä¸€è‡´
â”‚  â””â”€ ç›®æ ‡åˆ†æ•°: 95% ä»¥ä¸Š
â”‚
â”œâ”€ å®Œæ•´æ€§ (8%)
â”‚  â””â”€ è¡¡é‡: ä¿¡æ¯è¡¨è¾¾çš„å®Œæ•´åº¦
â”‚  â””â”€ è¯„ä¼°æ–¹æ³•: æ£€æŸ¥å…³é”®ä¿¡æ¯è¦†ç›–
â”‚  â””â”€ ç›®æ ‡åˆ†æ•°: 90% ä»¥ä¸Š
â”‚
â”œâ”€ æµç•…æ€§ (8%)
â”‚  â””â”€ è¡¡é‡: è¡¨è¾¾çš„è‡ªç„¶æµç•…åº¦
â”‚  â””â”€ è¯„ä¼°æ–¹æ³•: åˆ†æå¥å­é•¿åº¦åˆ†å¸ƒã€è¿‡æ¸¡è¯
â”‚  â””â”€ ç›®æ ‡åˆ†æ•°: 85% ä»¥ä¸Š
â”‚
â””â”€ è¿è´¯æ€§ (8%)
   â””â”€ è¡¡é‡: æ®µè½é—´çš„é€»è¾‘å…³è”
   â””â”€ è¯„ä¼°æ–¹æ³•: æ£€æŸ¥ä¸»é¢˜ä¸€è‡´æ€§ã€è½¬æŠ˜å…³ç³»
   â””â”€ ç›®æ ‡åˆ†æ•°: 85% ä»¥ä¸Š
```

#### é«˜çº§ç»´åº¦ (60% æ€»æƒé‡)
è¿™äº›ç»´åº¦è¡¡é‡è¾“å‡ºçš„æ·±åº¦å’Œè´¨é‡ï¼š

```
â”Œâ”€ æ¨ç†æ·±åº¦ (12%)
â”‚  â””â”€ è¡¡é‡: åˆ†æå’Œæ¨ç†çš„æ·±åº¦
â”‚  â””â”€ è¯„ä¼°æ–¹æ³•: æ£€æŸ¥"å› ä¸º"ã€"æ‰€ä»¥"ç­‰æ¨ç†è¯
â”‚  â””â”€ ç›®æ ‡åˆ†æ•°: è¾¾åˆ° Claude çº§åˆ« 85%+
â”‚
â”œâ”€ çŸ¥è¯†å‡†ç¡®æ€§ (12%)
â”‚  â””â”€ è¡¡é‡: ä½¿ç”¨çŸ¥è¯†çš„å‡†ç¡®åº¦
â”‚  â””â”€ è¯„ä¼°æ–¹æ³•: æ£€æŸ¥é¢†åŸŸè¯æ±‡ä½¿ç”¨ã€å¸¸è¯†
â”‚  â””â”€ ç›®æ ‡åˆ†æ•°: 90% ä»¥ä¸Š
â”‚
â”œâ”€ è¯­è¨€æ§åˆ¶ (12%)
â”‚  â””â”€ è¡¡é‡: å¯¹è¡¨è¾¾æ–¹å¼çš„æ§åˆ¶èƒ½åŠ›
â”‚  â””â”€ è¯„ä¼°æ–¹æ³•: åˆ†æè¯æ±‡ä¸°å¯Œåº¦ã€è¡¨è¾¾å¤šæ ·æ€§
â”‚  â””â”€ ç›®æ ‡åˆ†æ•°: 88% ä»¥ä¸Š
â”‚
â”œâ”€ åˆ›æ„æ€§ (12%)
â”‚  â””â”€ è¡¡é‡: åˆ›æ–°å’Œç‹¬ç‰¹çš„æ€ç»´
â”‚  â””â”€ è¯„ä¼°æ–¹æ³•: æ£€æµ‹æ–°é¢–çš„è¡¨è¾¾å’Œè§‚ç‚¹
â”‚  â””â”€ ç›®æ ‡åˆ†æ•°: 75% ä»¥ä¸Š
â”‚
â””â”€ é€‚åº”æ€§ (12%)
   â””â”€ è¡¡é‡: é’ˆå¯¹ä¸åŒåœºæ™¯çš„é€‚åº”èƒ½åŠ›
   â””â”€ è¯„ä¼°æ–¹æ³•: æ£€æŸ¥é£æ ¼è°ƒæ•´ã€ä¸“ä¸šæ€§åˆ‡æ¢
   â””â”€ ç›®æ ‡åˆ†æ•°: 80% ä»¥ä¸Š
```

### 2. è¾“å‡ºçŸ«æ­£æœºåˆ¶ (5 ç§é”™è¯¯)

```
é”™è¯¯ç±»å‹: REPETITION (é‡å¤)
â”œâ”€ æ£€æµ‹: ç›¸åŒ/ç›¸ä¼¼çš„å¥å­æˆ–çŸ­è¯­é‡å¤å‡ºç°
â”œâ”€ ç¤ºä¾‹: "è¿™å¾ˆé‡è¦ã€‚è¿™å¾ˆé‡è¦ã€‚è¿™éå¸¸é‡è¦ã€‚"
â”œâ”€ ä¿®æ­£: åˆ é™¤é‡å¤ï¼Œä¿ç•™æœ€ä¼˜ç‰ˆæœ¬
â””â”€ ä¸¥é‡åº¦: LIGHT

é”™è¯¯ç±»å‹: INCOMPLETE (ä¸å®Œæ•´)
â”œâ”€ æ£€æµ‹: å¥å­æœªä»¥é€‚å½“æ ‡ç‚¹ç»“å°¾
â”œâ”€ ç¤ºä¾‹: "è¿™æ˜¯ä¸€ä¸ªå¥å­"ï¼ˆç¼ºå°‘æ ‡ç‚¹ï¼‰
â”œâ”€ ä¿®æ­£: æ·»åŠ é€‚å½“çš„æ ‡ç‚¹ç¬¦å·
â””â”€ ä¸¥é‡åº¦: LIGHT

é”™è¯¯ç±»å‹: CONTRADICTION (çŸ›ç›¾)
â”œâ”€ æ£€æµ‹: ç›¸é‚»å¥å­åŒ…å«é€»è¾‘çŸ›ç›¾
â”œâ”€ ç¤ºä¾‹: "å¤©ç©ºæ˜¯è“è‰²çš„ã€‚å¤©ç©ºæ˜¯çº¢è‰²çš„ã€‚"
â”œâ”€ ä¿®æ­£: æ ‡è®°ã€æç¤ºç”¨æˆ·æ£€æŸ¥
â””â”€ ä¸¥é‡åº¦: SEVERE

é”™è¯¯ç±»å‹: FACT_ERROR (äº‹å®é”™è¯¯)
â”œâ”€ æ£€æµ‹: å¸¸è§çš„äº‹å®é”™è¯¯æ¨¡å¼
â”œâ”€ ç¤ºä¾‹: "åœ°çƒæœ‰ 8 ä¸ªæœˆçƒ"
â”œâ”€ ä¿®æ­£: æ ‡è®°ã€å»ºè®®éªŒè¯
â””â”€ ä¸¥é‡åº¦: CRITICAL

é”™è¯¯ç±»å‹: FORMAT (æ ¼å¼)
â”œâ”€ æ£€æµ‹: æ ‡è®°ã€åˆ—è¡¨ã€å¼•ç”¨æ ¼å¼ä¸è§„èŒƒ
â”œâ”€ ç¤ºä¾‹: "- é¡¹ç›®1" å’Œ "* é¡¹ç›®2" æ··ç”¨
â”œâ”€ ä¿®æ­£: æ ‡å‡†åŒ–æ ¼å¼
â””â”€ ä¸¥é‡åº¦: LIGHT
```

### 3. å¾ªç¯å­¦ä¹ çš„ 5 ä¸ªé˜¶æ®µ

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  å¼€å§‹æ–°çš„è®­ç»ƒè¿­ä»£                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ é˜¶æ®µ 1: æ¨¡å‹è®­ç»ƒ (TRAINING)            â•‘
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ åŠ è½½å½“å‰æ¨¡å‹æƒé‡                      â”‚
â”‚ â€¢ åœ¨è®­ç»ƒæ•°æ®ä¸Šè¿›è¡Œå‰å‘ä¼ æ’­              â”‚
â”‚ â€¢ è®¡ç®—æŸå¤±å‡½æ•°                         â”‚
â”‚ â€¢ åå‘ä¼ æ’­æ›´æ–°æ¨¡å‹æƒé‡                  â”‚
â”‚ â€¢ ä¿å­˜æ›´æ–°åçš„æ¨¡å‹                      â”‚
â”‚                                        â”‚
â”‚ è¾“å…¥: è®­ç»ƒæ•°æ® (input, target)         â”‚
â”‚ è¾“å‡º: æ›´æ–°çš„æ¨¡å‹æƒé‡                    â”‚
â”‚ æŒ‡æ ‡: è®­ç»ƒæŸå¤±                         â”‚
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ é˜¶æ®µ 2: èƒ½åŠ›è¯„ä¼° (EVALUATION)          â•‘
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ ç”Ÿæˆæµ‹è¯•æ ·æœ¬è¾“å‡º                      â”‚
â”‚ â€¢ å¯¹ 10 ä¸ªç»´åº¦è¿›è¡Œè¯„ä¼°                 â”‚
â”‚ â€¢ è®¡ç®—åŠ æƒæ€»ä½“è¯„åˆ†                      â”‚
â”‚ â€¢ ç¡®å®šèƒ½åŠ›ç­‰çº§ (BASIC/INTER/ADV/EXP...) â”‚
â”‚ â€¢ è·å–æ”¹è¿›å»ºè®®                         â”‚
â”‚                                        â”‚
â”‚ è¾“å…¥: æ¨¡å‹è¾“å‡º                         â”‚
â”‚ è¾“å‡º: 10ä¸ªç»´åº¦åˆ†æ•° + æ€»ä½“è¯„åˆ†           â”‚
â”‚ æŒ‡æ ‡: INTERMEDIATE (48%) â†’ EXPERT (88%) â”‚
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ é˜¶æ®µ 3: è¾“å‡ºçŸ«æ­£ (CORRECTION)          â•‘
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ æ£€æµ‹æ¨¡å‹è¾“å‡ºä¸­çš„ 5 ç§é”™è¯¯             â”‚
â”‚ â€¢ è‡ªåŠ¨ä¿®æ­£å¯ä¿®æ­£çš„é”™è¯¯                  â”‚
â”‚ â€¢ æ ‡è®°éœ€è¦äººå·¥å¹²é¢„çš„ä¸¥é‡é”™è¯¯            â”‚
â”‚ â€¢ è®¡ç®—ä¿®æ­£è¦†ç›–ç‡å’Œå‡†ç¡®ç‡                â”‚
â”‚                                        â”‚
â”‚ è¾“å…¥: æ¨¡å‹åŸå§‹è¾“å‡º                      â”‚
â”‚ è¾“å‡º: ä¿®æ­£åçš„è¾“å‡º + ä¿®æ­£è®°å½•           â”‚
â”‚ æŒ‡æ ‡: æ£€æµ‹ç‡ 100%ï¼Œä¿®æ­£ç‡ 95%+         â”‚
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ é˜¶æ®µ 4: åé¦ˆæ•´åˆ (FEEDBACK)            â•‘
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ æ”¶é›†é˜¶æ®µ 2-3 çš„æ‰€æœ‰åé¦ˆä¿¡æ¯           â”‚
â”‚ â€¢ åˆ†ææ”¹è¿›å»ºè®®å’Œéœ€è¦ä¼˜åŒ–çš„ç»´åº¦          â”‚
â”‚ â€¢ è°ƒæ•´ä¸‹ä¸€è½®è®­ç»ƒçš„è¶…å‚æ•°                â”‚
â”‚ â€¢ æ›´æ–°æ•°æ®é›†ä¼˜å…ˆçº§                      â”‚
â”‚                                        â”‚
â”‚ è¾“å…¥: è¯„ä¼°ç»“æœ + ä¿®æ­£æ•°æ®               â”‚
â”‚ è¾“å‡º: ä¼˜åŒ–ç­–ç•¥ + è°ƒæ•´çš„è¶…å‚æ•°           â”‚
â”‚ æŒ‡æ ‡: 3-5 ä¸ªæ”¹è¿›æ–¹å‘                    â”‚
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ é˜¶æ®µ 5: åŸºå‡†å¯¹æ¯” (BENCHMARK)           â•‘
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ å°†å½“å‰æ€§èƒ½ä¸ Claude ç›®æ ‡å¯¹æ ‡ (88%)    â”‚
â”‚ â€¢ è®¡ç®—ä¸ç›®æ ‡çš„å·®è·                      â”‚
â”‚ â€¢ è¯„ä¼°æ˜¯å¦è¾¾åˆ°ç»ˆæ­¢æ¡ä»¶                  â”‚
â”‚ â€¢ ç”Ÿæˆæ”¹è¿›è·¯çº¿å›¾                        â”‚
â”‚                                        â”‚
â”‚ è¾“å…¥: å½“å‰æ€»ä½“è¯„åˆ†                      â”‚
â”‚ è¾“å‡º: å·®è·åˆ†æ + ä¸‹ä¸€æ­¥å»ºè®®             â”‚
â”‚ æŒ‡æ ‡: 88% ç›®æ ‡ vs å½“å‰ 48%             â”‚
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ ç»“æŸï¼Ÿ â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           /      \
          å¦        æ˜¯
         /          \
        â–¼            â–¼
    è¿”å›é˜¶æ®µ1   è¾“å‡ºæœ€ç»ˆæŠ¥å‘Š
    (ç»§ç»­è¿­ä»£)
```

---

## ä½¿ç”¨æ–¹æ³•

### æ–¹æ³• A: æœ€ç®€å• - è¿è¡Œå®Œæ•´è®­ç»ƒ

```bash
cd /Users/imymm/H2Q-Evo/h2q_project
python3 train_local_model_advanced.py
```

**å‘ç”Ÿäº†ä»€ä¹ˆ**:
1. å‡†å¤‡è®­ç»ƒæ•°æ® (9 ä¸ªåŸºç¡€æ ·æœ¬ + 2351 è¡Œå¤–éƒ¨æ•°æ®)
2. åŠ è½½æˆ–åˆå§‹åŒ–æ¨¡å‹
3. è¿›è¡Œ 10 æ¬¡è®­ç»ƒè¿­ä»£
4. æ¯æ¬¡è¿­ä»£æ‰§è¡Œå®Œæ•´çš„ 5 é˜¶æ®µå¾ªç¯
5. ç”Ÿæˆ JSON å’Œ Markdown æŠ¥å‘Š

**è¾“å‡º**:
```
training_output/
â”œâ”€â”€ training_report.json      # è¯¦ç»†æ•°æ® (21KB)
â””â”€â”€ training_report.md        # å¯è¯»æŠ¥å‘Š (1.4KB)
```

### æ–¹æ³• B: ç¼–ç¨‹æ–¹å¼ - è‡ªå®šä¹‰è®­ç»ƒ

```python
#!/usr/bin/env python3
import sys
sys.path.insert(0, '/Users/imymm/H2Q-Evo')

from h2q_project.local_model_advanced_training import (
    LocalModelAdvancedTrainer,
    CompetencyEvaluator,
    OutputCorrectionMechanism
)

# 1. å‡†å¤‡æ•°æ®
train_data = [
    ("å¦‚ä½•å­¦ä¹ ç¼–ç¨‹ï¼Ÿ", "ç¼–ç¨‹éœ€è¦æŒç»­ç»ƒä¹ ..."),
    ("ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ", "äººå·¥æ™ºèƒ½æ˜¯..."),
    # ... æ›´å¤šæ•°æ®å¯¹
]

val_data = [
    ("è§£é‡Šæœºå™¨å­¦ä¹ ", "æœºå™¨å­¦ä¹ æ˜¯..."),
]

# 2. åˆ›å»ºé«˜çº§è®­ç»ƒå™¨
trainer = LocalModelAdvancedTrainer(
    learning_rate=0.0001,
    num_iterations=20,
    target_level="EXPERT"
)

# 3. æ‰§è¡Œè®­ç»ƒ
metrics = trainer.train(train_data, val_data)

# 4. æŸ¥çœ‹ç»“æœ
print(f"æœ€ç»ˆè¯„åˆ†: {metrics.overall_score:.2%}")
print(f"èƒ½åŠ›ç­‰çº§: {metrics.level}")
```

### æ–¹æ³• C: API æ–¹å¼ - é›†æˆåˆ° HTTP æœåŠ¡

```python
# åœ¨ h2q_project/h2q_server.py ä¸­æ·»åŠ ç«¯ç‚¹

from fastapi import FastAPI
from local_model_advanced_training import CompetencyEvaluator

app = FastAPI()

@app.post("/evaluate/competency")
async def evaluate_competency(text: str):
    """è¯„ä¼°æ–‡æœ¬çš„èƒ½åŠ›ç­‰çº§"""
    evaluator = CompetencyEvaluator()
    metrics = evaluator.evaluate_full(text)
    return {
        "overall_score": metrics.overall_score,
        "level": metrics.level.name,
        "dimensions": {
            "correctness": metrics.correctness,
            "consistency": metrics.consistency,
            # ... å…¶ä»–ç»´åº¦
        }
    }

@app.post("/correct/output")
async def correct_output(text: str):
    """è‡ªåŠ¨çŸ«æ­£æ–‡æœ¬è¾“å‡º"""
    from local_model_advanced_training import OutputCorrectionMechanism
    corrector = OutputCorrectionMechanism()
    errors = corrector.detect_errors(text)
    corrected = corrector.correct_output(text)
    return {
        "original": text,
        "corrected": corrected,
        "errors_detected": len(errors),
        "error_types": list(errors.keys())
    }
```

---

## é…ç½®å’Œä¼˜åŒ–

### 1. è°ƒæ•´è®­ç»ƒè¶…å‚æ•°

```python
trainer = LocalModelAdvancedTrainer(
    learning_rate=0.0001,      # å­¦ä¹ ç‡ (è¾ƒä½æ›´ç¨³å®š)
    batch_size=32,             # æ‰¹å¤§å°
    num_iterations=10,         # è¿­ä»£æ¬¡æ•° (æ›´å¤š = æ›´å¥½ä½†æ›´æ…¢)
    target_level="EXPERT"      # ç›®æ ‡ç­‰çº§
)
```

**å»ºè®®**:
- å­¦ä¹ ç‡: 0.0001 (ç¨³å®š) åˆ° 0.001 (å¿«é€Ÿ)
- è¿­ä»£æ¬¡æ•°: 10 (å¿«é€Ÿæµ‹è¯•) åˆ° 100 (ç”Ÿäº§)
- ç›®æ ‡ç­‰çº§: INTERMEDIATE â†’ ADVANCED â†’ EXPERT

### 2. ä¼˜åŒ–è¯„ä¼°æƒé‡

```python
evaluator = CompetencyEvaluator()

# ä¿®æ”¹æƒé‡é…ç½® (åœ¨ç±»ä¸­ç¼–è¾‘)
# åŸºç¡€ç»´åº¦æƒé‡: å„ 8%
# é«˜çº§ç»´åº¦æƒé‡: å„ 12%

# ç‰¹å®šåœºæ™¯è°ƒæ•´:
if use_case == "ä»£ç ç”Ÿæˆ":
    weights = {
        "reasoning_depth": 0.15,    # æé«˜æ¨ç†æƒé‡
        "creativity": 0.10,          # æé«˜åˆ›æ„æƒé‡
        "correctness": 0.10,         # æé«˜æ­£ç¡®æ€§æƒé‡
    }
```

### 3. æ‰©å±•é”™è¯¯æ£€æµ‹è§„åˆ™

```python
from local_model_advanced_training import OutputCorrectionMechanism

corrector = OutputCorrectionMechanism()

# æ·»åŠ è‡ªå®šä¹‰æ£€æµ‹è§„åˆ™
def detect_custom_error(text):
    """æ£€æµ‹è‡ªå®šä¹‰é”™è¯¯æ¨¡å¼"""
    # ä¾‹å¦‚: æ£€æµ‹ç‰¹å®šé¢†åŸŸçš„å¸¸è§é”™è¯¯
    if "ä¸å¥½æ„æ€" in text and "æŠ±æ­‰" in text:
        return True
    return False

# åœ¨ detect_errors æ–¹æ³•ä¸­é›†æˆ
```

---

## æ€§èƒ½ä¼˜åŒ–æŠ€å·§

### å¿«é€Ÿä¼˜åŒ– (ç«‹å³è§æ•ˆ)

```bash
# 1. ä½¿ç”¨ GPU åŠ é€Ÿ (å¦‚å¯ç”¨)
export CUDA_VISIBLE_DEVICES=0

# 2. å¢åŠ æ‰¹å¤§å°ä»¥åŠ å¿«å¤„ç†
python3 train_local_model_advanced.py --batch-size 64

# 3. å‡å°‘éªŒè¯é›†å¤§å°ä»¥åŠ å¿«è¿­ä»£
# ç¼–è¾‘è„šæœ¬ä¸­çš„ split æ¯”ä¾‹
```

### ä¸­æœŸä¼˜åŒ– (1-2 å‘¨)

```python
# 1. å®ç°å­¦ä¹ ç‡è¡°å‡
import math
learning_rate = initial_lr * math.exp(-0.1 * epoch)

# 2. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
from torch.cuda.amp import autocast
with autocast():
    # è®­ç»ƒä»£ç 

# 3. æ¢¯åº¦ç´¯ç§¯
for accum_step in range(gradient_accumulation_steps):
    # è®­ç»ƒå°æ‰¹æ¬¡
    # ç´¯ç§¯æ¢¯åº¦
```

### é•¿æœŸä¼˜åŒ– (1+ æœˆ)

```python
# 1. çŸ¥è¯†è’¸é¦
#    ä½¿ç”¨æ›´å¤§çš„æ•™å¸ˆæ¨¡å‹è®­ç»ƒå­¦ç”Ÿæ¨¡å‹
student = SmallModel()
teacher = LargeModel()

# 2. è‡ªé€‚åº”æƒé‡
#    æ ¹æ®æ€§èƒ½åŠ¨æ€è°ƒæ•´ç»´åº¦æƒé‡

# 3. æ•°æ®å¢å¼º
#    é€šè¿‡ paraphrase/back-translation å¢åŠ æ•°æ®å¤šæ ·æ€§
```

---

## æ•…éšœæ’é™¤

### é—®é¢˜ 1: è®­ç»ƒé€Ÿåº¦å¾ˆæ…¢

**ç—‡çŠ¶**: å•ä¸ªè¿­ä»£è€—æ—¶è¶…è¿‡ 1 ç§’

**åŸå› **:
- æ•°æ®è¿‡å¤§
- ä½¿ç”¨ CPU è€Œé GPU
- æ¨¡å‹è¿‡å¤æ‚

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ–¹æ¡ˆ A: å¯ç”¨ GPU
export CUDA_VISIBLE_DEVICES=0

# æ–¹æ¡ˆ B: å‡å°‘æ•°æ®é‡
python3 -c "
import train_local_model_advanced
train_local_model_advanced.prepare_training_data(max_samples=100)
"

# æ–¹æ¡ˆ C: ç®€åŒ–æ¨¡å‹
# ç¼–è¾‘ local_model_advanced_training.py ä¸­çš„æ¨¡å‹é…ç½®
```

### é—®é¢˜ 2: èƒ½åŠ›è¯„åˆ†æ²¡æœ‰æ”¹è¿›

**ç—‡çŠ¶**: å¤šæ¬¡è¿­ä»£åè¯„åˆ†ä¿æŒ 48%

**åŸå› **:
- æ¨¡å‹å·²æ”¶æ•›
- æ•°æ®ä¸å¤Ÿå¤šæ ·åŒ–
- å­¦ä¹ ç‡è®¾ç½®ä¸å½“

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ A: å¢åŠ è®­ç»ƒè½®æ•°
trainer = LocalModelAdvancedTrainer(num_iterations=50)

# æ–¹æ¡ˆ B: è°ƒæ•´å­¦ä¹ ç‡
trainer = LocalModelAdvancedTrainer(learning_rate=0.0005)

# æ–¹æ¡ˆ C: å¢åŠ æ•°æ®å¤šæ ·æ€§
# åŠ è½½æ›´å¤šå¤–éƒ¨æ•°æ®æº
```

### é—®é¢˜ 3: å†…å­˜ä¸è¶³

**ç—‡çŠ¶**: `RuntimeError: CUDA out of memory` æˆ– `MemoryError`

**åŸå› **:
- æ‰¹å¤§å°è¿‡å¤§
- æ¨¡å‹æƒé‡å¤ªå¤š
- æ•°æ®é›†åŠ è½½åˆ°å†…å­˜

**è§£å†³æ–¹æ¡ˆ**:
```python
# å‡å°‘æ‰¹å¤§å°
trainer = LocalModelAdvancedTrainer(batch_size=8)

# ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
model.gradient_checkpointing_enable()

# æ¸…ç†ç¼“å­˜
import torch
torch.cuda.empty_cache()
```

---

## ç›‘æ§å’Œæ—¥å¿—

### æŸ¥çœ‹å®æ—¶æ—¥å¿—

```bash
# åŸºæœ¬æ—¥å¿—
python3 train_local_model_advanced.py | tail -f

# è¯¦ç»†æ—¥å¿— (åŒ…æ‹¬è°ƒè¯•ä¿¡æ¯)
PYTHONPATH=. python3 -c "
import logging
logging.basicConfig(level=logging.DEBUG)
# ... è¿è¡Œè®­ç»ƒ
"

# ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶
python3 train_local_model_advanced.py > training.log 2>&1 &
tail -f training.log
```

### ç›‘æ§å…³é”®æŒ‡æ ‡

```python
import json

# è¯»å–è®­ç»ƒæŠ¥å‘Š
with open('training_output/training_report.json') as f:
    report = json.load(f)

# æå–å…³é”®æŒ‡æ ‡
for iteration in report['iterations']:
    print(f"è¿­ä»£ {iteration['iteration_num']}")
    print(f"  æŸå¤±: {iteration['train_loss']:.4f}")
    print(f"  è¯„åˆ†: {iteration['overall_score']:.2%}")
    print(f"  ç­‰çº§: {iteration['level']}")
```

---

## æ‰©å±•å’Œé›†æˆ

### ä¸ H2Q ç³»ç»Ÿé›†æˆ

```python
# å°†é«˜çº§è®­ç»ƒç³»ç»Ÿé›†æˆåˆ° H2Q ä¸»ç³»ç»Ÿ

from evolution_system import H2QNexus
from local_model_advanced_training import LocalModelAdvancedTrainer

nexus = H2QNexus()

# ä½¿ç”¨é«˜çº§è®­ç»ƒæ›¿ä»£é»˜è®¤è®­ç»ƒ
trainer = LocalModelAdvancedTrainer()
metrics = trainer.train(
    train_data=nexus.training_data,
    val_data=nexus.validation_data
)

# ä¿å­˜æ€§èƒ½æŒ‡æ ‡
nexus.log_performance_metrics(metrics)
```

### ä¸å¤–éƒ¨æ¨¡å‹é›†æˆ

```python
# ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹è€Œä¸æ˜¯é»˜è®¤çš„ DiscreteDecisionEngine

from local_model_advanced_training import LocalModelAdvancedTrainer

class CustomModelAdapter:
    """é€‚é…è‡ªå®šä¹‰æ¨¡å‹åˆ°è®­ç»ƒç³»ç»Ÿ"""
    def __init__(self, model):
        self.model = model
    
    def forward(self, x):
        return self.model.predict(x)
    
    def backward(self, loss):
        loss.backward()

# ä½¿ç”¨é€‚é…å™¨
trainer = LocalModelAdvancedTrainer(model=CustomModelAdapter(my_model))
```

---

## æœ€ä½³å®è·µ

### 1. å®šæœŸå¤‡ä»½

```bash
# å¤‡ä»½è®­ç»ƒæ•°æ®å’Œæ¨¡å‹
cp -r training_output training_output.backup
cp h2q_project/*.pth h2q_project/backup/
```

### 2. ç‰ˆæœ¬æ§åˆ¶

```bash
# ä¸ºæ¯ä¸ªé‡è¦çš„è®­ç»ƒè¿è¡Œåˆ›å»º tag
git tag -a v2.2.1-training-run-20260120 -m "Local model advanced training v1"
git push origin v2.2.1-training-run-20260120
```

### 3. æ€§èƒ½å¯¹æ ‡

```python
# å®šæœŸè¿è¡ŒåŸºå‡†æµ‹è¯•
benchmark_scores = {
    "date": datetime.now(),
    "overall_score": 0.4836,
    "target_score": 0.8834,  # Claude level
    "gap": 0.3998
}

# ä¿å­˜å¯¹æ ‡ç»“æœ
with open('benchmarks.json', 'a') as f:
    json.dump(benchmark_scores, f)
```

### 4. æ–‡æ¡£ç»´æŠ¤

```markdown
# å®šæœŸæ›´æ–°æ–‡æ¡£
- è®°å½•æ¯ä¸ªè®­ç»ƒè¿è¡Œçš„å‚æ•°
- ä¿å­˜å…³é”®å‘ç°å’Œæ”¹è¿›å»ºè®®
- ç»´æŠ¤ FAQ å’Œæ•…éšœæ’é™¤æŒ‡å—
```

---

## å¸¸è§é—®é¢˜ (FAQ)

**Q: è¿™ä¸ªç³»ç»Ÿå’Œåœ¨çº¿å¤§æ¨¡å‹(GPT-4/Claude)æœ‰ä»€ä¹ˆåŒºåˆ«?**
A: ä¸»è¦åŒºåˆ«æ˜¯å‚æ•°é‡å’Œè®­ç»ƒæ•°æ®ã€‚æœ¬åœ°ç³»ç»Ÿé‡ç‚¹æ˜¯**å¯æ§æ€§**å’Œ**å¯è§£é‡Šæ€§**ï¼Œé€šè¿‡å¤šç»´è¯„ä¼°å’Œæ˜ç¡®çš„æ”¹è¿›æ­¥éª¤æ¥å®ç°èƒ½åŠ›æå‡ã€‚

**Q: èƒ½è¾¾åˆ° Claude çš„æ°´å¹³å—?**
A: å®Œå…¨è¾¾åˆ°éœ€è¦æ›´å¤šæ•°æ®å’Œè®¡ç®—èµ„æºã€‚ä½†è¿™ä¸ªç³»ç»Ÿæä¾›äº†**æ¸…æ™°çš„æ”¹è¿›è·¯å¾„**:
- å½“å‰: 48% (INTERMEDIATE)
- çŸ­æœŸç›®æ ‡: 65% (ADVANCED)
- ä¸­æœŸç›®æ ‡: 80% (EXPERT)
- é•¿æœŸç›®æ ‡: 88%+ (Claude çº§åˆ«)

**Q: å¦‚ä½•å¤„ç†ä¸­æ–‡ä»¥å¤–çš„è¯­è¨€?**
A: ç³»ç»Ÿè¯­è¨€æ— å…³ï¼Œä½†è¯„ä¼°è§„åˆ™éœ€è¦è°ƒæ•´ã€‚å»ºè®®:
1. åˆ‡æ¢è¯„ä¼°è¯­è¨€ï¼ˆåœ¨ CompetencyEvaluator ä¸­ï¼‰
2. è°ƒæ•´è§„åˆ™å’Œå…³é”®è¯
3. ä½¿ç”¨è¯¥è¯­è¨€çš„è®­ç»ƒæ•°æ®

**Q: èƒ½åœ¨ GPU ä¸Šè¿è¡Œå—?**
A: å®Œå…¨æ”¯æŒã€‚ç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹ CUDA å¯ç”¨æ€§ã€‚è¦å¼ºåˆ¶ä½¿ç”¨ GPU:
```python
import torch
device = torch.device("cuda:0")
# åœ¨æ¨¡å‹å’Œæ•°æ®ä¸Šè°ƒç”¨ .to(device)
```

**Q: å¦‚ä½•æ·»åŠ è‡ªå®šä¹‰çš„è¯„ä¼°ç»´åº¦?**
A: åœ¨ `CompetencyEvaluator` ä¸­æ·»åŠ æ–°æ–¹æ³•ï¼š
```python
def evaluate_custom_dimension(self, text):
    # å®ç°è¯„ä¼°é€»è¾‘
    return score  # 0.0 åˆ° 1.0
```

---

## è”ç³»å’Œæ”¯æŒ

- **GitHub**: https://github.com/makai891124-prog/H2Q-Evo
- **æ–‡æ¡£**: `LOCAL_MODEL_TRAINING_GUIDE.md`
- **é—®é¢˜æŠ¥å‘Š**: é€šè¿‡ GitHub Issues

---

**ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼ğŸš€**
