#!/usr/bin/env python3
"""
H2Q-Evo å­¦ä¹ æˆæœç»¼åˆå±•ç¤º
"""

import json
from pathlib import Path
from datetime import datetime

print("="*80)
print("ğŸ“ H2Q-Evo æŒç»­ç›‘ç£å­¦ä¹ ä¸è¿›åŒ–ç³»ç»Ÿ - ç»¼åˆæˆæœå±•ç¤º")
print("="*80)
print(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print()

# è¯»å–å­¦ä¹ æŠ¥å‘Š
report_file = Path("learning_report.json")
if not report_file.exists():
    print("âš ï¸ å­¦ä¹ æŠ¥å‘Šæœªç”Ÿæˆ")
    exit(1)

with open(report_file) as f:
    report = json.load(f)

# åŸºæœ¬ç»Ÿè®¡
stats = report['stats']
kb_stats = report['kb_stats']

print("ğŸ“Š æ ¸å¿ƒæŒ‡æ ‡")
print("-"*80)
print(f"æ€»å­¦ä¹ é¡¹ç›®:     {stats['total_learned']:3d} é¡¹")
print(f"çŸ¥è¯†åº“æ€»é‡:     {kb_stats['total_count']:3d} æ¡")
print(f"å·²éªŒè¯çŸ¥è¯†:     {kb_stats['verified_count']:3d} æ¡ ({kb_stats['verified_count']/kb_stats['total_count']*100:.1f}%)")
print(f"æµ‹è¯•æ¬¡æ•°:       {len(report['test_results']):3d} æ¬¡")
print(f"è¿›åŒ–å‘¨æœŸ:       {stats['evolution_count']:3d} æ¬¡")
print()

# çŸ¥è¯†å¢é•¿
print("ğŸ“ˆ çŸ¥è¯†å¢é•¿")
print("-"*80)
initial_verified = 2  # åˆå§‹å·²éªŒè¯
growth = kb_stats['verified_count'] - initial_verified
growth_rate = (growth / initial_verified * 100) if initial_verified > 0 else 0
print(f"åˆå§‹çŠ¶æ€:       {initial_verified} æ¡å·²éªŒè¯")
print(f"å½“å‰çŠ¶æ€:       {kb_stats['verified_count']} æ¡å·²éªŒè¯")
print(f"å¢é•¿æ•°é‡:       +{growth} æ¡")
print(f"å¢é•¿ç‡:         +{growth_rate:.0f}%")
print()

# é¡¶çº§æŒæ¡
print("âœ¨ æŒæ¡æœ€å¥½çš„æ¦‚å¿µ (Top 5)")
print("-"*80)
if 'top_concepts' in report and report['top_concepts']:
    for i, item in enumerate(report['top_concepts'][:5], 1):
        concept = item['concept']
        domain = item['domain']
        score = item['understanding_score'] * 100
        quality = "ğŸŒŸä¼˜ç§€" if score >= 80 else "âœ…è‰¯å¥½" if score >= 70 else "ğŸ“åŠæ ¼"
        print(f"{i}. {concept:30s} â”‚ {domain:20s} â”‚ {score:5.1f}% â”‚ {quality}")
else:
    print("   (æš‚æ— æ•°æ®)")
print()

# å„é¢†åŸŸåˆ†å¸ƒ
print("ğŸ¯ å„é¢†åŸŸæŒæ¡æƒ…å†µ")
print("-"*80)

from large_knowledge_base import LargeKnowledgeBase
kb = LargeKnowledgeBase()
kb.load()

for domain, total in sorted(kb_stats['by_domain'].items()):
    verified = sum(1 for k in kb.knowledge[domain] if k.get('verified'))
    mastery = verified / total * 100 if total > 0 else 0
    bar = "â–ˆ" * int(mastery / 5)
    quality = "ğŸŒŸä¼˜ç§€" if mastery >= 80 else "âœ…è‰¯å¥½" if mastery >= 60 else "ğŸ“åŠæ ¼" if mastery >= 40 else "âš ï¸éœ€åŠ å¼º"
    print(f"{domain:20s} â”‚{bar:<20s}â”‚ {verified:2d}/{total:2d} ({mastery:5.1f}%) {quality}")
print()

# æµ‹è¯•ç»“æœ
if report['test_results']:
    print("ğŸ¯ æµ‹è¯•å†å²")
    print("-"*80)
    for i, test in enumerate(report['test_results'], 1):
        status = "âœ…" if test['quality'] in ['excellent', 'good'] else "âš ï¸"
        quality_cn = {"excellent": "ä¼˜ç§€", "good": "è‰¯å¥½", "needs_improvement": "éœ€æ”¹è¿›"}.get(test['quality'], test['quality'])
        print(f"æµ‹è¯• {i}: {status} {test['correct']}/{test['total']} æ­£ç¡® ({test['pass_rate']*100:.0f}%) - {quality_cn}")
    print()

# è´¨é‡è¯„ä¼°
if stats['quality_scores']:
    avg_quality = sum(stats['quality_scores']) / len(stats['quality_scores'])
    print("ğŸ“Š å­¦ä¹ è´¨é‡è¯„ä¼°")
    print("-"*80)
    print(f"å¹³å‡è´¨é‡:       {avg_quality*100:.1f}%")
    print(f"æœ€é«˜è´¨é‡:       {max(stats['quality_scores'])*100:.0f}%")
    print(f"æœ€ä½è´¨é‡:       {min(stats['quality_scores'])*100:.0f}%")
    print(f"è´¨é‡è¯„çº§:       ", end="")
    if avg_quality >= 0.85:
        print("ğŸŒŸ ä¼˜ç§€")
    elif avg_quality >= 0.70:
        print("âœ… è‰¯å¥½")
    elif avg_quality >= 0.60:
        print("ğŸ“ åŠæ ¼")
    else:
        print("âš ï¸ éœ€æ”¹è¿›")
    print()

# å­¦ä¹ æ•ˆç‡
if stats['total_learned'] > 0:
    print("âš¡ å­¦ä¹ æ•ˆç‡")
    print("-"*80)
    
    # è®¡ç®—æ€»æ—¶é—´
    total_time = sum(item['learning_time'] for item in report['top_concepts'])
    avg_time = total_time / len(report['top_concepts']) if report['top_concepts'] else 0
    
    print(f"å¹³å‡å­¦ä¹ æ—¶é—´:   {avg_time:.2f} ç§’/æ¦‚å¿µ")
    print(f"å­¦ä¹ é€Ÿç‡:       {1/avg_time:.2f} æ¦‚å¿µ/ç§’" if avg_time > 0 else "N/A")
    print()

# ç³»ç»ŸçŠ¶æ€
print("ğŸ”§ ç³»ç»ŸçŠ¶æ€")
print("-"*80)
print(f"âœ… æŒç»­å­¦ä¹ ç³»ç»Ÿ:  è¿è¡Œæ­£å¸¸")
print(f"âœ… çŸ¥è¯†åº“:        {kb_stats['total_count']}æ¡ï¼ŒæŒä¹…åŒ–æˆåŠŸ")
print(f"âœ… å­¦ä¹ æŠ¥å‘Š:      å·²ç”Ÿæˆ")
print(f"âœ… è‡ªæˆ‘è¿›åŒ–:      {stats['evolution_count']}æ¬¡")
print()

# éªŒæ”¶ç»“è®º
print("="*80)
print("ğŸ‰ éªŒæ”¶ç»“è®º")
print("="*80)
verdict = "âœ… é€šè¿‡" if kb_stats['verified_count'] >= 10 and (avg_quality >= 0.7 if stats['quality_scores'] else True) else "âš ï¸ éœ€æ”¹è¿›"
print(f"éªŒæ”¶çŠ¶æ€:       {verdict}")
print()

if kb_stats['verified_count'] >= 10:
    print("âœ… çŸ¥è¯†å¢é•¿è¾¾æ ‡ (â‰¥10æ¡éªŒè¯çŸ¥è¯†)")
else:
    print(f"âš ï¸ çŸ¥è¯†å¢é•¿ä¸è¶³ ({kb_stats['verified_count']}/10)")

if stats['quality_scores'] and avg_quality >= 0.7:
    print("âœ… å­¦ä¹ è´¨é‡è¾¾æ ‡ (â‰¥70%)")
else:
    print(f"âš ï¸ å­¦ä¹ è´¨é‡å¾…æå‡")

if stats['evolution_count'] > 0:
    print(f"âœ… ç³»ç»Ÿè¿›åŒ–æ­£å¸¸ ({stats['evolution_count']}æ¬¡)")
else:
    print("âš ï¸ æœªè§¦å‘ç³»ç»Ÿè¿›åŒ–")

print()
print("="*80)
print("ğŸ“ è¯¦ç»†æŠ¥å‘Š: LEARNING_ACHIEVEMENT_REPORT.md")
print("ğŸ“Š åŸå§‹æ•°æ®: learning_report.json")
print("="*80)
