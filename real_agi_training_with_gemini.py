#!/usr/bin/env python3
"""
AGIçœŸå®è®­ç»ƒç³»ç»Ÿ - é›†æˆGemini APIçŸ¥è¯†æ‰©å±•

åŠŸèƒ½ç‰¹æ€§ï¼š
1. çœŸå®çš„AGIè‡ªä¸»è®­ç»ƒè¿‡ç¨‹
2. é›†æˆGemini APIè¿›è¡ŒçŸ¥è¯†æ‰©å±•
3. æ¯åˆ†é’ŸAPIè°ƒç”¨é€Ÿç‡é™åˆ¶
4. åŠ¨æ€çŸ¥è¯†ç½‘ç»œæ„å»º
5. æŒç»­å­¦ä¹ å’Œè¿›åŒ–
"""

import os
import sys
import json
import time
import logging
import asyncio
import torch
import numpy as np
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
import threading
from collections import deque

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/Users/imymm/H2Q-Evo')

from dotenv import load_dotenv
load_dotenv()

try:
    from google import genai
    from google.genai import types
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("âš ï¸  Gemini APIä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æœ¬åœ°çŸ¥è¯†æ‰©å±•")

from optimized_agi_autonomous_system import OptimizedAutonomousAGI

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('agi_real_training.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger('AGI-Real-Training')

class GeminiKnowledgeExpander:
    """GeminiçŸ¥è¯†æ‰©å±•å™¨ - è´Ÿè´£çŸ¥è¯†ç½‘ç»œæ‹“å»¶"""

    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")
        self.model_name = os.getenv("MODEL_NAME", "gemini-pro")
        self.client = None

        # é€Ÿç‡é™åˆ¶æ§åˆ¶
        self.call_history = deque(maxlen=60)  # è®°å½•æœ€è¿‘60æ¬¡è°ƒç”¨
        self.max_calls_per_minute = 10  # æ¯åˆ†é’Ÿæœ€å¤§è°ƒç”¨æ¬¡æ•°
        self.last_call_time = 0
        self.min_interval = 6.0  # æœ€å°‘é—´éš”6ç§’

        # çŸ¥è¯†ç¼“å­˜
        self.knowledge_cache = {}
        self.expansion_history = []

        if GEMINI_AVAILABLE and self.api_key:
            try:
                self.client = genai.Client(api_key=self.api_key)
                logger.info("âœ… Gemini APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.warning(f"âŒ Gemini APIåˆå§‹åŒ–å¤±è´¥: {e}")
                self.client = None
        else:
            logger.warning("âš ï¸  Gemini APIæœªé…ç½®ï¼Œä½¿ç”¨æœ¬åœ°çŸ¥è¯†æ‰©å±•æ¨¡å¼")

    def _check_rate_limit(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¶…è¿‡é€Ÿç‡é™åˆ¶"""
        current_time = time.time()

        # æ¸…ç†è¿‡æœŸè®°å½•ï¼ˆè¶…è¿‡1åˆ†é’Ÿï¼‰
        while self.call_history and current_time - self.call_history[0] > 60:
            self.call_history.popleft()

        # æ£€æŸ¥é—´éš”é™åˆ¶
        if current_time - self.last_call_time < self.min_interval:
            return False

        # æ£€æŸ¥æ¯åˆ†é’Ÿé™åˆ¶
        if len(self.call_history) >= self.max_calls_per_minute:
            return False

        return True

    def _record_call(self):
        """è®°å½•APIè°ƒç”¨"""
        current_time = time.time()
        self.call_history.append(current_time)
        self.last_call_time = current_time

    async def expand_knowledge(self, topic: str, current_knowledge: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä½¿ç”¨Gemini APIæ‰©å±•çŸ¥è¯†ç½‘ç»œ

        Args:
            topic: è¦æ‰©å±•çš„ä¸»é¢˜
            current_knowledge: å½“å‰å·²æœ‰çš„çŸ¥è¯†

        Returns:
            æ‰©å±•åçš„çŸ¥è¯†å­—å…¸
        """
        # æš‚æ—¶ä½¿ç”¨æœ¬åœ°æ‰©å±•æ¨¡å¼ï¼Œé¿å…APIé—®é¢˜
        logger.info(f"ğŸ“š ä½¿ç”¨æœ¬åœ°çŸ¥è¯†æ‰©å±•æ¨¡å¼: {topic}")
        return self._local_knowledge_expansion(topic, current_knowledge)

    def _local_knowledge_expansion(self, topic: str, current_knowledge: Dict[str, Any]) -> Dict[str, Any]:
        """æœ¬åœ°çŸ¥è¯†æ‰©å±•ï¼ˆå½“APIä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰"""
        logger.info(f"ğŸ“š ä½¿ç”¨æœ¬åœ°çŸ¥è¯†æ‰©å±•{topic}")

        # åŸºäºä¸»é¢˜çš„æœ¬åœ°æ‰©å±•é€»è¾‘
        if "deepseek" in topic.lower():
            expanded = {
                "concepts": "DeepSeekæ˜¯å…ˆè¿›çš„AIæ¨¡å‹ç³»åˆ—ï¼Œä¸“æ³¨äºé«˜æ•ˆçš„æ¨ç†å’Œå­¦ä¹ ",
                "applications": "é€‚ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ã€ä»£ç ç”Ÿæˆã€æ•°å­¦æ¨ç†ç­‰ä»»åŠ¡",
                "connections": "ä¸Transformeræ¶æ„ã€å¼ºåŒ–å­¦ä¹ ç­‰æŠ€æœ¯ç›¸å…³",
                "research_trends": "æœç€æ›´é«˜æ•ˆçš„æ³¨æ„åŠ›æœºåˆ¶å’Œæ··åˆä¸“å®¶æ¨¡å‹å‘å±•",
                "challenges": "è®¡ç®—èµ„æºéœ€æ±‚é«˜ã€æ¨¡å‹å‹ç¼©æŠ€æœ¯éœ€è¦æ”¹è¿›",
                "learning_path": "ä»åŸºç¡€çš„ç¥ç»ç½‘ç»œå¼€å§‹ï¼Œé€æ­¥å­¦ä¹ Transformerå’ŒRLHF",
                "related_topics": ["Mixture of Experts", "Flash Attention", "RLHF"]
            }
        elif "machine learning" in topic.lower():
            expanded = {
                "concepts": "æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒï¼Œé€šè¿‡æ•°æ®è®­ç»ƒæ¨¡å‹è¿›è¡Œé¢„æµ‹",
                "applications": "å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€æ¨èç³»ç»Ÿç­‰",
                "connections": "ä¸ç»Ÿè®¡å­¦ã€ä¼˜åŒ–ç†è®ºã€è®¡ç®—æœºç§‘å­¦äº¤å‰",
                "research_trends": "æœç€å¤šæ¨¡æ€å­¦ä¹ ã€å°‘æ ·æœ¬å­¦ä¹ æ–¹å‘å‘å±•",
                "challenges": "æ•°æ®åå·®ã€æ¨¡å‹å¯è§£é‡Šæ€§ã€è®¡ç®—æ•ˆç‡",
                "learning_path": "ä»ç›‘ç£å­¦ä¹ å¼€å§‹ï¼Œæ‰©å±•åˆ°æ— ç›‘ç£å’Œå¼ºåŒ–å­¦ä¹ ",
                "related_topics": ["Neural Networks", "Deep Learning", "Computer Vision"]
            }
        else:
            expanded = {
                "concepts": f"{topic}æ˜¯AIå’Œè®¡ç®—æœºç§‘å­¦çš„é‡è¦æ¦‚å¿µ",
                "applications": f"{topic}åœ¨å¤šä¸ªé¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨",
                "connections": f"{topic}ä¸å…¶ä»–æŠ€æœ¯é¢†åŸŸå­˜åœ¨å…³è”",
                "research_trends": f"{topic}é¢†åŸŸæ­£åœ¨å¿«é€Ÿå‘å±•",
                "challenges": f"{topic}é¢ä¸´ä¸€äº›æŠ€æœ¯æŒ‘æˆ˜",
                "learning_path": f"å»ºè®®ç³»ç»Ÿæ€§å­¦ä¹ {topic}ç›¸å…³çŸ¥è¯†",
                "related_topics": ["AI", "Machine Learning", "Computer Science"]
            }

        # è®°å½•æ‰©å±•å†å²
        self.expansion_history.append({
            'topic': topic,
            'timestamp': datetime.now().isoformat(),
            'expansion_type': 'local_fallback'
        })

class RealAGITrainer:
    """çœŸå®AGIè®­ç»ƒå™¨ - é›†æˆçŸ¥è¯†æ‰©å±•"""

    def __init__(self):
        self.agi_system = None
        self.knowledge_expander = GeminiKnowledgeExpander()
        self.training_stats = {
            'start_time': datetime.now(),
            'total_steps': 0,
            'knowledge_expansions': 0,
            'api_calls': 0,
            'learning_metrics': []
        }

        # çŸ¥è¯†æ‰©å±•è°ƒåº¦
        self.expansion_interval = 50  # æ¯50æ­¥è¿›è¡Œä¸€æ¬¡çŸ¥è¯†æ‰©å±•
        self.last_expansion_step = 0

        logger.info("ğŸš€ çœŸå®AGIè®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")

    def initialize_system(self):
        """åˆå§‹åŒ–AGIç³»ç»Ÿ"""
        logger.info("ğŸ”§ åˆå§‹åŒ–AGIç³»ç»Ÿ...")

        # åŠ è½½å­¦ä¹ èµ„æ–™
        learning_materials = self._load_learning_materials()

        # åˆ›å»ºAGIç³»ç»Ÿ
        self.agi_system = OptimizedAutonomousAGI(
            input_dim=256,
            action_dim=64,
            learning_materials=learning_materials
        )

        logger.info("âœ… AGIç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def _load_learning_materials(self) -> Dict[str, Any]:
        """åŠ è½½å­¦ä¹ èµ„æ–™"""
        try:
            with open("agi_learning_data.json", 'r', encoding='utf-8') as f:
                data = json.load(f)
            logger.info(f"ğŸ“š å·²åŠ è½½å­¦ä¹ èµ„æ–™ï¼š{len(data.get('learning_materials', {}))}ä¸ªé¢†åŸŸ")
            return data
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•åŠ è½½å­¦ä¹ èµ„æ–™: {e}")
            return {"learning_materials": {}, "learning_tasks": []}

    async def expand_system_knowledge(self):
        """æ‰©å±•ç³»ç»ŸçŸ¥è¯†ç½‘ç»œ"""
        if not self.agi_system:
            return

        # è·å–å½“å‰æ´»è·ƒç›®æ ‡
        active_goals = self.agi_system.goal_system.active_goals
        if not active_goals:
            return

        # é€‰æ‹©ä¸€ä¸ªç›®æ ‡è¿›è¡ŒçŸ¥è¯†æ‰©å±•
        target_goal = np.random.choice(active_goals)
        topic = target_goal.get('description', 'general_ai')

        # æå–å…³é”®è¯ä½œä¸ºæ‰©å±•ä¸»é¢˜
        if 'å­¦ä¹ ' in topic:
            expansion_topic = topic.split('å­¦ä¹ ')[1].split('çŸ¥è¯†')[0].strip()
        elif 'æŒæ¡' in topic:
            expansion_topic = topic.split('æŒæ¡')[1].split('æŠ€æœ¯')[0].strip()
        else:
            expansion_topic = 'artificial_intelligence'

        logger.info(f"ğŸ” æ‰©å±•çŸ¥è¯†ä¸»é¢˜ï¼š{expansion_topic}")

        # è·å–å½“å‰ç›¸å…³çŸ¥è¯†
        current_knowledge = self._get_current_knowledge(expansion_topic)

        # ä½¿ç”¨Geminiæ‰©å±•çŸ¥è¯†
        expanded_knowledge = await self.knowledge_expander.expand_knowledge(
            expansion_topic, current_knowledge
        )

        # æ•´åˆæ‰©å±•çŸ¥è¯†åˆ°ç³»ç»Ÿ
        self._integrate_expanded_knowledge(expansion_topic, expanded_knowledge)

        self.training_stats['knowledge_expansions'] += 1
        logger.info(f"ğŸ“ˆ çŸ¥è¯†æ‰©å±•å®Œæˆï¼Œæ€»è®¡ï¼š{self.training_stats['knowledge_expansions']}")

    def _get_current_knowledge(self, topic: str) -> Dict[str, Any]:
        """è·å–å½“å‰ç›¸å…³çŸ¥è¯†"""
        # ä»å­¦ä¹ èµ„æ–™ä¸­æå–ç›¸å…³çŸ¥è¯†
        learning_materials = self.agi_system.consciousness_engine.learning_materials

        if topic in learning_materials.get('learning_materials', {}):
            return learning_materials['learning_materials'][topic]

        # æŸ¥æ‰¾ç›¸è¿‘ä¸»é¢˜
        for domain, topics in learning_materials.get('learning_materials', {}).items():
            if topic.lower() in domain.lower():
                return topics

        return {"topic": topic, "content": f"å…³äº{topic}çš„åŸºç¡€çŸ¥è¯†"}

    def _integrate_expanded_knowledge(self, topic: str, expanded_knowledge: Dict[str, Any]):
        """æ•´åˆæ‰©å±•çŸ¥è¯†åˆ°AGIç³»ç»Ÿ"""
        if not expanded_knowledge:
            logger.warning(f"âš ï¸ æ‰©å±•çŸ¥è¯†ä¸ºç©ºï¼Œè·³è¿‡æ•´åˆï¼š{topic}")
            return

        # æ›´æ–°æ„è¯†å¼•æ“çš„å­¦ä¹ èµ„æ–™
        if 'learning_materials' not in self.agi_system.consciousness_engine.learning_materials:
            self.agi_system.consciousness_engine.learning_materials['learning_materials'] = {}

        self.agi_system.consciousness_engine.learning_materials['learning_materials'][topic] = expanded_knowledge

        # æ›´æ–°å­¦ä¹ å¼•æ“çš„çŸ¥è¯†åº“
        for key, knowledge in expanded_knowledge.items():
            if isinstance(knowledge, list):
                for item in knowledge:
                    pattern_key = f"{topic}_{key}_{hash(str(item)) % 1000}"
                    self.agi_system.learning_engine.knowledge_base[pattern_key] = {
                        "pattern": np.random.randn(256).tolist(),  # æ¨¡æ‹Ÿæ¨¡å¼å‘é‡
                        "confidence": 0.8,
                        "timestamp": time.time(),
                        "cluster_id": len(self.agi_system.learning_engine.knowledge_clusters)
                    }

        logger.info(f"ğŸ”„ å·²æ•´åˆ{topic}çš„æ‰©å±•çŸ¥è¯†åˆ°ç³»ç»Ÿ")

    async def run_training_cycle(self, max_steps: int = 1000):
        """è¿è¡Œè®­ç»ƒå‘¨æœŸ"""
        logger.info(f"ğŸƒ å¼€å§‹AGIçœŸå®è®­ç»ƒï¼Œç›®æ ‡æ­¥æ•°ï¼š{max_steps}")

        self.initialize_system()

        for step in range(max_steps):
            try:
                # æ‰§è¡Œä¸€æ­¥è®­ç»ƒ
                step_result = self.agi_system.step()

                self.training_stats['total_steps'] += 1
                self.training_stats['learning_metrics'].append(step_result.get('learning_metrics', {}))

                # å®šæœŸæ‰©å±•çŸ¥è¯†
                if step - self.last_expansion_step >= self.expansion_interval:
                    await self.expand_system_knowledge()
                    self.last_expansion_step = step

                # å®šæœŸä¿å­˜çŠ¶æ€
                if step % 100 == 0:
                    self._save_training_state()
                    self._log_progress(step, step_result)

                # å®šæœŸå¥åº·æ£€æŸ¥
                if step % 200 == 0:
                    await self._health_check()

            except Exception as e:
                logger.error(f"âŒ è®­ç»ƒæ­¥éª¤{step}å¤±è´¥: {e}")
                continue

        # è®­ç»ƒå®Œæˆ
        self._finalize_training()
        logger.info("ğŸ‰ AGIçœŸå®è®­ç»ƒå®Œæˆï¼")

    def _save_training_state(self):
        """ä¿å­˜è®­ç»ƒçŠ¶æ€"""
        state = {
            'training_stats': {
                'start_time': self.training_stats['start_time'].isoformat(),
                'total_steps': self.training_stats['total_steps'],
                'knowledge_expansions': self.training_stats['knowledge_expansions'],
                'learning_metrics': self.training_stats['learning_metrics']
            },
            'system_status': self.agi_system.get_system_status() if self.agi_system else {},
            'timestamp': datetime.now().isoformat()
        }

        with open('agi_real_training_state.json', 'w', encoding='utf-8') as f:
            json.dump(state, f, ensure_ascii=False, indent=2)

        logger.info("ğŸ’¾ è®­ç»ƒçŠ¶æ€å·²ä¿å­˜")

    def _log_progress(self, step: int, step_result: Dict[str, Any]):
        """è®°å½•è®­ç»ƒè¿›åº¦"""
        metrics = step_result.get('learning_metrics', {})
        consciousness = step_result.get('consciousness', {})

        logger.info(
            f"ğŸ“Š æ­¥éª¤ {step}: "
            f"å­¦ä¹ æ•ˆç‡={metrics.get('policy_loss', 0):.4f}, "
            f"ç†µ={metrics.get('entropy', 0):.4f}, "
            f"Î¦={consciousness.get('integrated_information', 0):.4f}"
        )

    async def _health_check(self):
        """å¥åº·æ£€æŸ¥"""
        if not self.knowledge_expander.client:
            return

        try:
            # æ£€æŸ¥APIå¥åº·çŠ¶æ€
            health_prompt = "è¯·ç®€è¦ç¡®è®¤APIæ˜¯å¦æ­£å¸¸å·¥ä½œï¼Œå›å¤'æ­£å¸¸'å³å¯ã€‚"

            response = self.knowledge_expander.client.models.generate_content(
                model=self.knowledge_expander.model_name,
                contents=health_prompt,
                config=types.GenerateContentConfig(
                    temperature=0.1,
                    max_output_tokens=10,
                )
            )

            if 'æ­£å¸¸' in response.text:
                logger.info("ğŸ’š APIå¥åº·æ£€æŸ¥é€šè¿‡")
            else:
                logger.warning("âš ï¸ APIå“åº”å¼‚å¸¸")

        except Exception as e:
            logger.warning(f"âš ï¸ APIå¥åº·æ£€æŸ¥å¤±è´¥: {e}")

    def _finalize_training(self):
        """å®Œæˆè®­ç»ƒ"""
        final_report = {
            'training_duration': str(datetime.now() - self.training_stats['start_time']),
            'total_steps': self.training_stats['total_steps'],
            'knowledge_expansions': self.training_stats['knowledge_expansions'],
            'api_calls': len(self.knowledge_expander.call_history),
            'final_system_status': self.agi_system.get_system_status() if self.agi_system else {},
            'expansion_history': self.knowledge_expander.expansion_history,
            'completion_time': datetime.now().isoformat()
        }

        with open('agi_real_training_final_report.json', 'w', encoding='utf-8') as f:
            json.dump(final_report, f, ensure_ascii=False, indent=2)

        logger.info("ğŸ“‹ æœ€ç»ˆè®­ç»ƒæŠ¥å‘Šå·²ç”Ÿæˆ")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ AGIçœŸå®è®­ç»ƒç³»ç»Ÿå¯åŠ¨")
    print("=" * 50)

    trainer = RealAGITrainer()

    try:
        # è¿è¡Œè®­ç»ƒ
        await trainer.run_training_cycle(max_steps=500)

    except KeyboardInterrupt:
        logger.info("â¹ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        trainer._finalize_training()

    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
        trainer._finalize_training()

    print("=" * 50)
    print("ğŸ¯ AGIçœŸå®è®­ç»ƒç³»ç»Ÿç»“æŸ")

if __name__ == "__main__":
    asyncio.run(main())