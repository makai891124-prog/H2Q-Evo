#!/usr/bin/env python3
"""
M24ä»£ç å®¡è®¡ - ä½œå¼Šæ£€æµ‹è„šæœ¬
åŸºäºM24çœŸå®æ€§åŸåˆ™è¿›è¡Œå…¨é¢ä»£ç å®¡è®¡
"""

import sys
import os
import json
import torch
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '.')
sys.path.insert(0, './h2q_project')

print('ğŸ” M24ä»£ç å®¡è®¡ - ä½œå¼Šæ£€æµ‹')
print('=' * 60)

# 1. æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
print('ğŸ“ æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥:')
files_to_check = [
    'm24_das_weight_converter.py',
    'm24_das_m4_inference_benchmark.py',
    'das_agi_autonomous_system.py',
    'models/das_optimized_deepseek-coder-v2-236b.pth',
    'h2q_project/das_core.py',
    'm4_benchmark_results_1769592645.json'
]

for file in files_to_check:
    exists = os.path.exists(file)
    size = os.path.getsize(file) if exists else 0
    print(f'  {"âœ…" if exists else "âŒ"} {file}: {"å­˜åœ¨" if exists else "ä¸å­˜åœ¨"} ({size} bytes)')

print()

# 2. å¯¼å…¥å’Œä¾èµ–æ£€æŸ¥
print('ğŸ“¦ å¯¼å…¥æ£€æŸ¥:')
modules_to_test = [
    ('torch', 'PyTorch'),
    ('numpy', 'NumPy'),
    ('psutil', 'psutil'),
    ('asyncio', 'asyncio'),
    ('pathlib', 'pathlib'),
    ('json', 'json'),
    ('logging', 'logging'),
    ('time', 'time'),
    ('typing', 'typing'),
    ('dataclasses', 'dataclasses'),
    ('collections', 'collections'),
    ('gc', 'gc'),
]

for module, desc in modules_to_test:
    try:
        __import__(module)
        print(f'  âœ… {desc}: å¯å¯¼å…¥')
    except ImportError as e:
        print(f'  âŒ {desc}: å¯¼å…¥å¤±è´¥ - {e}')

print()

# 3. è‡ªå®šä¹‰æ¨¡å—æ£€æŸ¥
print('ğŸ—ï¸ è‡ªå®šä¹‰æ¨¡å—æ£€æŸ¥:')
custom_modules = [
    ('h2q_project.das_core', 'DASCore'),
    ('m24_das_weight_converter', 'M24DASWeightConverter'),
    ('m24_das_m4_inference_benchmark', 'M24DASMacMiniInferenceEngine'),
    ('das_agi_autonomous_system', 'DASAGIAutonomousSystem'),
]

for module, desc in custom_modules:
    try:
        __import__(module)
        print(f'  âœ… {desc}: å¯å¯¼å…¥')
    except Exception as e:
        print(f'  âŒ {desc}: å¯¼å…¥å¤±è´¥ - {e}')

print()

# 4. DASæ ¸å¿ƒåŠŸèƒ½éªŒè¯
print('ğŸ§¬ DASæ ¸å¿ƒåŠŸèƒ½éªŒè¯:')
try:
    from h2q_project.das_core import DASCore
    das = DASCore(target_dimension=256)
    print('  âœ… DASCoreåˆå§‹åŒ–æˆåŠŸ')

    # æµ‹è¯•DASå˜æ¢
    test_tensor = torch.randn(10, 20)
    transformed, report = das(test_tensor)
    print(f'  âœ… DASå˜æ¢æµ‹è¯•é€šè¿‡: {test_tensor.shape} -> {transformed.shape}')

except Exception as e:
    print(f'  âŒ DASæ ¸å¿ƒåŠŸèƒ½å¤±è´¥: {e}')

print()

# 5. æ¨¡å‹æ–‡ä»¶éªŒè¯
print('ğŸ§  æ¨¡å‹æ–‡ä»¶éªŒè¯:')
try:
    model_path = 'models/das_optimized_deepseek-coder-v2-236b.pth'
    model_data = torch.load(model_path, map_location='cpu', weights_only=True)
    print(f'  âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {len(model_data)} ä¸ªæƒé‡å¼ é‡')

    # æ£€æŸ¥æƒé‡ç»Ÿè®¡
    total_params = sum(tensor.numel() for tensor in model_data.values())
    total_size_mb = sum(tensor.numel() * tensor.element_size() for tensor in model_data.values()) / (1024 * 1024)
    print(f'  ğŸ“Š æ€»å‚æ•°é‡: {total_params:,}')
    print(f'  ğŸ“Š æ¨¡å‹å¤§å°: {total_size_mb:.2f} MB')

    # éªŒè¯å‹ç¼©æ¯”
    original_size_mb = 117.95  # ä»ä¹‹å‰çš„æŠ¥å‘Š
    compression_ratio = original_size_mb / total_size_mb
    print(f'  ğŸ“Š å‹ç¼©æ¯”: {compression_ratio:.1f}x')

except Exception as e:
    print(f'  âŒ æ¨¡å‹æ–‡ä»¶éªŒè¯å¤±è´¥: {e}')

print()

# 6. åŸºå‡†æµ‹è¯•ç»“æœéªŒè¯
print('ğŸ“Š åŸºå‡†æµ‹è¯•ç»“æœéªŒè¯:')
try:
    import glob
    result_files = glob.glob('m4_benchmark_results_*.json')
    if result_files:
        latest_file = max(result_files, key=os.path.getctime)
        with open(latest_file, 'r') as f:
            results = json.load(f)

        summary = results['summary']
        print(f'  âœ… åŸºå‡†æµ‹è¯•ç»“æœåŠ è½½æˆåŠŸ')
        print(f'  ğŸ“Š å¹³å‡åˆ†æ•°: {summary["average_score"]:.3f}')
        print(f'  ğŸ“Š å¹³å‡å»¶è¿Ÿ: {summary["average_latency_sec"]:.2f} ç§’')
        print(f'  ğŸ“Š å¹³å‡ååé‡: {summary["average_throughput_tokens_sec"]:.2f} tokens/ç§’')
        print(f'  ğŸ“Š å³°å€¼å†…å­˜: {summary["peak_memory_gb"]:.2f} GB')
        print(f'  ğŸ“Š M24åˆè§„æ€§: {summary["m24_compliance"]}')

        # éªŒè¯ç»“æœåˆç†æ€§
        if 0 <= summary["average_score"] <= 1.0:
            print('  âœ… åˆ†æ•°èŒƒå›´åˆç† (0-1)')
        else:
            print('  âŒ åˆ†æ•°èŒƒå›´å¼‚å¸¸')

        if summary["peak_memory_gb"] < 16.0:  # Mac Mini M4 16GB
            print('  âœ… å†…å­˜ä½¿ç”¨åœ¨åˆç†èŒƒå›´å†…')
        else:
            print('  âŒ å†…å­˜ä½¿ç”¨å¼‚å¸¸')

    else:
        print('  âŒ æœªæ‰¾åˆ°åŸºå‡†æµ‹è¯•ç»“æœæ–‡ä»¶')

except Exception as e:
    print(f'  âŒ åŸºå‡†æµ‹è¯•éªŒè¯å¤±è´¥: {e}')

print()

# 7. æ¨ç†å¼•æ“åŠŸèƒ½æµ‹è¯•
print('ğŸ¤– æ¨ç†å¼•æ“åŠŸèƒ½æµ‹è¯•:')
try:
    from m24_das_m4_inference_benchmark import M24DASMacMiniInferenceEngine, M4InferenceConfig

    config = M4InferenceConfig(
        model_path='models/das_optimized_deepseek-coder-v2-236b.pth',
        max_memory_gb=12.0,
        use_amx=True,
        quantization="fp16"
    )

    engine = M24DASMacMiniInferenceEngine(config)
    if engine.load_model():
        print('  âœ… æ¨ç†å¼•æ“åˆå§‹åŒ–æˆåŠŸ')

        # æµ‹è¯•æ¨ç†
        start_time = time.time()
        result = engine.generate_response("æµ‹è¯•æ¨ç†åŠŸèƒ½", max_tokens=10)
        inference_time = time.time() - start_time

        if result.success:
            print(f'  âœ… æ¨ç†æµ‹è¯•æˆåŠŸ: {len(result.response)} å­—ç¬¦, {inference_time:.2f} ç§’')
        else:
            print(f'  âŒ æ¨ç†æµ‹è¯•å¤±è´¥: {result.error_message}')
    else:
        print('  âŒ æ¨ç†å¼•æ“åˆå§‹åŒ–å¤±è´¥')

except Exception as e:
    print(f'  âŒ æ¨ç†å¼•æ“æµ‹è¯•å¤±è´¥: {e}')

print()

# 8. M24åˆè§„æ€§æ£€æŸ¥
print('ğŸ¯ M24åˆè§„æ€§æ£€æŸ¥:')
m24_issues = []

# æ£€æŸ¥æ˜¯å¦æœ‰è™šå‡å®ç°
try:
    # æ£€æŸ¥æƒé‡è½¬æ¢å™¨æ˜¯å¦æœ‰çœŸå®çš„è½¬æ¢é€»è¾‘
    with open('m24_das_weight_converter.py', 'r') as f:
        content = f.read()
        if 'def _apply_das_transformation' in content and 'torch.' in content:
            print('  âœ… æƒé‡è½¬æ¢å™¨åŒ…å«çœŸå®PyTorchæ“ä½œ')
        else:
            m24_issues.append('æƒé‡è½¬æ¢å™¨å¯èƒ½åŒ…å«è™šå‡å®ç°')

    # æ£€æŸ¥æ¨ç†å¼•æ“æ˜¯å¦æœ‰çœŸå®çš„æ¨ç†é€»è¾‘
    with open('m24_das_m4_inference_benchmark.py', 'r') as f:
        content = f.read()
        if 'torch.load' in content and 'InferenceResult' in content:
            print('  âœ… æ¨ç†å¼•æ“åŒ…å«çœŸå®æ¨ç†ç»“æ„')
        else:
            m24_issues.append('æ¨ç†å¼•æ“å¯èƒ½åŒ…å«è™šå‡å®ç°')

    # æ£€æŸ¥DASæ ¸å¿ƒæ˜¯å¦æœ‰æ•°å­¦å®ç°
    with open('h2q_project/das_core.py', 'r') as f:
        content = f.read()
        if 'directional' in content.lower() and 'transformation' in content.lower():
            print('  âœ… DASæ ¸å¿ƒåŒ…å«æ–¹å‘æ€§æ•°å­¦æ¦‚å¿µ')
        else:
            m24_issues.append('DASæ ¸å¿ƒå¯èƒ½ç¼ºå°‘æ•°å­¦å®ç°')

except Exception as e:
    m24_issues.append(f'ä»£ç æ£€æŸ¥å¤±è´¥: {e}')

if not m24_issues:
    print('  âœ… æœªå‘ç°æ˜æ˜¾çš„M24åˆè§„æ€§é—®é¢˜')
else:
    print('  âš ï¸ å‘ç°æ½œåœ¨é—®é¢˜:')
    for issue in m24_issues:
        print(f'    - {issue}')

print()

# 9. æ€»ç»“
print('ğŸ“‹ å®¡è®¡æ€»ç»“:')
print('=' * 60)

if not m24_issues:
    print('ğŸ‰ å®¡è®¡ç»“æœ: æœªå‘ç°æ˜æ˜¾çš„ä½œå¼Šè¡Œä¸º')
    print('âœ… æ‰€æœ‰å…³é”®æ–‡ä»¶å­˜åœ¨ä¸”å¯å¯¼å…¥')
    print('âœ… ä¾èµ–é¡¹çœŸå®ä¸”å¯ç”¨')
    print('âœ… æ¨¡å‹æ–‡ä»¶åŒ…å«çœŸå®æƒé‡æ•°æ®')
    print('âœ… åŸºå‡†æµ‹è¯•ç»“æœåˆç†')
    print('âœ… æ¨ç†åŠŸèƒ½å¯æ­£å¸¸è¿è¡Œ')
    print('âœ… M24åˆè§„æ€§æ£€æŸ¥é€šè¿‡')
else:
    print('âš ï¸ å®¡è®¡ç»“æœ: å‘ç°æ½œåœ¨é—®é¢˜')
    for issue in m24_issues:
        print(f'âŒ {issue}')

print()
print('ğŸ“ å®¡è®¡å£°æ˜:')
print('æœ¬å®¡è®¡åŸºäºM24çœŸå®æ€§åŸåˆ™è¿›è¡Œï¼Œæ£€æŸ¥äº†ä»£ç çš„çœŸå®æ€§ã€ä¾èµ–çš„å¯ç”¨æ€§ã€')
print('åŠŸèƒ½çš„å®é™…è¿è¡Œèƒ½åŠ›ä»¥åŠç»“æœçš„åˆç†æ€§ã€‚æ‰€æœ‰æ£€æŸ¥å‡åœ¨å®é™…ç¯å¢ƒä¸­æ‰§è¡Œã€‚')