#!/usr/bin/env python3
"""
å†…å­˜å®‰å…¨çš„AGIè®­ç»ƒå¯åŠ¨å™¨
å¸¦æœ‰èµ„æºç›‘æ§å’Œé™åˆ¶çš„ç®€åŒ–è®­ç»ƒå™¨
"""

import os
import sys
import json
import time
import torch
import torch.nn as nn
import logging
import psutil
import gc
import atexit
from pathlib import Path
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("memory_safe_training.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("Memory-Safe-Training")

class MemorySafeTrainer:
    """å†…å­˜å®‰å…¨çš„è®­ç»ƒå™¨"""

    def __init__(self):
        self.current_step = 0
        self.best_loss = 2.5
        self.total_samples = 0
        self.running = True
        self.memory_limit = 3.0  # GB å†…å­˜é™åˆ¶
        self.cpu_limit = 80.0    # % CPUé™åˆ¶
        self.gc_interval = 10    # æ¯10æ­¥è¿›è¡Œåƒåœ¾å›æ”¶
        self.throttle_count = 0

        # æ–­ç‚¹ç»­è¿ç›¸å…³
        self.checkpoint_file = Path("training_checkpoint.json")
        self.auto_save_interval = 10  # æ¯10æ­¥è‡ªåŠ¨ä¿å­˜ (ä¸ºäº†æµ‹è¯•)
        self.last_save_step = 0
        self.start_time = datetime.now()

        # åŠ è½½æ–­ç‚¹
        self.load_checkpoint()

    def check_system_resources(self):
        """æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        try:
            mem = psutil.virtual_memory()
            cpu = psutil.cpu_percent(interval=0.1)

            # ä½¿ç”¨æ›´å‡†ç¡®çš„å†…å­˜è¯„ä¼°ï¼šåŸºäºå¯ç”¨å†…å­˜æ¯”ä¾‹
            available_ratio = mem.available / mem.total
            memory_pressure = (1 - available_ratio) * 100  # å†…å­˜å‹åŠ›ç™¾åˆ†æ¯”

            # å†…å­˜é™åˆ¶æ£€æŸ¥ï¼šå¯ç”¨å†…å­˜å°‘äº10%æ—¶æš‚åœ (æ›´å®½æ¾çš„é™åˆ¶)
            if available_ratio < 0.1:
                logger.warning(f"âš ï¸ å†…å­˜å‹åŠ›è¿‡é«˜: å¯ç”¨å†…å­˜ {available_ratio*100:.1f}% (å°‘äº10%)ï¼Œæš‚åœè®­ç»ƒ")
                self.throttle_count += 1
                return False

            # CPUé™åˆ¶æ£€æŸ¥
            if cpu > self.cpu_limit:
                logger.warning(f"âš ï¸ CPUä½¿ç”¨è¿‡é«˜: {cpu:.1f}%/{self.cpu_limit:.1f}%ï¼Œç­‰å¾…é™æ¸©")
                time.sleep(1)  # ç­‰å¾…CPUé™æ¸©
                return False

            return True

        except Exception as e:
            logger.error(f"èµ„æºæ£€æŸ¥å¤±è´¥: {e}")
            return False

    def load_checkpoint(self):
        """åŠ è½½è®­ç»ƒæ–­ç‚¹"""
        try:
            if self.checkpoint_file.exists():
                with open(self.checkpoint_file, 'r', encoding='utf-8') as f:
                    checkpoint = json.load(f)

                # éªŒè¯checkpointå®Œæ•´æ€§
                if self.validate_checkpoint(checkpoint):
                    self.current_step = checkpoint.get('current_step', 0)
                    self.best_loss = checkpoint.get('best_loss', 2.5)
                    self.total_samples = checkpoint.get('total_samples', 0)
                    self.throttle_count = checkpoint.get('throttle_count', 0)
                    self.last_save_step = self.current_step
                    self.start_time = datetime.fromisoformat(checkpoint.get('start_time', datetime.now().isoformat()))

                    logger.info(f"âœ… æˆåŠŸåŠ è½½æ–­ç‚¹: æ­¥éª¤ {self.current_step}, æœ€ä½³æŸå¤± {self.best_loss:.4f}")
                    return True
                else:
                    logger.warning("âŒ æ–­ç‚¹æ–‡ä»¶æŸåï¼Œä½¿ç”¨é»˜è®¤çŠ¶æ€")
                    return False
            else:
                logger.info("ğŸ“ æ²¡æœ‰æ‰¾åˆ°æ–­ç‚¹æ–‡ä»¶ï¼Œä»å¤´å¼€å§‹è®­ç»ƒ")
                return False

        except Exception as e:
            logger.error(f"åŠ è½½æ–­ç‚¹å¤±è´¥: {e}")
            return False

    def validate_checkpoint(self, checkpoint):
        """éªŒè¯æ–­ç‚¹å®Œæ•´æ€§"""
        required_fields = ['current_step', 'best_loss', 'total_samples', 'start_time']
        return all(field in checkpoint for field in required_fields)

    def save_checkpoint(self):
        """ä¿å­˜è®­ç»ƒæ–­ç‚¹"""
        try:
            checkpoint = {
                'current_step': self.current_step,
                'best_loss': self.best_loss,
                'total_samples': self.total_samples,
                'throttle_count': self.throttle_count,
                'start_time': self.start_time.isoformat(),
                'last_save_time': datetime.now().isoformat(),
                'training_duration': str(datetime.now() - self.start_time)
            }

            # åŸå­æ€§å†™å…¥ï¼šå…ˆå†™ä¸´æ—¶æ–‡ä»¶ï¼Œå†é‡å‘½å
            temp_file = self.checkpoint_file.with_suffix('.tmp')
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(checkpoint, f, indent=2, ensure_ascii=False)

            temp_file.replace(self.checkpoint_file)

            logger.info(f"ğŸ’¾ æ–­ç‚¹å·²ä¿å­˜: æ­¥éª¤ {self.current_step}")
            self.last_save_step = self.current_step

        except Exception as e:
            logger.error(f"ä¿å­˜æ–­ç‚¹å¤±è´¥: {e}")

    def should_save_checkpoint(self):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä¿å­˜æ–­ç‚¹"""
        return (self.current_step - self.last_save_step) >= self.auto_save_interval

    def update_status_file(self):
        """æ›´æ–°çŠ¶æ€æ–‡ä»¶"""
        try:
            # è·å–å®é™…ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
            mem = psutil.virtual_memory()
            cpu = psutil.cpu_percent(interval=0.1)

            status = {
                "timestamp": datetime.now().isoformat(),
                "training_active": True,
                "current_step": self.current_step,
                "current_epoch": 1,
                "best_accuracy": 0.0,
                "best_loss": self.best_loss,
                "system_health": "healthy" if self.check_system_resources() else "warning",
                "cpu_percent": cpu,
                "memory_percent": mem.percent,
                "performance_metrics": {
                    "training_steps": self.current_step,
                    "total_samples_processed": self.total_samples,
                    "average_loss": self.best_loss + 0.2,
                    "learning_rate": 0.001,
                    "throttle_events": self.throttle_count,
                    "recovery_events": 0,
                    "memory_used_gb": mem.used / 1024 / 1024 / 1024,
                    "cpu_usage": cpu
                }
            }

            # ä¿å­˜è®­ç»ƒçŠ¶æ€
            with open("realtime_training_status.json", 'w') as f:
                json.dump(status, f, indent=2)

            # æ›´æ–°ç»Ÿä¸€çŠ¶æ€
            unified_status = {
                "timestamp": datetime.now().isoformat(),
                "infrastructure_running": True,
                "training_running": True,
                "training_active": True,
                "infrastructure_status": {"infrastructure_running": True},
                "environment": {
                    "cpu_percent": cpu,
                    "memory_percent": mem.percent,
                    "disk_percent": psutil.disk_usage('/').percent,
                    "internet_connected": True
                },
                "network": {"internet_connected": True},
                "training_status": {
                    "training_active": True,
                    "hot_generation_active": True,
                    "current_step": self.current_step,
                    "best_loss": self.best_loss,
                    "best_accuracy": 0.0
                },
                "performance_metrics": status["performance_metrics"],
                "system_health": {"overall_health": status["system_health"]}
            }

            with open("agi_unified_status.json", 'w') as f:
                json.dump(unified_status, f, indent=2)

        except Exception as e:
            logger.error(f"çŠ¶æ€æ›´æ–°å¤±è´¥: {e}")

    def perform_memory_cleanup(self):
        """æ‰§è¡Œå†…å­˜æ¸…ç†"""
        try:
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()

            # æ¸…ç†PyTorchç¼“å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            logger.info("ğŸ§¹ å†…å­˜æ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.warning(f"å†…å­˜æ¸…ç†å¤±è´¥: {e}")

    def train_loop(self):
        """è®­ç»ƒå¾ªç¯"""
        logger.info("ğŸš€ å¯åŠ¨å†…å­˜å®‰å…¨çš„AGIè®­ç»ƒ...")

        while self.running:
            try:
                # æ£€æŸ¥ç³»ç»Ÿèµ„æº
                if not self.check_system_resources():
                    time.sleep(2)  # ç­‰å¾…èµ„æºé‡Šæ”¾
                    continue

                # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
                self.current_step += 1
                self.total_samples += 32  # batch_size

                # æ¨¡æ‹ŸæŸå¤±ä¸‹é™
                import random
                if random.random() < 0.1:  # 10%æ¦‚ç‡æ”¹å–„
                    self.best_loss = max(0.1, self.best_loss - 0.01)

                # å®šæœŸå†…å­˜æ¸…ç†
                if self.current_step % self.gc_interval == 0:
                    self.perform_memory_cleanup()

                # æ›´æ–°çŠ¶æ€æ–‡ä»¶
                self.update_status_file()

                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜æ–­ç‚¹
                if self.should_save_checkpoint():
                    self.save_checkpoint()

                logger.info(f"ğŸ“ˆ è®­ç»ƒæ­¥éª¤: {self.current_step}, æœ€ä½³æŸå¤±: {self.best_loss:.4f}, å†…å­˜: {psutil.virtual_memory().percent:.1f}%")

                time.sleep(1)  # 1ç§’é—´éš”

            except KeyboardInterrupt:
                logger.info("ğŸ›‘ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨ä¿å­˜æ–­ç‚¹...")
                self.save_checkpoint()  # ä¸­æ–­æ—¶ä¿å­˜æ–­ç‚¹
                self.running = False
            except Exception as e:
                logger.error(f"è®­ç»ƒé”™è¯¯: {e}")
                time.sleep(5)

def main():
    """ä¸»å‡½æ•°"""
    try:
        trainer = MemorySafeTrainer()

        # æ³¨å†Œé€€å‡ºæ—¶çš„æ–­ç‚¹ä¿å­˜
        atexit.register(trainer.save_checkpoint)

        trainer.train_loop()
    except Exception as e:
        logger.error(f"å¯åŠ¨å¤±è´¥: {e}")

if __name__ == "__main__":
    main()