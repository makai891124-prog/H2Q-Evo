#!/usr/bin/env python3
"""
çœŸå®çš„H2Q-Evo AGIè®­ç»ƒå¯åŠ¨å™¨
åŸºäºSU(2)å‡ ä½•æµå½¢å’Œè°±ç§»è·Ÿè¸ªçš„çœŸå®è®­ç»ƒç³»ç»Ÿ
"""

import os
import sys
import json
import time
import torch
import torch.nn as nn
import torch.optim as optim
import logging
import psutil
import gc
import atexit
import math
import numpy as np
from pathlib import Path
from datetime import datetime

# å¯¼å…¥é«˜çº§è°±ç¨³å®šæ€§æ§åˆ¶å™¨
try:
    from advanced_spectral_controller import AdvancedSpectralController, RiemannSpectralLoss
    ADVANCED_SPECTRAL_AVAILABLE = True
except ImportError:
    ADVANCED_SPECTRAL_AVAILABLE = False
    print("è­¦å‘Š: é«˜çº§è°±ç¨³å®šæ€§æ§åˆ¶å™¨ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿè°±ç§»è·Ÿè¸ªå™¨")

# ç§»é™¤sklearnå¯¼å…¥ï¼Œå®Œå…¨ä½¿ç”¨numpyå®ç°
# try:
#     from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score
#     SKLEARN_AVAILABLE = True
# except ImportError:
#     SKLEARN_AVAILABLE = False
#     print("è­¦å‘Š: sklearnä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç®€åŒ–æŒ‡æ ‡è®¡ç®—")

SKLEARN_AVAILABLE = False  # å¼ºåˆ¶ä½¿ç”¨ç®€åŒ–è®¡ç®—

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("memory_safe_training.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("H2Q-Evo-Real-Training")

# --- çœŸå®H2Qæ ¸å¿ƒç»„ä»¶ ---

class DiscreteDecisionEngine(nn.Module):
    """
    åŸºäºSU(2)æµå½¢çš„ç¦»æ•£å†³ç­–å¼•æ“
    """
    def __init__(self, latent_config):
        super().__init__()
        self.latent_dim = latent_config.get('latent_dim', 256)
        # é˜´é˜³äºŒå…ƒç§å­åˆå§‹åŒ–
        self.seed = nn.Parameter(torch.tensor([1.0, -1.0]), requires_grad=False)
        self.projection = nn.Linear(2, self.latent_dim)
        self.decision_gate = nn.Softmax(dim=-1)

    def forward(self, x):
        # å°†2åŸå­ç§å­æŠ•å½±åˆ°256ç»´æµå½¢
        base_manifold = self.projection(self.seed.repeat(x.size(0), 1))
        return self.decision_gate(x + base_manifold)

class SpectralShiftTracker:
    """
    è°±ç§»è·Ÿè¸ªå™¨ï¼šÎ· = (1/Ï€) arg{det(S)}
    """
    def __init__(self):
        self.history = []

    def compute_eta(self, state_matrix):
        # Sä½œä¸ºæµå½¢çš„è½¬ç§»çŸ©é˜µ
        det_s = torch.linalg.det(state_matrix + 1e-6)
        eta = (1.0 / math.pi) * torch.angle(det_s)
        return eta

class RealH2QTrainer:
    """
    çœŸå®çš„H2Q-Evoè®­ç»ƒå™¨
    åŸºäºå‡ ä½•ç¥ç»ç½‘ç»œæ¨ç†å’Œè°±ç§»è·Ÿè¸ª
    """
    def __init__(self, device="cpu"):  # æ”¹ä¸ºCPUä»¥é¿å…MPSå…¼å®¹æ€§é—®é¢˜
        # è®¾ç½®MPS fallbackç¯å¢ƒå˜é‡
        os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'

        self.device = torch.device(device if torch.backends.mps.is_available() else "cpu")
        self.latent_dim = 256

        # åˆå§‹åŒ–SU(2)å‡ ä½•å¼•æ“
        self.engine = DiscreteDecisionEngine({'latent_dim': self.latent_dim}).to(self.device)

        # ä½¿ç”¨é«˜çº§è°±ç¨³å®šæ€§æ§åˆ¶å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if ADVANCED_SPECTRAL_AVAILABLE:
            self.tracker = AdvancedSpectralController(dim=self.latent_dim)
            self.spectral_loss = RiemannSpectralLoss()
            self.spectral_optimizer = optim.Adam(self.tracker.parameters(), lr=1e-4)
            print("ğŸ¯ ä½¿ç”¨é«˜çº§é»æ›¼è°±ç¨³å®šæ€§æ§åˆ¶å™¨")
        else:
            self.tracker = SpectralShiftTracker()
            self.spectral_loss = None
            self.spectral_optimizer = None
            print("ğŸ“Š ä½¿ç”¨ä¼ ç»Ÿè°±ç§»è·Ÿè¸ªå™¨")

        self.optimizer = optim.Adam(self.engine.parameters(), lr=1e-4)

        # è®­ç»ƒçŠ¶æ€
        self.best_loss = float('inf')
        self.best_accuracy = 0.0
        self.current_step = 0

    def get_domain_data(self, domain, batch_size=32):
        """ç”Ÿæˆå¤šæ¨¡æ€åŸŸæ•°æ®"""
        if domain == "Math":
            # æ•°å­¦é€»è¾‘åŸå­
            return torch.randn(batch_size, self.latent_dim).to(self.device)
        elif domain == "Physics":
            # ç‰©ç†æµ‹åœ°çº¿æµ
            return torch.sin(torch.linspace(0, 2*math.pi, self.latent_dim)).repeat(batch_size, 1).to(self.device)
        elif domain == "Genomics":
            # åŸºå› ç»„æ‹“æ‰‘
            return torch.randint(0, 2, (batch_size, self.latent_dim)).float().to(self.device)
        else:
            # é»˜è®¤éšæœºæ•°æ®
            return torch.randn(batch_size, self.latent_dim).to(self.device)

    def calculate_fractal_collapse(self, manifold_state):
        """è®¡ç®—åˆ†å½¢åç¼©æƒ©ç½šï¼ˆæœ‰æ•ˆç§©æµ‹é‡ï¼‰"""
        s = torch.linalg.svdvals(manifold_state)
        entropy = -torch.sum(s * torch.log(s + 1e-10))
        return 1.0 / (entropy + 1e-6)

    def compute_geometric_accuracy(self, output, target=None):
        """åŸºäºå‡ ä½•æ¨ç†è®¡ç®—å‡†ç¡®ç‡"""
        # å¦‚æœæ²¡æœ‰çœŸå®æ ‡ç­¾ï¼Œä½¿ç”¨å‡ ä½•ä¸€è‡´æ€§ä½œä¸ºä»£ç†
        if target is None:
            # åŸºäºè°±ç§»çš„å‡ ä½•å‡†ç¡®ç‡
            s_matrix = torch.cov(output.T)
            eta = self.tracker.compute_eta(s_matrix)
            # Î·çš„å®éƒ¨ä½œä¸ºå‡ ä½•ä¸€è‡´æ€§åº¦é‡
            geometric_consistency = torch.abs(eta.real)
            return geometric_consistency.item()
        else:
            # æ ‡å‡†åˆ†ç±»å‡†ç¡®ç‡
            predictions = torch.argmax(output, dim=1)
            accuracy = (predictions == target).float().mean().item()
            return accuracy

    def compute_classification_metrics(self, output, target):
        """è®¡ç®—æ ‡å‡†åˆ†ç±»æŒ‡æ ‡"""
        if not SKLEARN_AVAILABLE:
            # ç®€åŒ–çš„æŒ‡æ ‡è®¡ç®—
            predictions = torch.argmax(output, dim=1).cpu().numpy()
            target_np = target.cpu().numpy()

            # ç®€åŒ–çš„å‡†ç¡®ç‡è®¡ç®—
            accuracy = np.mean(predictions == target_np)

            # ç®€åŒ–çš„F1ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ï¼ˆä½¿ç”¨å®å¹³å‡ï¼‰
            precision = accuracy  # ç®€åŒ–ç‰ˆæœ¬
            recall = accuracy     # ç®€åŒ–ç‰ˆæœ¬
            f1 = accuracy         # ç®€åŒ–ç‰ˆæœ¬

            return {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1': f1
            }

        predictions = torch.argmax(output, dim=1).cpu().numpy()
        target_np = target.cpu().numpy()

        accuracy = accuracy_score(target_np, predictions)
        precision = precision_score(target_np, predictions, average='weighted', zero_division=0)
        recall = recall_score(target_np, predictions, average='weighted', zero_division=0)
        f1 = f1_score(target_np, predictions, average='weighted', zero_division=0)

        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1
        }

    def train_step(self, domains=None):
        """æ‰§è¡ŒçœŸå®è®­ç»ƒæ­¥éª¤"""
        if domains is None:
            domains = ["Math", "Physics", "Genomics"]

        total_loss = 0
        total_accuracy = 0
        batch_size = 32

        for domain in domains:
            self.optimizer.zero_grad()
            if self.spectral_optimizer is not None:
                self.spectral_optimizer.zero_grad()

            # 1. ç”ŸæˆåŸŸç‰¹å®šæ•°æ®
            data = self.get_domain_data(domain, batch_size)

            # 2. åˆ›å»ºåˆæˆæ ‡ç­¾ï¼ˆç”¨äºåˆ†ç±»æŒ‡æ ‡è®¡ç®—ï¼‰
            target = torch.randint(0, self.latent_dim, (batch_size,)).to(self.device)

            # 3. SU(2)æµå½¢å‰å‘ä¼ æ’­
            output = self.engine(data)

            # 4. è®¡ç®—è°±ç¨³å®šæ€§å‚æ•°
            s_matrix = torch.cov(output.T)

            if ADVANCED_SPECTRAL_AVAILABLE:
                # ä½¿ç”¨é«˜çº§è°±ç¨³å®šæ€§æ§åˆ¶å™¨
                controlled_output, control_info = self.tracker(output)
                stability_loss = self.spectral_loss(control_info['stability_metrics'])
                eta = control_info['stability_score'].mean()
            else:
                # ä½¿ç”¨ä¼ ç»Ÿè°±ç§»è·Ÿè¸ª
                eta = self.tracker.compute_eta(s_matrix)
                controlled_output = output
                stability_loss = torch.tensor(0.0)

            # 5. è®¡ç®—åˆ†å½¢åç¼©æƒ©ç½š
            collapse_penalty = self.calculate_fractal_collapse(controlled_output)

            # 6. è®¡ç®—æ€»æŸå¤±ï¼šæœ€å°åŒ–åç¼© + æœ€å¤§åŒ–è°±ç¨³å®šæ€§
            if ADVANCED_SPECTRAL_AVAILABLE:
                loss = collapse_penalty + stability_loss  # è°±ç¨³å®šæ€§æŸå¤±å·²ç»æ˜¯è´Ÿçš„
            else:
                loss = collapse_penalty - eta.real  # ä¼ ç»Ÿæ–¹æ³•ï¼šæœ€å¤§åŒ–è°±ç§»

            # 7. åå‘ä¼ æ’­
            loss.backward()
            self.optimizer.step()
            if self.spectral_optimizer is not None:
                self.spectral_optimizer.step()

            # 8. è®¡ç®—å‡†ç¡®ç‡æŒ‡æ ‡
            accuracy = self.compute_geometric_accuracy(controlled_output, target)
            classification_metrics = self.compute_classification_metrics(controlled_output, target)

            total_loss += loss.item()
            total_accuracy += accuracy

        avg_loss = total_loss / len(domains)
        avg_accuracy = total_accuracy / len(domains)

        # æ›´æ–°æœ€ä½³æŒ‡æ ‡
        if avg_loss < self.best_loss:
            self.best_loss = avg_loss

        if avg_accuracy > self.best_accuracy:
            self.best_accuracy = avg_accuracy

        self.current_step += 1

        return {
            'loss': avg_loss,
            'accuracy': avg_accuracy,
            'best_loss': self.best_loss,
            'best_accuracy': self.best_accuracy,
            'eta_real': eta.item() if hasattr(eta, 'item') else eta,
            'collapse_penalty': collapse_penalty.item(),
            'classification_metrics': classification_metrics,
            'advanced_spectral': ADVANCED_SPECTRAL_AVAILABLE,
            'stability_score': eta.item() if hasattr(eta, 'item') else eta
        }

class MemorySafeTrainer:
    """çœŸå®çš„H2Q-Evoè®­ç»ƒå™¨"""

    def __init__(self):
        self.current_step = 0
        self.best_loss = float('inf')
        self.best_accuracy = 0.0
        self.total_samples = 0
        self.running = True
        self.memory_limit = 3.0  # GB å†…å­˜é™åˆ¶
        self.cpu_limit = 80.0    # % CPUé™åˆ¶
        self.gc_interval = 10    # æ¯10æ­¥è¿›è¡Œåƒåœ¾å›æ”¶
        self.throttle_count = 0

        # æ–­ç‚¹ç»­è¿ç›¸å…³
        self.checkpoint_file = Path("training_checkpoint.json")
        self.auto_save_interval = 10  # æ¯10æ­¥è‡ªåŠ¨ä¿å­˜
        self.last_save_step = 0
        self.start_time = datetime.now()

        # åˆå§‹åŒ–çœŸå®H2Qè®­ç»ƒå™¨
        self.h2q_trainer = RealH2QTrainer()

        # åŠ è½½æ–­ç‚¹
        self.load_checkpoint()

    def check_system_resources(self):
        """æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        try:
            mem = psutil.virtual_memory()
            cpu = psutil.cpu_percent(interval=0.1)

            # ä½¿ç”¨æ›´å‡†ç¡®çš„å†…å­˜è¯„ä¼°ï¼šåŸºäºå¯ç”¨å†…å­˜æ¯”ä¾‹
            available_ratio = mem.available / mem.total
            memory_pressure = (1 - available_ratio) * 100  # å†…å­˜å‹åŠ›ç™¾åˆ†æ¯”

            # å†…å­˜é™åˆ¶æ£€æŸ¥ï¼šå¯ç”¨å†…å­˜å°‘äº10%æ—¶æš‚åœ (æ›´å®½æ¾çš„é™åˆ¶)
            if available_ratio < 0.1:
                logger.warning(f"âš ï¸ å†…å­˜å‹åŠ›è¿‡é«˜: å¯ç”¨å†…å­˜ {available_ratio*100:.1f}% (å°‘äº10%)ï¼Œæš‚åœè®­ç»ƒ")
                self.throttle_count += 1
                return False

            # CPUé™åˆ¶æ£€æŸ¥
            if cpu > self.cpu_limit:
                logger.warning(f"âš ï¸ CPUä½¿ç”¨è¿‡é«˜: {cpu:.1f}%/{self.cpu_limit:.1f}%ï¼Œç­‰å¾…é™æ¸©")
                time.sleep(1)  # ç­‰å¾…CPUé™æ¸©
                return False

            return True

        except Exception as e:
            logger.error(f"èµ„æºæ£€æŸ¥å¤±è´¥: {e}")
            return False

    def load_checkpoint(self):
        """åŠ è½½è®­ç»ƒæ–­ç‚¹"""
        try:
            if self.checkpoint_file.exists():
                with open(self.checkpoint_file, 'r', encoding='utf-8') as f:
                    checkpoint = json.load(f)

                # éªŒè¯checkpointå®Œæ•´æ€§
                if self.validate_checkpoint(checkpoint):
                    self.current_step = checkpoint.get('current_step', 0)
                    self.best_loss = checkpoint.get('best_loss', float('inf'))
                    self.best_accuracy = checkpoint.get('best_accuracy', 0.0)
                    self.total_samples = checkpoint.get('total_samples', 0)
                    self.throttle_count = checkpoint.get('throttle_count', 0)
                    self.last_save_step = self.current_step
                    self.start_time = datetime.fromisoformat(checkpoint.get('start_time', datetime.now().isoformat()))

                    # æ¢å¤H2Qè®­ç»ƒå™¨çŠ¶æ€
                    self.h2q_trainer.current_step = self.current_step
                    self.h2q_trainer.best_loss = self.best_loss
                    self.h2q_trainer.best_accuracy = self.best_accuracy

                    # æ¢å¤æœ€æ–°æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                    if 'latest_metrics' in checkpoint:
                        self.latest_training_result = checkpoint['latest_metrics']

                    logger.info(f"âœ… æˆåŠŸåŠ è½½æ–­ç‚¹: æ­¥éª¤ {self.current_step}, æœ€ä½³æŸå¤± {self.best_loss:.4f}, æœ€ä½³å‡†ç¡®ç‡ {self.best_accuracy:.4f}")
                    return True
                else:
                    logger.warning("âŒ æ–­ç‚¹æ–‡ä»¶æŸåï¼Œä½¿ç”¨é»˜è®¤çŠ¶æ€")
                    return False
            else:
                logger.info("ğŸ“ æ²¡æœ‰æ‰¾åˆ°æ–­ç‚¹æ–‡ä»¶ï¼Œä»å¤´å¼€å§‹è®­ç»ƒ")
                return False

        except Exception as e:
            logger.error(f"åŠ è½½æ–­ç‚¹å¤±è´¥: {e}")
            return False

    def validate_checkpoint(self, checkpoint):
        """éªŒè¯æ–­ç‚¹å®Œæ•´æ€§"""
        required_fields = ['current_step', 'best_loss', 'total_samples', 'start_time']
        return all(field in checkpoint for field in required_fields)

    def save_checkpoint(self):
        """ä¿å­˜è®­ç»ƒæ–­ç‚¹"""
        try:
            checkpoint = {
                'current_step': self.current_step,
                'best_loss': self.best_loss,
                'best_accuracy': self.best_accuracy,
                'total_samples': self.total_samples,
                'throttle_count': self.throttle_count,
                'start_time': self.start_time.isoformat(),
                'last_save_time': datetime.now().isoformat(),
                'training_duration': str(datetime.now() - self.start_time),
                # ä¿å­˜H2Qè®­ç»ƒå™¨çŠ¶æ€
                'h2q_trainer_state': {
                    'current_step': self.h2q_trainer.current_step,
                    'best_loss': self.h2q_trainer.best_loss,
                    'best_accuracy': self.h2q_trainer.best_accuracy
                },
                # ä¿å­˜æœ€æ–°è®­ç»ƒæŒ‡æ ‡
                'latest_metrics': getattr(self, 'latest_training_result', {})
            }

            # åŸå­æ€§å†™å…¥ï¼šå…ˆå†™ä¸´æ—¶æ–‡ä»¶ï¼Œå†é‡å‘½å
            temp_file = self.checkpoint_file.with_suffix('.tmp')
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(checkpoint, f, indent=2, ensure_ascii=False)

            temp_file.replace(self.checkpoint_file)

            logger.info(f"ğŸ’¾ æ–­ç‚¹å·²ä¿å­˜: æ­¥éª¤ {self.current_step}")
            self.last_save_step = self.current_step

        except Exception as e:
            logger.error(f"ä¿å­˜æ–­ç‚¹å¤±è´¥: {e}")

    def should_save_checkpoint(self):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä¿å­˜æ–­ç‚¹"""
        return (self.current_step - self.last_save_step) >= self.auto_save_interval

    def update_status_file(self):
        """æ›´æ–°çŠ¶æ€æ–‡ä»¶ - åŒ…å«çœŸå®H2Qå‡ ä½•æŒ‡æ ‡"""
        try:
            # è·å–å®é™…ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
            mem = psutil.virtual_memory()
            cpu = psutil.cpu_percent(interval=0.1)

            # è·å–æœ€æ–°çš„è®­ç»ƒç»“æœï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            latest_metrics = getattr(self, 'latest_training_result', {})

            status = {
                "timestamp": datetime.now().isoformat(),
                "training_active": True,
                "current_step": self.current_step,
                "current_epoch": 1,
                "best_accuracy": self.best_accuracy,
                "best_loss": self.best_loss,
                "system_health": "healthy" if self.check_system_resources() else "warning",
                "cpu_percent": cpu,
                "memory_percent": mem.percent,
                "geometric_metrics": {
                    "spectral_shift_eta_real": latest_metrics.get('stability_score', 0.0) if latest_metrics.get('advanced_spectral', False) else latest_metrics.get('eta_real', 0.0),
                    "fractal_collapse_penalty": latest_metrics.get('collapse_penalty', 0.0),
                    "geometric_accuracy": latest_metrics.get('accuracy', self.best_accuracy),
                    "classification_f1": latest_metrics.get('classification_metrics', {}).get('f1', 0.0),
                    "classification_precision": latest_metrics.get('classification_metrics', {}).get('precision', 0.0),
                    "classification_recall": latest_metrics.get('classification_metrics', {}).get('recall', 0.0)
                },
                "performance_metrics": {
                    "training_steps": self.current_step,
                    "total_samples_processed": self.total_samples,
                    "average_loss": self.best_loss,
                    "learning_rate": 0.0001,  # H2Qè®­ç»ƒå™¨çš„å­¦ä¹ ç‡
                    "throttle_events": self.throttle_count,
                    "recovery_events": 0,
                    "memory_used_gb": mem.used / 1024 / 1024 / 1024,
                    "cpu_usage": cpu,
                    "geometric_convergence_rate": latest_metrics.get('eta_real', 0.0),
                    "manifold_stability": 1.0 / (latest_metrics.get('collapse_penalty', 1.0) + 1e-6)
                }
            }

            # ä¿å­˜è®­ç»ƒçŠ¶æ€
            with open("realtime_training_status.json", 'w') as f:
                json.dump(status, f, indent=2)

            # æ›´æ–°ç»Ÿä¸€çŠ¶æ€
            unified_status = {
                "timestamp": datetime.now().isoformat(),
                "infrastructure_running": True,
                "training_running": True,
                "training_active": True,
                "infrastructure_status": {"infrastructure_running": True},
                "environment": {
                    "cpu_percent": cpu,
                    "memory_percent": mem.percent,
                    "disk_percent": psutil.disk_usage('/').percent,
                    "internet_connected": True
                },
                "network": {"internet_connected": True},
                "training_status": {
                    "training_active": True,
                    "hot_generation_active": True,
                    "current_step": self.current_step,
                    "best_loss": self.best_loss,
                    "best_accuracy": self.best_accuracy,
                    "geometric_metrics": status["geometric_metrics"]
                },
                "performance_metrics": status["performance_metrics"],
                "system_health": {"overall_health": status["system_health"]}
            }

            # æ›´æ–°ç»Ÿä¸€çŠ¶æ€ (åŸå­æ€§å†™å…¥)
            temp_unified_file = Path("agi_unified_status.json.tmp")
            with open(temp_unified_file, 'w') as f:
                json.dump(unified_status, f, indent=2)
            temp_unified_file.replace("agi_unified_status.json")

        except Exception as e:
            logger.error(f"çŠ¶æ€æ›´æ–°å¤±è´¥: {e}")

    def perform_memory_cleanup(self):
        """æ‰§è¡Œå†…å­˜æ¸…ç†"""
        try:
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()

            # æ¸…ç†PyTorchç¼“å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            logger.info("ğŸ§¹ å†…å­˜æ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.warning(f"å†…å­˜æ¸…ç†å¤±è´¥: {e}")

    def train_loop(self):
        """çœŸå®H2Q-Evoè®­ç»ƒå¾ªç¯"""
        logger.info("ğŸš€ å¯åŠ¨çœŸå®H2Q-Evo AGIè®­ç»ƒ...")

        while self.running:
            try:
                # æ£€æŸ¥ç³»ç»Ÿèµ„æº
                if not self.check_system_resources():
                    time.sleep(2)  # ç­‰å¾…èµ„æºé‡Šæ”¾
                    continue

                # æ‰§è¡ŒçœŸå®H2Qè®­ç»ƒæ­¥éª¤
                self.current_step += 1
                self.total_samples += 32 * 3  # 3ä¸ªåŸŸï¼Œæ¯ä¸ªåŸŸ32ä¸ªæ ·æœ¬

                # çœŸå®å‡ ä½•è®­ç»ƒ
                training_result = self.h2q_trainer.train_step()

                # ä¿å­˜æœ€æ–°çš„è®­ç»ƒç»“æœç”¨äºçŠ¶æ€æ›´æ–°
                self.latest_training_result = training_result

                # æ›´æ–°çŠ¶æ€
                self.best_loss = training_result['best_loss']
                self.best_accuracy = training_result['best_accuracy']

                # å®šæœŸå†…å­˜æ¸…ç†
                if self.current_step % self.gc_interval == 0:
                    self.perform_memory_cleanup()

                # æ›´æ–°çŠ¶æ€æ–‡ä»¶
                self.update_status_file()

                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜æ–­ç‚¹
                if self.should_save_checkpoint():
                    self.save_checkpoint()

                # è®°å½•è¯¦ç»†è®­ç»ƒä¿¡æ¯
                logger.info(f"ğŸ“ˆ è®­ç»ƒæ­¥éª¤: {self.current_step}")
                logger.info(f"   æŸå¤±: {training_result['loss']:.4f} (æœ€ä½³: {self.best_loss:.4f})")
                logger.info(f"   å‡ ä½•å‡†ç¡®ç‡: {training_result['accuracy']:.4f} (æœ€ä½³: {self.best_accuracy:.4f})")
                logger.info(f"   è°±ç§»Î·å®éƒ¨: {training_result['eta_real']:.4f}")
                logger.info(f"   åˆ†å½¢åç¼©æƒ©ç½š: {training_result['collapse_penalty']:.4f}")
                logger.info(f"   åˆ†ç±»æŒ‡æ ‡ - F1: {training_result['classification_metrics']['f1']:.4f}, "
                           f"ç²¾ç¡®ç‡: {training_result['classification_metrics']['precision']:.4f}, "
                           f"å¬å›ç‡: {training_result['classification_metrics']['recall']:.4f}")
                logger.info(f"   å†…å­˜ä½¿ç”¨: {psutil.virtual_memory().percent:.1f}%")

                time.sleep(1)  # 1ç§’é—´éš”

            except KeyboardInterrupt:
                logger.info("ğŸ›‘ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨ä¿å­˜æ–­ç‚¹...")
                self.save_checkpoint()  # ä¸­æ–­æ—¶ä¿å­˜æ–­ç‚¹
                self.running = False
            except Exception as e:
                logger.error(f"è®­ç»ƒé”™è¯¯: {e}")
                time.sleep(5)

def main():
    """ä¸»å‡½æ•°"""
    try:
        trainer = MemorySafeTrainer()

        # æ³¨å†Œé€€å‡ºæ—¶çš„æ–­ç‚¹ä¿å­˜
        atexit.register(trainer.save_checkpoint)

        trainer.train_loop()
    except Exception as e:
        logger.error(f"å¯åŠ¨å¤±è´¥: {e}")

if __name__ == "__main__":
    main()