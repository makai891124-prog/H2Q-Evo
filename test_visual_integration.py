#!/usr/bin/env python3
"""
æµ‹è¯•æ–°çš„è§†è§‰æ•°æ®é›†æˆå’Œå¤„ç†åŠŸèƒ½
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/Users/imymm/H2Q-Evo')

from extended_multimodal_agi_training import VisualDataLoader, AdvancedVisualProcessor

async def test_visual_data_integration():
    """æµ‹è¯•è§†è§‰æ•°æ®é›†æˆ"""
    print("ğŸ§ª æµ‹è¯•è§†è§‰æ•°æ®é›†æˆåŠŸèƒ½...")

    # æµ‹è¯•è§†è§‰æ•°æ®åŠ è½½å™¨
    print("\n1. æµ‹è¯•è§†è§‰æ•°æ®åŠ è½½å™¨...")
    visual_loader = VisualDataLoader(batch_size=2)

    print(f"   å¯ç”¨æ•°æ®é›†: {visual_loader.available_datasets}")

    # åŠ è½½å›¾åƒæ‰¹æ¬¡
    try:
        image_batch = visual_loader.load_image_batch()
        print(f"   å›¾åƒæ‰¹æ¬¡å½¢çŠ¶: {image_batch.shape}")
        print(f"   å›¾åƒæ•°æ®ç±»å‹: {image_batch.dtype}")
        print(f"   å›¾åƒå€¼èŒƒå›´: [{image_batch.min():.3f}, {image_batch.max():.3f}]")
    except Exception as e:
        print(f"   âŒ å›¾åƒåŠ è½½å¤±è´¥: {e}")

    # åŠ è½½è§†é¢‘æ‰¹æ¬¡
    try:
        video_batch = visual_loader.load_video_batch()
        print(f"   è§†é¢‘æ‰¹æ¬¡å½¢çŠ¶: {video_batch.shape}")
        print(f"   è§†é¢‘æ•°æ®ç±»å‹: {video_batch.dtype}")
        print(f"   è§†é¢‘å€¼èŒƒå›´: [{video_batch.min():.3f}, {video_batch.max():.3f}]")
    except Exception as e:
        print(f"   âŒ è§†é¢‘åŠ è½½å¤±è´¥: {e}")

    # è·å–æè¿°
    captions = visual_loader.get_visual_captions(2)
    print(f"   ç”Ÿæˆçš„æè¿°: {captions}")

    # æµ‹è¯•é«˜çº§è§†è§‰å¤„ç†å™¨
    print("\n2. æµ‹è¯•é«˜çº§è§†è§‰å¤„ç†å™¨...")
    device = 'cpu'  # ä½¿ç”¨CPUé¿å…MPSå…¼å®¹æ€§é—®é¢˜
    visual_processor = AdvancedVisualProcessor(device=device)

    # æµ‹è¯•å›¾åƒåˆ†æ
    try:
        if 'image_batch' in locals():
            print("   åˆ†æå›¾åƒ...")
            image_analysis = visual_processor.analyze_image_comprehensive(image_batch)
            print(f"   å›¾åƒç‰¹å¾ç»´åº¦: {image_analysis['features'].shape}")
            print(f"   ç‰©ä½“æ£€æµ‹: {'objects' in image_analysis}")
            print(f"   åœºæ™¯ç†è§£: {'scene' in image_analysis}")
            print(f"   è´¨é‡è¯„åˆ†: {image_analysis.get('quality_score', 'N/A')}")
    except Exception as e:
        print(f"   âŒ å›¾åƒåˆ†æå¤±è´¥: {e}")

    # æµ‹è¯•è§†é¢‘åˆ†æ
    try:
        if 'video_batch' in locals():
            print("   åˆ†æè§†é¢‘...")
            video_analysis = visual_processor.analyze_video_comprehensive(video_batch)
            print(f"   è§†é¢‘ç‰¹å¾ç»´åº¦: {video_analysis['features'].shape}")
            print(f"   åŠ¨ä½œè¯†åˆ«: {'actions' in video_analysis}")
            print(f"   è¿åŠ¨æ¨¡å¼: {'motion_patterns' in video_analysis}")
            print(f"   æ—¶é—´ä¸€è‡´æ€§: {video_analysis.get('temporal_consistency', 'N/A')}")
    except Exception as e:
        print(f"   âŒ è§†é¢‘åˆ†æå¤±è´¥: {e}")

    print("\nâœ… è§†è§‰æ•°æ®é›†æˆæµ‹è¯•å®Œæˆ")

async def test_learning_engine():
    """æµ‹è¯•ä¼˜åŒ–åçš„å­¦ä¹ å¼•æ“"""
    print("\n3. æµ‹è¯•ä¼˜åŒ–å­¦ä¹ å¼•æ“...")

    try:
        from extended_multimodal_agi_training import (
            UnifiedBinaryFlowPerceptionCore,
            OptimizedHybridLearningEngine,
            AdvancedVisualProcessor
        )

        # åˆ›å»ºç»„ä»¶
        perception_core = UnifiedBinaryFlowPerceptionCore(dim=256, num_modalities=6)
        visual_processor = AdvancedVisualProcessor(device='cpu')
        learning_engine = OptimizedHybridLearningEngine(perception_core, visual_processor)

        # å¯åŠ¨é¢„å–
        await learning_engine.start_prefetch()

        # æµ‹è¯•å­¦ä¹ æ‰¹æ¬¡ç”Ÿæˆ
        print("   ç”Ÿæˆå­¦ä¹ æ‰¹æ¬¡...")
        for step in range(3):
            batch = await learning_engine.get_learning_batch(step)
            print(f"   æ­¥éª¤ {step}: {batch['type']} - æ¨¡æ€: {list(batch.get('data', {}).keys())}")

        # è·å–æ€§èƒ½æŠ¥å‘Š
        performance = learning_engine.get_performance_report()
        print(f"   å­¦ä¹ æ•ˆç‡: {performance['performance_metrics']['learning_efficiency']:.2%}")
        print(f"   æ¨¡æ€å¹³è¡¡: {performance['performance_metrics']['modality_balance']:.2%}")

        # åœæ­¢é¢„å–
        await learning_engine.stop_prefetch()

        print("   âœ… å­¦ä¹ å¼•æ“æµ‹è¯•é€šè¿‡")

    except Exception as e:
        print(f"   âŒ å­¦ä¹ å¼•æ“æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹è§†è§‰æ•°æ®é›†æˆå’Œå¤„ç†æµ‹è¯•")
    print("=" * 50)

    await test_visual_data_integration()
    await test_learning_engine()

    print("\n" + "=" * 50)
    print("ğŸ¯ æ‰€æœ‰æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main())