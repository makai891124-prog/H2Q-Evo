#!/usr/bin/env python3
"""
AGIå¤šæ¨¡æ€å…¨èƒ½åŠ›è®­ç»ƒç³»ç»Ÿ - é›†æˆGemini 2.5 Flash

åŠŸèƒ½ç‰¹æ€§ï¼š
1. ç»“åˆæœ¬åœ°AGIè‡ªä¸»è®­ç»ƒçš„æ‰€æœ‰åŠŸèƒ½
2. é›†æˆGemini 2.5 Flash APIè¿›è¡ŒçŸ¥è¯†æ‰©å±•
3. å¢å¼ºçš„ç¼“å­˜æœºåˆ¶å’Œé€Ÿç‡æ§åˆ¶
4. å¤šæ¨¡æ€å­¦ä¹ èƒ½åŠ›ï¼ˆæ–‡æœ¬ã€ä»£ç ã€æ•°å­¦ç­‰ï¼‰
5. æŒç»­å­¦ä¹ å’Œè¿›åŒ–
6. æ™ºèƒ½APIè°ƒç”¨ç®¡ç†
"""

import os
import sys
import json
import time
import logging
import asyncio
import torch
import numpy as np
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timedelta
import threading
from collections import deque, defaultdict
import hashlib
import pickle
from functools import lru_cache

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/Users/imymm/H2Q-Evo')

from dotenv import load_dotenv
load_dotenv()

try:
    from google import genai
    from google.genai import types
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("âš ï¸  Gemini APIä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æœ¬åœ°çŸ¥è¯†æ‰©å±•")

from optimized_agi_autonomous_system import OptimizedAutonomousAGI

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [MULTIMODAL-AGI] %(levelname)s: %(message)s',
    handlers=[
        logging.FileHandler('multimodal_agi_training.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger('MULTIMODAL-AGI')

class EnhancedGeminiKnowledgeExpander:
    """å¢å¼ºçš„GeminiçŸ¥è¯†æ‰©å±•å™¨ - æ™ºèƒ½ç¼“å­˜å’Œé€Ÿç‡æ§åˆ¶"""

    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")
        self.model_name = "gemini-2.5-flash"  # ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹
        self.client = None

        # å¢å¼ºçš„é€Ÿç‡é™åˆ¶æ§åˆ¶
        self.call_history = deque(maxlen=60)  # è®°å½•æœ€è¿‘60æ¬¡è°ƒç”¨
        self.max_calls_per_minute = 8  # é™ä½åˆ°æ¯åˆ†é’Ÿ8æ¬¡è°ƒç”¨ï¼Œæ›´ä¿å®ˆ
        self.last_call_time = 0
        self.min_interval = 8.0  # å¢åŠ åˆ°8ç§’é—´éš”
        self.burst_limit = 3  # çªå‘é™åˆ¶
        self.burst_window = 30  # 30ç§’çª—å£

        # å¤šå±‚ç¼“å­˜ç³»ç»Ÿ
        self.memory_cache = {}  # å†…å­˜ç¼“å­˜
        self.disk_cache_dir = Path("./gemini_cache")
        self.disk_cache_dir.mkdir(exist_ok=True)
        self.cache_expiry = 3600  # ç¼“å­˜1å°æ—¶

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'api_calls': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'errors': 0,
            'last_reset': time.time()
        }

        # çŸ¥è¯†é¢†åŸŸæ˜ å°„
        self.domain_experts = {
            'mathematics': 'æ•°å­¦ä¸“å®¶',
            'computer_science': 'è®¡ç®—æœºç§‘å­¦ä¸“å®¶',
            'physics': 'ç‰©ç†å­¦ä¸“å®¶',
            'philosophy': 'å“²å­¦ä¸“å®¶',
            'artificial_intelligence': 'äººå·¥æ™ºèƒ½ä¸“å®¶',
            'deepseek_technologies': 'DeepSeekæŠ€æœ¯ä¸“å®¶'
        }

        if GEMINI_AVAILABLE and self.api_key:
            try:
                self.client = genai.Client(api_key=self.api_key)
                logger.info("âœ… Gemini 2.5 Flash APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.warning(f"âŒ Gemini APIåˆå§‹åŒ–å¤±è´¥: {e}")
                self.client = None
        else:
            logger.warning("âš ï¸  Gemini APIæœªé…ç½®ï¼Œä½¿ç”¨æœ¬åœ°çŸ¥è¯†æ‰©å±•æ¨¡å¼")

    def _get_cache_key(self, topic: str, context: Dict[str, Any]) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = f"{topic}:{json.dumps(context, sort_keys=True)}"
        return hashlib.md5(content.encode()).hexdigest()

    def _load_from_disk_cache(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """ä»ç£ç›˜ç¼“å­˜åŠ è½½"""
        cache_file = self.disk_cache_dir / f"{cache_key}.pkl"
        if cache_file.exists():
            try:
                with open(cache_file, 'rb') as f:
                    data, timestamp = pickle.load(f)
                    if time.time() - timestamp < self.cache_expiry:
                        return data
                    else:
                        # è¿‡æœŸåˆ é™¤
                        cache_file.unlink()
            except Exception as e:
                logger.warning(f"ç¼“å­˜æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return None

    def _save_to_disk_cache(self, cache_key: str, data: Dict[str, Any]):
        """ä¿å­˜åˆ°ç£ç›˜ç¼“å­˜"""
        cache_file = self.disk_cache_dir / f"{cache_key}.pkl"
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump((data, time.time()), f)
        except Exception as e:
            logger.warning(f"ç¼“å­˜æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")

    def _check_burst_limit(self) -> bool:
        """æ£€æŸ¥çªå‘é™åˆ¶"""
        current_time = time.time()
        recent_calls = [t for t in self.call_history if current_time - t < self.burst_window]
        return len(recent_calls) < self.burst_limit

    def _check_rate_limit(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¶…è¿‡é€Ÿç‡é™åˆ¶"""
        current_time = time.time()

        # æ¸…ç†è¿‡æœŸè®°å½•
        while self.call_history and current_time - self.call_history[0] > 60:
            self.call_history.popleft()

        # æ£€æŸ¥é—´éš”é™åˆ¶
        if current_time - self.last_call_time < self.min_interval:
            return False

        # æ£€æŸ¥çªå‘é™åˆ¶
        if not self._check_burst_limit():
            return False

        # æ£€æŸ¥æ¯åˆ†é’Ÿé™åˆ¶
        if len(self.call_history) >= self.max_calls_per_minute:
            return False

        return True

    def _record_call(self):
        """è®°å½•APIè°ƒç”¨"""
        current_time = time.time()
        self.call_history.append(current_time)
        self.last_call_time = current_time
        self.stats['api_calls'] += 1

    def _wait_for_rate_limit(self) -> float:
        """ç­‰å¾…ç›´åˆ°å¯ä»¥è¿›è¡ŒAPIè°ƒç”¨ï¼Œè¿”å›ç­‰å¾…æ—¶é—´"""
        while not self._check_rate_limit():
            time.sleep(1.0)
        return 0.0

    async def expand_knowledge(self, topic: str, current_knowledge: Dict[str, Any],
                              modality: str = "text") -> Dict[str, Any]:
        """
        ä½¿ç”¨Gemini 2.5 Flashæ‰©å±•çŸ¥è¯†ç½‘ç»œ

        Args:
            topic: è¦æ‰©å±•çš„ä¸»é¢˜
            current_knowledge: å½“å‰å·²æœ‰çš„çŸ¥è¯†
            modality: æ¨¡æ€ç±»å‹ (text, code, math, etc.)

        Returns:
            æ‰©å±•åçš„çŸ¥è¯†å­—å…¸
        """
        if not self.client:
            logger.info(f"ğŸ“š ä½¿ç”¨æœ¬åœ°çŸ¥è¯†æ‰©å±•æ¨¡å¼: {topic}")
            return self._local_knowledge_expansion(topic, current_knowledge, modality)

        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = self._get_cache_key(topic, current_knowledge)

        # æ£€æŸ¥å†…å­˜ç¼“å­˜
        if cache_key in self.memory_cache:
            self.stats['cache_hits'] += 1
            logger.info(f"ğŸ’¾ å†…å­˜ç¼“å­˜å‘½ä¸­: {topic}")
            return self.memory_cache[cache_key]

        # æ£€æŸ¥ç£ç›˜ç¼“å­˜
        cached_data = self._load_from_disk_cache(cache_key)
        if cached_data:
            self.stats['cache_hits'] += 1
            self.memory_cache[cache_key] = cached_data  # åŠ è½½åˆ°å†…å­˜ç¼“å­˜
            logger.info(f"ğŸ’¾ ç£ç›˜ç¼“å­˜å‘½ä¸­: {topic}")
            return cached_data

        self.stats['cache_misses'] += 1

        # ç­‰å¾…é€Ÿç‡é™åˆ¶
        wait_time = self._wait_for_rate_limit()
        if wait_time > 0:
            logger.info(f"â³ ç­‰å¾…é€Ÿç‡é™åˆ¶: {wait_time:.1f}ç§’")

        try:
            # æ„å»ºä¸“å®¶æç¤º
            expert_role = self.domain_experts.get(topic.lower(), "çŸ¥è¯†ä¸“å®¶")

            prompt = f"""ä½ æ˜¯ä¸€ä½{expert_role}ï¼Œè¯·åŸºäºä»¥ä¸‹å½“å‰çŸ¥è¯†ï¼Œæ‰©å±•å…³äº"{topic}"çš„çŸ¥è¯†ç½‘ç»œã€‚

å½“å‰çŸ¥è¯†çŠ¶æ€ï¼š
{json.dumps(current_knowledge, ensure_ascii=False, indent=2)}

è¯·ä»ä»¥ä¸‹{modality}æ¨¡æ€è§’åº¦æä¾›æ‰©å±•çŸ¥è¯†ï¼š

1. æ ¸å¿ƒæ¦‚å¿µæ·±åŒ–
2. å®é™…åº”ç”¨æ¡ˆä¾‹
3. ç›¸å…³æŠ€æœ¯è¿æ¥
4. ç ”ç©¶å‘å±•è¶‹åŠ¿
5. æŠ€æœ¯æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ
6. å­¦ä¹ è·¯å¾„å»ºè®®
7. ç›¸å…³ä¸»é¢˜æ¨è

è¯·æä¾›ç»“æ„åŒ–çš„JSONå“åº”ï¼ŒåŒ…å«ä¸Šè¿°æ‰€æœ‰æ–¹é¢ã€‚"""

            # è°ƒç”¨Gemini 2.5 Flash API
            self._record_call()

            response = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.7,
                    top_p=0.9,
                    max_output_tokens=2048,
                    response_mime_type="application/json"
                )
            )

            # è§£æå“åº”
            if response and response.text:
                try:
                    expanded_knowledge = json.loads(response.text.strip())
                    logger.info(f"âœ… Gemini APIæ‰©å±•æˆåŠŸ: {topic}")

                    # ç¼“å­˜ç»“æœ
                    self.memory_cache[cache_key] = expanded_knowledge
                    self._save_to_disk_cache(cache_key, expanded_knowledge)

                    return expanded_knowledge

                except json.JSONDecodeError as e:
                    logger.warning(f"âŒ JSONè§£æå¤±è´¥: {e}")
                    self.stats['errors'] += 1
                    return self._local_knowledge_expansion(topic, current_knowledge, modality)
            else:
                logger.warning("âŒ Gemini APIæ— å“åº”")
                self.stats['errors'] += 1
                return self._local_knowledge_expansion(topic, current_knowledge, modality)

        except Exception as e:
            logger.error(f"âŒ Gemini APIè°ƒç”¨å¤±è´¥: {e}")
            self.stats['errors'] += 1
            return self._local_knowledge_expansion(topic, current_knowledge, modality)

    def _local_knowledge_expansion(self, topic: str, current_knowledge: Dict[str, Any],
                                  modality: str = "text") -> Dict[str, Any]:
        """æœ¬åœ°çŸ¥è¯†æ‰©å±•ï¼ˆå½“APIä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰"""
        logger.info(f"ğŸ“š ä½¿ç”¨æœ¬åœ°çŸ¥è¯†æ‰©å±•{topic} ({modality}æ¨¡æ€)")

        # åŸºäºä¸»é¢˜å’Œæ¨¡æ€çš„æœ¬åœ°æ‰©å±•é€»è¾‘
        base_expansion = {
            "æ ¸å¿ƒæ¦‚å¿µæ·±åŒ–": f"{topic}æ˜¯{modality}é¢†åŸŸçš„é‡è¦æ¦‚å¿µ",
            "å®é™…åº”ç”¨æ¡ˆä¾‹": f"{topic}åœ¨{modality}å¤„ç†ä¸­æœ‰å¹¿æ³›åº”ç”¨",
            "ç›¸å…³æŠ€æœ¯è¿æ¥": f"{topic}ä¸å…¶ä»–{modality}æŠ€æœ¯å¯†åˆ‡ç›¸å…³",
            "ç ”ç©¶å‘å±•è¶‹åŠ¿": f"{topic}åœ¨{modality}é¢†åŸŸæ­£åœ¨å¿«é€Ÿå‘å±•",
            "æŠ€æœ¯æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ": f"{topic}é¢ä¸´{modality}å¤„ç†çš„æŒ‘æˆ˜",
            "å­¦ä¹ è·¯å¾„å»ºè®®": f"å»ºè®®ç³»ç»Ÿæ€§å­¦ä¹ {topic}åœ¨{modality}æ–¹é¢çš„çŸ¥è¯†",
            "ç›¸å…³ä¸»é¢˜æ¨è": [f"{modality}å¤„ç†", "AIæŠ€æœ¯", "æœºå™¨å­¦ä¹ "]
        }

        # æ¨¡æ€ç‰¹å®šçš„æ‰©å±•
        if modality == "code":
            base_expansion.update({
                "æ ¸å¿ƒæ¦‚å¿µæ·±åŒ–": f"{topic}æ¶‰åŠä»£ç ç”Ÿæˆã€åˆ†æå’Œä¼˜åŒ–æŠ€æœ¯",
                "å®é™…åº”ç”¨æ¡ˆä¾‹": "ä»£ç è¡¥å…¨ã€bugæ£€æµ‹ã€é‡æ„ç­‰",
                "ç›¸å…³æŠ€æœ¯è¿æ¥": "ç¼–è¯‘å™¨æŠ€æœ¯ã€é™æ€åˆ†æã€ASTå¤„ç†",
                "ç ”ç©¶å‘å±•è¶‹åŠ¿": "æœç€å¤šè¯­è¨€æ”¯æŒã€å¤§æ¨¡å‹é›†æˆæ–¹å‘å‘å±•"
            })
        elif modality == "math":
            base_expansion.update({
                "æ ¸å¿ƒæ¦‚å¿µæ·±åŒ–": f"{topic}åŒ…å«æ•°å­¦æ¨ç†å’Œè¯æ˜æŠ€æœ¯",
                "å®é™…åº”ç”¨æ¡ˆä¾‹": "å®šç†è¯æ˜ã€æ•°å­¦é—®é¢˜æ±‚è§£ã€å…¬å¼æ¨å¯¼",
                "ç›¸å…³æŠ€æœ¯è¿æ¥": "ç¬¦å·è®¡ç®—ã€é€»è¾‘æ¨ç†ã€æ•°å­¦å»ºæ¨¡",
                "ç ”ç©¶å‘å±•è¶‹åŠ¿": "æœç€è‡ªåŠ¨åŒ–æ•°å­¦å‘ç°æ–¹å‘å‘å±•"
            })

        return base_expansion

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        current_time = time.time()
        if current_time - self.stats['last_reset'] > 3600:  # æ¯å°æ—¶é‡ç½®
            self.stats.update({
                'api_calls': 0,
                'cache_hits': 0,
                'cache_misses': 0,
                'errors': 0,
                'last_reset': current_time
            })

        total_requests = self.stats['cache_hits'] + self.stats['cache_misses']
        hit_rate = self.stats['cache_hits'] / total_requests if total_requests > 0 else 0

        return {
            **self.stats,
            'hit_rate': hit_rate,
            'current_queue_size': len(self.call_history),
            'memory_cache_size': len(self.memory_cache)
        }

class MultimodalAGITrainer:
    """å¤šæ¨¡æ€AGIè®­ç»ƒå™¨ - é›†æˆæ‰€æœ‰åŠŸèƒ½"""

    def __init__(self):
        self.agi_system = None
        self.knowledge_expander = EnhancedGeminiKnowledgeExpander()

        # å¤šæ¨¡æ€æ”¯æŒ
        self.modalities = ["text", "code", "math", "reasoning", "technical"]
        self.modality_weights = {mod: 1.0 for mod in self.modalities}

        # è®­ç»ƒç»Ÿè®¡
        self.training_stats = {
            'start_time': datetime.now(),
            'total_steps': 0,
            'knowledge_expansions': 0,
            'api_calls': 0,
            'learning_metrics': [],
            'modality_usage': {mod: 0 for mod in self.modalities}
        }

        # æ™ºèƒ½è°ƒåº¦
        self.expansion_interval = 30  # æ¯30æ­¥è¿›è¡Œä¸€æ¬¡çŸ¥è¯†æ‰©å±•
        self.last_expansion_step = 0
        self.adaptive_expansion = True  # è‡ªé€‚åº”æ‰©å±•é¢‘ç‡

        # æ€§èƒ½ç›‘æ§
        self.performance_history = deque(maxlen=100)

        logger.info("ğŸš€ å¤šæ¨¡æ€AGIè®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")

    def initialize_system(self):
        """åˆå§‹åŒ–AGIç³»ç»Ÿ"""
        logger.info("ğŸ”§ åˆå§‹åŒ–å¤šæ¨¡æ€AGIç³»ç»Ÿ...")

        # åŠ è½½å­¦ä¹ èµ„æ–™
        learning_materials = self._load_learning_materials()

        # åˆ›å»ºAGIç³»ç»Ÿ
        self.agi_system = OptimizedAutonomousAGI(
            input_dim=256,
            action_dim=64,
            learning_materials=learning_materials
        )

        logger.info("âœ… å¤šæ¨¡æ€AGIç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def _load_learning_materials(self) -> Dict[str, Any]:
        """åŠ è½½å­¦ä¹ èµ„æ–™"""
        try:
            with open('agi_learning_data.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
                logger.info(f"ğŸ“š å·²åŠ è½½å­¦ä¹ èµ„æ–™ï¼š{len(data.get('domains', []))}ä¸ªé¢†åŸŸ")
                return data
        except Exception as e:
            logger.warning(f"âŒ å­¦ä¹ èµ„æ–™åŠ è½½å¤±è´¥: {e}")
            return {"domains": [], "learning_tasks": []}

    def _select_modality(self) -> str:
        """æ™ºèƒ½é€‰æ‹©æ¨¡æ€"""
        # åŸºäºå½“å‰ç³»ç»ŸçŠ¶æ€å’Œå­¦ä¹ éœ€æ±‚é€‰æ‹©æ¨¡æ€
        if not hasattr(self.agi_system, 'consciousness_engine'):
            return "text"

        consciousness = self._get_consciousness_level() if hasattr(self.agi_system, 'consciousness_engine') else {}

        # æ ¹æ®æ„è¯†æ°´å¹³é€‰æ‹©æ¨¡æ€
        if consciousness['integrated_information'] > 0.5:
            # é«˜æ„è¯†æ°´å¹³ï¼Œé€‚åˆå¤æ‚æ¨¡æ€
            weights = {"reasoning": 0.3, "technical": 0.3, "code": 0.2, "math": 0.1, "text": 0.1}
        elif consciousness['metacognitive_awareness'] > 0.4:
            # è¾ƒé«˜å…ƒè®¤çŸ¥ï¼Œé€‚åˆæŠ€æœ¯æ¨¡æ€
            weights = {"technical": 0.4, "code": 0.3, "reasoning": 0.2, "text": 0.1, "math": 0.0}
        else:
            # åŸºç¡€æ°´å¹³ï¼Œä»æ–‡æœ¬å¼€å§‹
            weights = {"text": 0.5, "reasoning": 0.3, "technical": 0.1, "code": 0.05, "math": 0.05}

        # å½’ä¸€åŒ–æƒé‡
        total = sum(weights.values())
        normalized_weights = {k: v/total for k, v in weights.items()}

        # æŒ‰æƒé‡é€‰æ‹©
        modalities = list(normalized_weights.keys())
        weights_list = list(normalized_weights.values())

        selected = np.random.choice(modalities, p=weights_list)
        self.training_stats['modality_usage'][selected] += 1

        return selected

    def _perform_knowledge_expansion_sync(self, step: int):
        """åŒæ­¥æ‰§è¡ŒçŸ¥è¯†æ‰©å±•ï¼ˆç”¨äºéå¼‚æ­¥ä¸Šä¸‹æ–‡ï¼‰"""
        try:
            # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå™¨æ¥é¿å…äº‹ä»¶å¾ªç¯å†²çª
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(self._run_async_expansion, step)
                future.result(timeout=30)  # 30ç§’è¶…æ—¶
        except Exception as e:
            logger.warning(f"çŸ¥è¯†æ‰©å±•å¤±è´¥: {e}")

    def _run_async_expansion(self, step: int):
        """åœ¨æ–°çš„çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥çŸ¥è¯†æ‰©å±•"""
        try:
            # åˆ›å»ºæ–°çš„å¼‚æ­¥ç¯å¢ƒ
            import nest_asyncio
            nest_asyncio.apply()

            # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

            # è¿è¡Œå¼‚æ­¥ä»»åŠ¡
            loop.run_until_complete(self._perform_knowledge_expansion(step))
            loop.close()
        except Exception as e:
            logger.warning(f"å¼‚æ­¥çŸ¥è¯†æ‰©å±•å¤±è´¥: {e}")

    async def _perform_knowledge_expansion(self, step: int):
        """æ‰§è¡ŒçŸ¥è¯†æ‰©å±•"""
        if step - self.last_expansion_step < self.expansion_interval:
            return

        # é€‰æ‹©è¦æ‰©å±•çš„ä¸»é¢˜
        available_topics = []
        if hasattr(self.agi_system, 'learning_materials'):
            for domain in self.agi_system.learning_materials.get('domains', []):
                available_topics.extend(domain.get('topics', []))

        if not available_topics:
            available_topics = ["artificial_intelligence", "machine_learning", "deepseek_technologies"]

        # é€‰æ‹©å½“å‰æœ€ç›¸å…³çš„ä¸»é¢˜
        current_goals = []
        if hasattr(self.agi_system, 'goal_system') and self.agi_system.goal_system:
            active_goals = getattr(self.agi_system.goal_system, 'active_goals', [])
            for goal in active_goals:
                if isinstance(goal, dict):
                    # å¦‚æœgoalæ˜¯å­—å…¸ï¼Œè·å–descriptionå­—æ®µ
                    current_goals.append(goal.get('description', str(goal)))
                elif hasattr(goal, 'description'):
                    # å¦‚æœgoalæ˜¯å¯¹è±¡ï¼Œè·å–descriptionå±æ€§
                    current_goals.append(goal.description)
                else:
                    # å…¶ä»–æƒ…å†µï¼Œè½¬ä¸ºå­—ç¬¦ä¸²
                    current_goals.append(str(goal))

        # ç®€å•çš„ç›¸å…³æ€§åŒ¹é…
        topic_scores = {}
        for topic in available_topics:
            score = 0
            for goal in current_goals:
                if topic.lower() in goal.lower():
                    score += 1
            topic_scores[topic] = score

        # é€‰æ‹©æœ€é«˜åˆ†çš„ä¸»é¢˜ï¼Œå¦‚æœéƒ½æ²¡æœ‰åˆ™éšæœºé€‰æ‹©
        if topic_scores:
            selected_topic = max(topic_scores.items(), key=lambda x: x[1])[0]
        else:
            selected_topic = np.random.choice(available_topics)

    def _get_consciousness_level(self) -> Dict[str, float]:
        """è·å–å½“å‰æ„è¯†æ°´å¹³"""
        if not hasattr(self.agi_system, 'consciousness_engine') or not self.agi_system.consciousness_engine:
            return {}

        try:
            # è°ƒç”¨forwardæ–¹æ³•è·å–æ„è¯†æŒ‡æ ‡
            consciousness_metrics, _ = self.agi_system.consciousness_engine(self.agi_system.current_state)
            return {
                'integrated_information': consciousness_metrics.integrated_information,
                'neural_complexity': consciousness_metrics.neural_complexity,
                'self_model_accuracy': consciousness_metrics.self_model_accuracy,
                'metacognitive_awareness': consciousness_metrics.metacognitive_awareness,
                'emotional_valence': consciousness_metrics.emotional_valence,
                'temporal_binding': consciousness_metrics.temporal_binding
            }
        except Exception as e:
            logger.warning(f"è·å–æ„è¯†æ°´å¹³å¤±è´¥: {e}")
            return {}

    def _select_modality(self) -> str:
        """è·å–å½“å‰çŸ¥è¯†çŠ¶æ€"""
        # ä»AGIç³»ç»Ÿçš„å­¦ä¹ èµ„æ–™ä¸­æå–ç›¸å…³çŸ¥è¯†
        current_state = {}

        if hasattr(self.agi_system, 'learning_materials'):
            materials = self.agi_system.learning_materials
            for domain in materials.get('domains', []):
                if topic.lower() in domain.get('name', '').lower():
                    current_state.update({
                        'existing_concepts': domain.get('concepts', []),
                        'current_level': domain.get('difficulty', 'beginner'),
                        'learned_topics': domain.get('topics', [])
                    })
                    break

        return current_state

    def _integrate_expanded_knowledge(self, topic: str, expanded_knowledge: Dict[str, Any], modality: str):
        """æ•´åˆæ‰©å±•çš„çŸ¥è¯†åˆ°AGIç³»ç»Ÿ"""
        try:
            # æ›´æ–°å­¦ä¹ èµ„æ–™
            if hasattr(self.agi_system, 'learning_materials'):
                materials = self.agi_system.learning_materials

                # æŸ¥æ‰¾æˆ–åˆ›å»ºé¢†åŸŸ
                domain_found = False
                for domain in materials.get('domains', []):
                    if topic.lower() in domain.get('name', '').lower():
                        # æ›´æ–°ç°æœ‰é¢†åŸŸ
                        domain.setdefault('expanded_knowledge', {}).update({
                            modality: expanded_knowledge
                        })
                        domain_found = True
                        break

                if not domain_found:
                    # åˆ›å»ºæ–°é¢†åŸŸ
                    new_domain = {
                        'name': topic,
                        'topics': [topic],
                        'concepts': list(expanded_knowledge.keys()),
                        'difficulty': 'intermediate',
                        'expanded_knowledge': {modality: expanded_knowledge}
                    }
                    materials['domains'].append(new_domain)

                # ä¿å­˜æ›´æ–°
                with open('agi_learning_data_expanded.json', 'w', encoding='utf-8') as f:
                    json.dump(materials, f, ensure_ascii=False, indent=2)

            logger.info(f"âœ… çŸ¥è¯†æ•´åˆå®Œæˆ: {topic} ({modality})")

        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†æ•´åˆå¤±è´¥: {e}")

    async def run_training_loop(self, max_steps: int = 1000):
        """è¿è¡Œè®­ç»ƒå¾ªç¯"""
        logger.info(f"ğŸƒ å¼€å§‹å¤šæ¨¡æ€AGIè®­ç»ƒï¼Œç›®æ ‡æ­¥æ•°ï¼š{max_steps}")

        try:
            for step in range(max_steps):
                self.training_stats['total_steps'] = step + 1

                # æ‰§è¡Œä¸€æ­¥è®­ç»ƒ
                if self.agi_system:
                    step_result = self.agi_system.step()
                    # è®°å½•æ­¥éª¤ç»“æœ
                    if step_result:
                        self.performance_history.append(step_result)

                # å®šæœŸæ‰§è¡ŒçŸ¥è¯†æ‰©å±•
                self._perform_knowledge_expansion_sync(step)

                # è®°å½•å­¦ä¹ æŒ‡æ ‡
                if self.agi_system and hasattr(self.agi_system, 'get_learning_metrics'):
                    metrics = self.agi_system.get_learning_metrics()
                    self.training_stats['learning_metrics'].append(metrics)

                # ä¿å­˜è®­ç»ƒçŠ¶æ€
                if step % 50 == 0:
                    self._save_training_state()

                # æ˜¾ç¤ºè¿›åº¦
                if step % 10 == 0:
                    self._log_progress(step)

                # å°å»¶è¿Ÿé¿å…è¿‡åº¦å ç”¨CPU
                await asyncio.sleep(0.1)

        except KeyboardInterrupt:
            logger.info("â¹ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            logger.error(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        finally:
            # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            self._generate_final_report()

    def _log_progress(self, step: int):
        """è®°å½•è®­ç»ƒè¿›åº¦"""
        expander_stats = self.knowledge_expander.get_stats()

        progress_info = {
            'step': step + 1,
            'expansions': self.training_stats['knowledge_expansions'],
            'api_calls': expander_stats['api_calls'],
            'cache_hit_rate': f"{expander_stats['hit_rate']:.2%}",
            'modality_usage': self.training_stats['modality_usage']
        }

        logger.info(f"ğŸ“Š æ­¥éª¤ {step + 1}: {progress_info}")

    def _save_training_state(self):
        """ä¿å­˜è®­ç»ƒçŠ¶æ€"""
        state = {
            'training_stats': self.training_stats,
            'system_status': self._get_system_status(),
            'timestamp': datetime.now().isoformat()
        }

        with open('multimodal_agi_training_state.json', 'w', encoding='utf-8') as f:
            json.dump(state, f, ensure_ascii=False, indent=2, default=str)

        logger.info("ğŸ’¾ è®­ç»ƒçŠ¶æ€å·²ä¿å­˜")

    def _get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        if not self.agi_system:
            return {}

        try:
            return {
                'step_count': getattr(self.agi_system, 'step_count', 0),
                'runtime': getattr(self.agi_system, 'runtime', 0),
                'consciousness_level': self._get_consciousness_level(),
                'goal_status': self.agi_system.goal_system.get_status() if hasattr(self.agi_system, 'goal_system') else {},
                'learning_status': self.agi_system.learning_engine.get_status() if hasattr(self.agi_system, 'learning_engine') else {}
            }
        except Exception as e:
            logger.warning(f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
            return {}

    def _generate_final_report(self):
        """ç”Ÿæˆæœ€ç»ˆè®­ç»ƒæŠ¥å‘Š"""
        report = {
            'training_duration': str(datetime.now() - self.training_stats['start_time']),
            'total_steps': self.training_stats['total_steps'],
            'knowledge_expansions': self.training_stats['knowledge_expansions'],
            'modality_distribution': self.training_stats['modality_usage'],
            'expander_stats': self.knowledge_expander.get_stats(),
            'final_system_status': self._get_system_status(),
            'completion_time': datetime.now().isoformat()
        }

        with open('multimodal_agi_training_final_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)

        logger.info("ğŸ“‹ æœ€ç»ˆè®­ç»ƒæŠ¥å‘Šå·²ç”Ÿæˆ")

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ AGIå¤šæ¨¡æ€å…¨èƒ½åŠ›è®­ç»ƒç³»ç»Ÿå¯åŠ¨")
    logger.info("=" * 50)

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = MultimodalAGITrainer()

    # åˆå§‹åŒ–ç³»ç»Ÿ
    trainer.initialize_system()

    # è¿è¡Œè®­ç»ƒ
    await trainer.run_training_loop(max_steps=500)

    logger.info("=" * 50)
    logger.info("ğŸ¯ AGIå¤šæ¨¡æ€å…¨èƒ½åŠ›è®­ç»ƒç³»ç»Ÿç»“æŸ")

if __name__ == "__main__":
    asyncio.run(main())