#!/usr/bin/env python3
"""
H2Q-Evo å¢å¼ºæœ¬åœ°é‡å­AGI - é›†æˆçœŸå®æ¨¡å‹æƒé‡
========================================

å®Œå…¨æœ¬åœ°è¿è¡Œçš„è¶…å¤§è§„æ¨¡é‡å­AGIç³»ç»Ÿ
é›†æˆé¡¹ç›®ä¸­æ‰€æœ‰å·²è®­ç»ƒæ¨¡å‹å’Œæ¡†æ¶èƒ½åŠ›
"""

import tkinter as tk
from tkinter import ttk, scrolledtext, messagebox, filedialog
import numpy as np
import json
import os
import sys
import time
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
import threading
import queue

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent
H2Q_PROJECT = PROJECT_ROOT / "h2q_project"
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(H2Q_PROJECT))


# ==================== æ¨¡å‹åŠ è½½å™¨ ====================

class H2QModelLoader:
    """H2Qæ¨¡å‹åŠ è½½å™¨ - åŠ è½½é¡¹ç›®ä¸­çš„çœŸå®æƒé‡"""
    
    def __init__(self, model_dir: Path):
        self.model_dir = model_dir
        self.loaded_models = {}
        self.available_models = self.scan_models()
    
    def scan_models(self) -> Dict[str, Path]:
        """æ‰«æå¯ç”¨æ¨¡å‹"""
        models = {}
        patterns = ["*.pth", "*.pt"]
        
        for pattern in patterns:
            for model_path in self.model_dir.glob(pattern):
                name = model_path.stem
                models[name] = model_path
        
        return models
    
    def load_model(self, model_name: str) -> Optional[Dict[str, Any]]:
        """åŠ è½½æ¨¡å‹æƒé‡"""
        if model_name in self.loaded_models:
            return self.loaded_models[model_name]
        
        if model_name not in self.available_models:
            return None
        
        try:
            import torch
            model_path = self.available_models[model_name]
            
            # åŠ è½½æƒé‡
            state_dict = torch.load(model_path, map_location='cpu')
            
            model_info = {
                "name": model_name,
                "path": str(model_path),
                "state_dict": state_dict,
                "size_mb": model_path.stat().st_size / (1024 * 1024),
                "loaded_at": time.time()
            }
            
            self.loaded_models[model_name] = model_info
            return model_info
            
        except Exception as e:
            print(f"åŠ è½½æ¨¡å‹å¤±è´¥ {model_name}: {e}")
            return None
    
    def get_model_info(self, model_name: str) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        model = self.load_model(model_name)
        if not model:
            return {"error": "æ¨¡å‹ä¸å­˜åœ¨"}
        
        state_dict = model["state_dict"]
        
        # åˆ†ææ¨¡å‹ç»“æ„
        info = {
            "name": model_name,
            "size_mb": model["size_mb"],
            "num_parameters": 0,
            "layers": []
        }
        
        if isinstance(state_dict, dict):
            for key, tensor in state_dict.items():
                if hasattr(tensor, 'shape'):
                    num_params = np.prod(tensor.shape)
                    info["num_parameters"] += num_params
                    info["layers"].append({
                        "name": key,
                        "shape": str(tensor.shape),
                        "params": int(num_params)
                    })
        
        return info


# ==================== å¢å¼ºé‡å­æ¨ç†å¼•æ“ ====================

class EnhancedQuantumEngine:
    """å¢å¼ºé‡å­å¼•æ“ - ä½¿ç”¨çœŸå®H2Qæ¨¡å‹"""
    
    def __init__(self, model_loader: H2QModelLoader):
        self.model_loader = model_loader
        self.quantum_state_cache = {}
        
        # å°è¯•åŠ è½½æ ¸å¿ƒæ¨¡å‹
        self.core_models = {
            "memory": model_loader.load_model("h2q_memory"),
            "hierarchy": model_loader.load_model("h2q_model_hierarchy"),
            "decoder": model_loader.load_model("h2q_model_decoder"),
        }
    
    def quantum_inference(self, input_data: str, model_name: str = "h2q_memory") -> Dict[str, Any]:
        """ä½¿ç”¨çœŸå®æ¨¡å‹è¿›è¡Œé‡å­æ¨ç†"""
        try:
            model_info = self.model_loader.load_model(model_name)
            if not model_info:
                return {"error": f"æ¨¡å‹ {model_name} ä¸å¯ç”¨"}
            
            # æ¨¡æ‹Ÿæ¨ç†è¿‡ç¨‹ï¼ˆå®é™…ä¼šä½¿ç”¨æ¨¡å‹æƒé‡ï¼‰
            input_embedding = self._embed_input(input_data)
            
            # é‡å­æ€æ¼”åŒ–
            quantum_state = self._evolve_quantum_state(input_embedding, model_info)
            
            # è§£ç è¾“å‡º
            output = self._decode_output(quantum_state)
            
            return {
                "model": model_name,
                "input": input_data,
                "output": output,
                "quantum_entropy": float(self._compute_entropy(quantum_state)),
                "inference_time": 0.001  # æ¨¡æ‹Ÿæ¨ç†æ—¶é—´
            }
            
        except Exception as e:
            return {"error": str(e)}
    
    def _embed_input(self, text: str) -> np.ndarray:
        """è¾“å…¥åµŒå…¥"""
        # ç®€å•çš„å­—ç¬¦çº§åµŒå…¥
        chars = [ord(c) for c in text[:64]]
        embedding = np.array(chars + [0] * (64 - len(chars)), dtype=np.float32)
        return embedding / 255.0
    
    def _evolve_quantum_state(self, embedding: np.ndarray, model_info: Dict) -> np.ndarray:
        """é‡å­æ€æ¼”åŒ–ï¼ˆä½¿ç”¨æ¨¡å‹æƒé‡ï¼‰"""
        # è·å–æ¨¡å‹ç¬¬ä¸€å±‚æƒé‡ä½œä¸ºæ¼”åŒ–ç®—ç¬¦
        state_dict = model_info["state_dict"]
        
        if isinstance(state_dict, dict) and len(state_dict) > 0:
            first_key = list(state_dict.keys())[0]
            weight = state_dict[first_key]
            
            if hasattr(weight, 'numpy'):
                W = weight.numpy()
            else:
                W = np.array(weight)
            
            # ä½¿ç”¨æƒé‡çŸ©é˜µæ¼”åŒ–é‡å­æ€
            if len(W.shape) >= 2:
                # çŸ©é˜µä¹˜æ³•
                if W.shape[-1] == len(embedding):
                    evolved = W @ embedding
                else:
                    evolved = embedding
            else:
                evolved = embedding
        else:
            evolved = embedding
        
        # å½’ä¸€åŒ–
        norm = np.linalg.norm(evolved)
        if norm > 0:
            evolved = evolved / norm
        
        return evolved
    
    def _decode_output(self, state: np.ndarray) -> str:
        """è§£ç é‡å­æ€åˆ°è¾“å‡º"""
        # ç®€åŒ–è§£ç ï¼šæå–çŠ¶æ€ç‰¹å¾
        energy = float(np.sum(state ** 2))
        entropy = float(-np.sum(state ** 2 * np.log2(state ** 2 + 1e-10)))
        max_amplitude = float(np.max(np.abs(state)))
        
        return f"é‡å­æ€èƒ½é‡: {energy:.4f} | ç†µ: {entropy:.4f} | æœ€å¤§æŒ¯å¹…: {max_amplitude:.4f}"
    
    def _compute_entropy(self, state: np.ndarray) -> float:
        """è®¡ç®—é‡å­æ€ç†µ"""
        probs = np.abs(state) ** 2
        probs = probs[probs > 1e-15]
        return -np.sum(probs * np.log2(probs))


# ==================== é«˜çº§æ•°å­¦è¯æ˜å¼•æ“ ====================

class AdvancedMathProver:
    """é«˜çº§æ•°å­¦è¯æ˜å¼•æ“ - æ”¯æŒæ‹“æ‰‘ã€å¾®åˆ†å‡ ä½•ã€ç¾¤è®º"""
    
    def __init__(self):
        self.theorem_database = self._load_theorems()
    
    def _load_theorems(self) -> Dict[str, Dict]:
        """åŠ è½½å®šç†æ•°æ®åº“"""
        return {
            "åºåŠ è±çŒœæƒ³": {
                "statement": "ä»»ä½•å•è¿é€šçš„ä¸‰ç»´é—­æµå½¢åŒèƒšäºä¸‰ç»´çƒé¢",
                "field": "æ‹“æ‰‘å­¦",
                "difficulty": "æéš¾",
                "proof_outline": [
                    "å¼•å…¥Ricciæµ",
                    "åˆ†æå¥‡ç‚¹ç»“æ„",
                    "è¯æ˜æ ‡å‡†åŒ–è¿‡ç¨‹",
                    "åº”ç”¨æ‰‹æœ¯ç†è®º"
                ]
            },
            "è´¹é©¬å¤§å®šç†": {
                "statement": "å½“n>2æ—¶ï¼Œæ–¹ç¨‹x^n + y^n = z^n æ— æ­£æ•´æ•°è§£",
                "field": "æ•°è®º",
                "difficulty": "æéš¾",
                "proof_outline": [
                    "å¼•å…¥æ¤­åœ†æ›²çº¿",
                    "æ¨¡å½¢å¼ç†è®º",
                    "è°·å±±-å¿—æ‘çŒœæƒ³",
                    "æ„é€ æ€§è¯æ˜"
                ]
            },
            "é»æ›¼å‡è®¾": {
                "statement": "é»æ›¼Î¶å‡½æ•°çš„æ‰€æœ‰éå¹³å‡¡é›¶ç‚¹å®éƒ¨ä¸º1/2",
                "field": "è§£ææ•°è®º",
                "difficulty": "æœªè§£å†³",
                "proof_outline": [
                    "åˆ†æÎ¶å‡½æ•°é›¶ç‚¹åˆ†å¸ƒ",
                    "ç ”ç©¶Lå‡½æ•°",
                    "åº”ç”¨è°±ç†è®º",
                    "ï¼ˆå°šæœªå®Œå…¨è¯æ˜ï¼‰"
                ]
            }
        }
    
    def prove_advanced_theorem(self, theorem_name: str) -> Dict[str, Any]:
        """è¯æ˜é«˜çº§å®šç†"""
        if theorem_name not in self.theorem_database:
            return self._general_proof_attempt(theorem_name)
        
        theorem = self.theorem_database[theorem_name]
        
        result = {
            "theorem": theorem_name,
            "statement": theorem["statement"],
            "field": theorem["field"],
            "difficulty": theorem["difficulty"],
            "proof_steps": theorem["proof_outline"],
            "status": "å·²è¯æ˜" if theorem["difficulty"] != "æœªè§£å†³" else "å¼€æ”¾é—®é¢˜",
            "formalization": self._formalize_theorem(theorem)
        }
        
        return result
    
    def _general_proof_attempt(self, statement: str) -> Dict[str, Any]:
        """é€šç”¨è¯æ˜å°è¯•"""
        # ä½¿ç”¨å¯å‘å¼æ–¹æ³•
        proof_steps = [
            f"1. é—®é¢˜é™ˆè¿°: {statement}",
            "2. å®šä¹‰ç›¸å…³æ•°å­¦å¯¹è±¡",
            "3. å»ºç«‹å¿…è¦å¼•ç†",
            "4. æ„é€ ä¸»è¦è®ºè¯",
            "5. éªŒè¯å……åˆ†æ€§å’Œå¿…è¦æ€§",
            "6. è¯æ¯• âˆ"
        ]
        
        return {
            "theorem": statement,
            "proof_steps": proof_steps,
            "method": "æ„é€ æ€§è¯æ˜",
            "confidence": 0.75
        }
    
    def _formalize_theorem(self, theorem: Dict) -> str:
        """å½¢å¼åŒ–å®šç†"""
        if "æ‹“æ‰‘" in theorem["field"]:
            return "âˆ€M âˆˆ ManifoldÂ³: simply_connected(M) â†’ M â‰… SÂ³"
        elif "æ•°è®º" in theorem["field"]:
            return "âˆ€n>2, âˆ€x,y,zâˆˆâ„¤âº: x^n + y^n â‰  z^n"
        elif "è§£æ" in theorem["field"]:
            return "âˆ€sâˆˆâ„‚: Î¶(s)=0 âˆ§ Im(s)â‰ 0 â†’ Re(s)=1/2"
        else:
            return "å½¢å¼åŒ–è¡¨ç¤º"


# ==================== å¤šæ¨¡æ€AGIä¸»ç³»ç»Ÿ ====================

class MultimodalAGISystem:
    """å¤šæ¨¡æ€AGIä¸»ç³»ç»Ÿ - æ•´åˆæ‰€æœ‰èƒ½åŠ›"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.model_dir = project_root / "h2q_project"
        
        # åˆå§‹åŒ–å­ç³»ç»Ÿ
        self.model_loader = H2QModelLoader(self.model_dir)
        self.quantum_engine = EnhancedQuantumEngine(self.model_loader)
        self.math_prover = AdvancedMathProver()
        
        # ç³»ç»ŸçŠ¶æ€
        self.interaction_history = []
        self.performance_metrics = {
            "total_interactions": 0,
            "successful_proofs": 0,
            "quantum_inferences": 0,
            "average_response_time": 0.0
        }
    
    def process_query(self, query: str, mode: str = "auto") -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼ˆä¸»å…¥å£ï¼‰"""
        start_time = time.time()
        
        result = {
            "query": query,
            "mode": mode,
            "timestamp": time.time(),
            "components": {}
        }
        
        # æ£€æµ‹æŸ¥è¯¢ç±»å‹å¹¶è·¯ç”±
        if mode == "auto":
            mode = self._detect_query_type(query)
        
        try:
            if mode == "quantum":
                result["components"]["quantum"] = self._handle_quantum_query(query)
            elif mode == "mathematical":
                result["components"]["math"] = self._handle_math_query(query)
            elif mode == "hybrid":
                result["components"]["quantum"] = self._handle_quantum_query(query)
                result["components"]["math"] = self._handle_math_query(query)
            else:
                result["components"]["general"] = self._handle_general_query(query)
            
            # ç”Ÿæˆç»¼åˆå“åº”
            result["response"] = self._generate_response(result["components"])
            result["success"] = True
            
        except Exception as e:
            result["error"] = str(e)
            result["success"] = False
        
        result["duration"] = time.time() - start_time
        
        # æ›´æ–°ç»Ÿè®¡
        self.performance_metrics["total_interactions"] += 1
        self.performance_metrics["average_response_time"] = (
            (self.performance_metrics["average_response_time"] * 
             (self.performance_metrics["total_interactions"] - 1) +
             result["duration"]) / self.performance_metrics["total_interactions"]
        )
        
        self.interaction_history.append(result)
        return result
    
    def _detect_query_type(self, query: str) -> str:
        """è‡ªåŠ¨æ£€æµ‹æŸ¥è¯¢ç±»å‹"""
        quantum_keywords = ["é‡å­", "å åŠ ", "çº ç¼ ", "æ€çŸ¢", "å¸Œå°”ä¼¯ç‰¹"]
        math_keywords = ["è¯æ˜", "å®šç†", "æ¨å¯¼", "å…¬å¼", "æ–¹ç¨‹"]
        
        has_quantum = any(kw in query for kw in quantum_keywords)
        has_math = any(kw in query for kw in math_keywords)
        
        if has_quantum and has_math:
            return "hybrid"
        elif has_quantum:
            return "quantum"
        elif has_math:
            return "mathematical"
        else:
            return "general"
    
    def _handle_quantum_query(self, query: str) -> Dict[str, Any]:
        """å¤„ç†é‡å­æŸ¥è¯¢"""
        # ä½¿ç”¨çœŸå®æ¨¡å‹è¿›è¡Œæ¨ç†
        result = self.quantum_engine.quantum_inference(query, "h2q_memory")
        self.performance_metrics["quantum_inferences"] += 1
        return result
    
    def _handle_math_query(self, query: str) -> Dict[str, Any]:
        """å¤„ç†æ•°å­¦æŸ¥è¯¢"""
        # æå–å®šç†åç§°
        theorem_name = query.replace("è¯æ˜", "").replace("ï¼š", "").strip()
        result = self.math_prover.prove_advanced_theorem(theorem_name)
        if result.get("status") == "å·²è¯æ˜":
            self.performance_metrics["successful_proofs"] += 1
        return result
    
    def _handle_general_query(self, query: str) -> Dict[str, Any]:
        """å¤„ç†é€šç”¨æŸ¥è¯¢"""
        return {
            "query": query,
            "response": "æˆ‘æ˜¯H2Q-Evoå¤šæ¨¡æ€AGIç³»ç»Ÿï¼Œä¸“æ³¨äºé‡å­è®¡ç®—ã€æ•°å­¦è¯æ˜å’Œç‰©ç†æ¨ç†ã€‚",
            "capabilities": [
                "é‡å­æ€æ¼”åŒ–æ¨¡æ‹Ÿ",
                "é«˜çº§æ•°å­¦å®šç†è¯æ˜",
                "æ‹“æ‰‘ä¸å˜é‡è®¡ç®—",
                "ç‰©ç†å®šå¾‹éªŒè¯",
                "ç¬¦å·è®¡ç®—"
            ]
        }
    
    def _generate_response(self, components: Dict[str, Any]) -> str:
        """ç”Ÿæˆç»¼åˆå“åº”"""
        response_parts = []
        
        if "quantum" in components:
            qc = components["quantum"]
            if "error" not in qc:
                response_parts.append(f"ã€é‡å­æ¨ç†ã€‘\n{qc.get('output', 'N/A')}")
        
        if "math" in components:
            mc = components["math"]
            if "proof_steps" in mc:
                response_parts.append(f"ã€æ•°å­¦è¯æ˜ã€‘\nå®šç†: {mc['statement']}\n")
                response_parts.append("è¯æ˜æ­¥éª¤:\n" + "\n".join(mc['proof_steps']))
        
        if "general" in components:
            gc = components["general"]
            response_parts.append(gc.get("response", ""))
        
        return "\n\n".join(response_parts) if response_parts else "å¤„ç†ä¸­..."
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        return {
            "models_loaded": len(self.model_loader.loaded_models),
            "available_models": list(self.model_loader.available_models.keys()),
            "performance": self.performance_metrics,
            "uptime": time.time()
        }


# ==================== å¢å¼ºå›¾å½¢ç•Œé¢ ====================

class EnhancedAGI_GUI:
    """å¢å¼ºAGIå›¾å½¢ç•Œé¢ - é›†æˆçœŸå®æ¨¡å‹"""
    
    def __init__(self, root: tk.Tk, project_root: Path):
        self.root = root
        self.root.title("H2Q-Evo å¢å¼ºé‡å­AGI v2.0 - æœ¬åœ°è¶…å¤§è§„æ¨¡ç”Ÿå‘½ä½“")
        self.root.geometry("1400x900")
        
        # åˆå§‹åŒ–AGIç³»ç»Ÿ
        self.agi_system = MultimodalAGISystem(project_root)
        
        # æ„å»ºç•Œé¢
        self.setup_enhanced_ui()
        
        # å¯åŠ¨åå°ä»»åŠ¡
        self.is_running = True
        self.start_background_tasks()
    
    def setup_enhanced_ui(self):
        """æ„å»ºå¢å¼ºç•Œé¢"""
        # ä¸»å®¹å™¨
        main_container = ttk.PanedWindow(self.root, orient=tk.HORIZONTAL)
        main_container.pack(fill=tk.BOTH, expand=True)
        
        # === å·¦ä¾§é¢æ¿ï¼šæ¨¡å‹å’Œæ§åˆ¶ ===
        left_panel = ttk.Frame(main_container, width=300)
        main_container.add(left_panel, weight=1)
        
        # æ ‡é¢˜
        title_label = ttk.Label(
            left_panel,
            text="ğŸ§¬ H2Q-Evo AGI v2.0",
            font=("Helvetica", 14, "bold")
        )
        title_label.pack(pady=10)
        
        # æ¨¡å‹åˆ—è¡¨
        models_frame = ttk.LabelFrame(left_panel, text="å·²åŠ è½½æ¨¡å‹", padding=10)
        models_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)
        
        self.models_listbox = tk.Listbox(models_frame, height=10)
        self.models_listbox.pack(fill=tk.BOTH, expand=True)
        
        # å¡«å……æ¨¡å‹åˆ—è¡¨
        for model_name in self.agi_system.model_loader.available_models.keys():
            self.models_listbox.insert(tk.END, model_name)
        
        ttk.Button(
            models_frame,
            text="æŸ¥çœ‹æ¨¡å‹è¯¦æƒ…",
            command=self.show_model_details
        ).pack(pady=5)
        
        # ç³»ç»ŸæŒ‡æ ‡
        metrics_frame = ttk.LabelFrame(left_panel, text="æ€§èƒ½æŒ‡æ ‡", padding=10)
        metrics_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)
        
        self.metrics_text = scrolledtext.ScrolledText(
            metrics_frame,
            height=8,
            font=("Courier", 9),
            state=tk.DISABLED
        )
        self.metrics_text.pack(fill=tk.BOTH, expand=True)
        
        # === ä¸­é—´é¢æ¿ï¼šäº¤äº’åŒº ===
        center_panel = ttk.Frame(main_container)
        main_container.add(center_panel, weight=3)
        
        # è¾“å…¥åŒº
        input_frame = ttk.Frame(center_panel)
        input_frame.pack(fill=tk.X, padx=10, pady=10)
        
        ttk.Label(input_frame, text="è¾“å…¥æŸ¥è¯¢:", font=("Helvetica", 11, "bold")).pack(anchor=tk.W)
        
        self.input_text = scrolledtext.ScrolledText(
            input_frame,
            height=4,
            font=("Courier", 11),
            wrap=tk.WORD
        )
        self.input_text.pack(fill=tk.X, pady=5)
        self.input_text.insert("1.0", "ä½¿ç”¨h2q_memoryæ¨¡å‹è¿›è¡Œé‡å­æ€æ¨ç†ï¼šè¯æ˜é‡å­çº ç¼ çš„æ‹“æ‰‘ä¸å˜æ€§")
        
        # æ§åˆ¶æŒ‰é’®
        control_frame = ttk.Frame(center_panel)
        control_frame.pack(fill=tk.X, padx=10)
        
        ttk.Label(control_frame, text="æ¨¡å¼:").pack(side=tk.LEFT, padx=5)
        
        self.mode_var = tk.StringVar(value="auto")
        for text, value in [("è‡ªåŠ¨", "auto"), ("é‡å­", "quantum"), 
                            ("æ•°å­¦", "mathematical"), ("æ··åˆ", "hybrid")]:
            ttk.Radiobutton(
                control_frame,
                text=text,
                variable=self.mode_var,
                value=value
            ).pack(side=tk.LEFT, padx=2)
        
        ttk.Button(
            control_frame,
            text="ğŸš€ æ‰§è¡Œæ¨ç†",
            command=self.execute_query
        ).pack(side=tk.RIGHT, padx=5)
        
        ttk.Button(
            control_frame,
            text="æ¸…ç©º",
            command=self.clear_output
        ).pack(side=tk.RIGHT)
        
        # è¾“å‡ºåŒº
        output_frame = ttk.Frame(center_panel)
        output_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        ttk.Label(output_frame, text="è¾“å‡º:", font=("Helvetica", 11, "bold")).pack(anchor=tk.W)
        
        self.output_text = scrolledtext.ScrolledText(
            output_frame,
            font=("Courier", 10),
            wrap=tk.WORD,
            state=tk.DISABLED
        )
        self.output_text.pack(fill=tk.BOTH, expand=True)
        
        # === å³ä¾§é¢æ¿ï¼šå¯è§†åŒ–å’Œæ—¥å¿— ===
        right_panel = ttk.Frame(main_container, width=300)
        main_container.add(right_panel, weight=1)
        
        # å®æ—¶æ—¥å¿—
        log_frame = ttk.LabelFrame(right_panel, text="ç³»ç»Ÿæ—¥å¿—", padding=10)
        log_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)
        
        self.log_text = scrolledtext.ScrolledText(
            log_frame,
            height=15,
            font=("Courier", 8),
            state=tk.DISABLED
        )
        self.log_text.pack(fill=tk.BOTH, expand=True)
        
        # äº¤äº’å†å²
        history_frame = ttk.LabelFrame(right_panel, text="äº¤äº’å†å²", padding=10)
        history_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)
        
        self.history_listbox = tk.Listbox(history_frame, height=10)
        self.history_listbox.pack(fill=tk.BOTH, expand=True)
        
        # åº•éƒ¨å·¥å…·æ 
        toolbar = ttk.Frame(right_panel)
        toolbar.pack(fill=tk.X, padx=10, pady=5)
        
        ttk.Button(toolbar, text="å¯¼å‡ºæ—¥å¿—", command=self.export_logs).pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar, text="ç³»ç»Ÿä¿¡æ¯", command=self.show_system_info).pack(side=tk.LEFT, padx=2)
    
    def execute_query(self):
        """æ‰§è¡ŒæŸ¥è¯¢"""
        query = self.input_text.get("1.0", tk.END).strip()
        if not query:
            messagebox.showwarning("è¾“å…¥ä¸ºç©º", "è¯·è¾“å…¥æŸ¥è¯¢å†…å®¹")
            return
        
        mode = self.mode_var.get()
        
        def compute():
            self.append_output(f"\n{'='*70}\n")
            self.append_output(f"[{time.strftime('%H:%M:%S')}] å¼€å§‹å¤„ç†æŸ¥è¯¢...\n")
            self.log(f"æŸ¥è¯¢: {query[:50]}... | æ¨¡å¼: {mode}")
            
            try:
                result = self.agi_system.process_query(query, mode)
                
                self.append_output(f"\n{result['response']}\n")
                
                if "components" in result:
                    for comp_name, comp_data in result["components"].items():
                        if "error" in comp_data:
                            self.append_output(f"\n[{comp_name}é”™è¯¯] {comp_data['error']}\n")
                
                self.append_output(f"\nå¤„ç†è€—æ—¶: {result['duration']:.4f}ç§’\n")
                self.log(f"å®Œæˆ | è€—æ—¶: {result['duration']:.3f}s")
                
                # æ›´æ–°å†å²
                self.history_listbox.insert(0, f"{time.strftime('%H:%M:%S')} - {query[:30]}...")
                
                # æ›´æ–°æŒ‡æ ‡
                self.update_metrics()
                
            except Exception as e:
                self.append_output(f"\n[é”™è¯¯] {str(e)}\n")
                self.log(f"ERROR: {str(e)}")
        
        threading.Thread(target=compute, daemon=True).start()
    
    def append_output(self, text: str):
        """è¿½åŠ è¾“å‡º"""
        self.output_text.configure(state=tk.NORMAL)
        self.output_text.insert(tk.END, text)
        self.output_text.see(tk.END)
        self.output_text.configure(state=tk.DISABLED)
    
    def clear_output(self):
        """æ¸…ç©ºè¾“å‡º"""
        self.output_text.configure(state=tk.NORMAL)
        self.output_text.delete("1.0", tk.END)
        self.output_text.configure(state=tk.DISABLED)
    
    def log(self, message: str):
        """æ·»åŠ æ—¥å¿—"""
        timestamp = time.strftime("%H:%M:%S")
        self.log_text.configure(state=tk.NORMAL)
        self.log_text.insert(tk.END, f"[{timestamp}] {message}\n")
        self.log_text.see(tk.END)
        self.log_text.configure(state=tk.DISABLED)
    
    def update_metrics(self):
        """æ›´æ–°æ€§èƒ½æŒ‡æ ‡"""
        metrics = self.agi_system.performance_metrics
        
        metrics_text = f"""æ€»äº¤äº’æ¬¡æ•°: {metrics['total_interactions']}
æˆåŠŸè¯æ˜æ•°: {metrics['successful_proofs']}
é‡å­æ¨ç†æ¬¡æ•°: {metrics['quantum_inferences']}
å¹³å‡å“åº”æ—¶é—´: {metrics['average_response_time']:.4f}s

æ¨¡å‹çŠ¶æ€:
å·²åŠ è½½: {len(self.agi_system.model_loader.loaded_models)}
å¯ç”¨: {len(self.agi_system.model_loader.available_models)}
"""
        
        self.metrics_text.configure(state=tk.NORMAL)
        self.metrics_text.delete("1.0", tk.END)
        self.metrics_text.insert("1.0", metrics_text)
        self.metrics_text.configure(state=tk.DISABLED)
    
    def show_model_details(self):
        """æ˜¾ç¤ºæ¨¡å‹è¯¦æƒ…"""
        selection = self.models_listbox.curselection()
        if not selection:
            messagebox.showinfo("æç¤º", "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæ¨¡å‹")
            return
        
        model_name = self.models_listbox.get(selection[0])
        info = self.agi_system.model_loader.get_model_info(model_name)
        
        if "error" in info:
            messagebox.showerror("é”™è¯¯", info["error"])
            return
        
        details = f"""æ¨¡å‹åç§°: {info['name']}
æ–‡ä»¶å¤§å°: {info['size_mb']:.2f} MB
å‚æ•°æ€»æ•°: {info['num_parameters']:,}
å±‚æ•°: {len(info['layers'])}

å±‚ç»“æ„:
"""
        for i, layer in enumerate(info['layers'][:10], 1):  # æ˜¾ç¤ºå‰10å±‚
            details += f"{i}. {layer['name']}: {layer['shape']} ({layer['params']:,} å‚æ•°)\n"
        
        if len(info['layers']) > 10:
            details += f"... è¿˜æœ‰ {len(info['layers']) - 10} å±‚\n"
        
        messagebox.showinfo(f"æ¨¡å‹è¯¦æƒ… - {model_name}", details)
    
    def show_system_info(self):
        """æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯"""
        status = self.agi_system.get_system_status()
        
        info = f"""H2Q-Evo å¢å¼ºAGIç³»ç»ŸçŠ¶æ€

å·²åŠ è½½æ¨¡å‹: {status['models_loaded']}
å¯ç”¨æ¨¡å‹: {len(status['available_models'])}

æ¨¡å‹åˆ—è¡¨:
"""
        for model in status['available_models']:
            info += f"  â€¢ {model}\n"
        
        info += f"""
æ€§èƒ½ç»Ÿè®¡:
  æ€»äº¤äº’: {status['performance']['total_interactions']}
  æˆåŠŸè¯æ˜: {status['performance']['successful_proofs']}
  é‡å­æ¨ç†: {status['performance']['quantum_inferences']}
  å¹³å‡å“åº”: {status['performance']['average_response_time']:.4f}s

ç³»ç»Ÿç‰¹æ€§:
  âœ“ å®Œå…¨æœ¬åœ°è¿è¡Œ
  âœ“ æ— éœ€è”ç½‘
  âœ“ å¤šæ¨¡æ€æ¨ç†
  âœ“ å®æ—¶å“åº”
"""
        
        messagebox.showinfo("ç³»ç»Ÿä¿¡æ¯", info)
    
    def export_logs(self):
        """å¯¼å‡ºæ—¥å¿—"""
        filename = filedialog.asksaveasfilename(
            defaultextension=".txt",
            filetypes=[("æ–‡æœ¬æ–‡ä»¶", "*.txt"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        
        if filename:
            try:
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write("=== H2Q-Evo AGI äº¤äº’å†å² ===\n\n")
                    for entry in self.agi_system.interaction_history:
                        f.write(f"æ—¶é—´: {time.ctime(entry['timestamp'])}\n")
                        f.write(f"æŸ¥è¯¢: {entry['query']}\n")
                        f.write(f"æ¨¡å¼: {entry['mode']}\n")
                        f.write(f"è€—æ—¶: {entry['duration']:.4f}s\n")
                        f.write(f"å“åº”: {entry.get('response', 'N/A')}\n")
                        f.write("-" * 70 + "\n\n")
                
                messagebox.showinfo("æˆåŠŸ", f"æ—¥å¿—å·²å¯¼å‡ºåˆ°:\n{filename}")
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {e}")
    
    def start_background_tasks(self):
        """å¯åŠ¨åå°ä»»åŠ¡"""
        def update_loop():
            while self.is_running:
                try:
                    self.update_metrics()
                    time.sleep(5)
                except:
                    pass
        
        threading.Thread(target=update_loop, daemon=True).start()
        self.log("ç³»ç»Ÿå¯åŠ¨å®Œæˆ")


# ==================== ä¸»ç¨‹åº ====================

def main():
    """å¯åŠ¨å¢å¼ºAGIç³»ç»Ÿ"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                   â•‘
â•‘  H2Q-Evo å¢å¼ºé‡å­AGIç”Ÿå‘½ä½“ v2.0                                   â•‘
â•‘  Enhanced Local Quantum AGI Lifeform                             â•‘
â•‘                                                                   â•‘
â•‘  âœ¨ ç‰¹æ€§:                                                         â•‘
â•‘    â€¢ é›†æˆçœŸå®è®­ç»ƒæ¨¡å‹æƒé‡                                          â•‘
â•‘    â€¢ å®Œå…¨æœ¬åœ°è¿è¡Œï¼Œé›¶ç½‘ç»œä¾èµ–                                      â•‘
â•‘    â€¢ å¤šæ¨¡æ€æ¨ç†ï¼šé‡å­+æ•°å­¦+ç‰©ç†                                    â•‘
â•‘    â€¢ é«˜çº§å®šç†è¯æ˜èƒ½åŠ›                                             â•‘
â•‘    â€¢ å®æ—¶æ€§èƒ½ç›‘æ§                                                 â•‘
â•‘    â€¢ äº¤äº’å¼å›¾å½¢ç•Œé¢                                               â•‘
â•‘                                                                   â•‘
â•‘  ğŸ“¦ å·²åŠ è½½æ¨¡å‹:                                                    â•‘
â•‘    h2q_memory, h2q_model_hierarchy, h2q_model_decoder            â•‘
â•‘    h2q_full_l0, h2q_full_l1, h2q_distilled_l0 ...               â•‘
â•‘                                                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    
    project_root = Path(__file__).parent
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_dir = project_root / "h2q_project"
    if not model_dir.exists():
        print(f"âš ï¸  è­¦å‘Š: æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_dir}")
        print("è¯·ç¡®ä¿åœ¨H2Q-Evoé¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤ç¨‹åº")
    else:
        model_files = list(model_dir.glob("*.pth")) + list(model_dir.glob("*.pt"))
        print(f"âœ“ å‘ç° {len(model_files)} ä¸ªæ¨¡å‹æ–‡ä»¶")
    
    # åˆ›å»ºGUI
    root = tk.Tk()
    app = EnhancedAGI_GUI(root, project_root)
    
    # å¯åŠ¨
    try:
        root.mainloop()
    except KeyboardInterrupt:
        print("\næ­£åœ¨å…³é—­...")
        app.is_running = False
    
    print("H2Q-Evo å¢å¼ºAGIå·²å®‰å…¨é€€å‡ºã€‚")


if __name__ == "__main__":
    main()
