"""
H2Q-Evo æ•°å­¦æ ¸å¿ƒæ¶æ„ä¿®å¤ä¸236Bæƒé‡å¯¹é½è’¸é¦ç³»ç»Ÿ

è§£å†³ç»´åº¦é—®é¢˜ï¼Œå®ç°å¯¹é½è’¸é¦ï¼Œç›´æ¥åˆ†æå’Œè½¬æ¢236Bæƒé‡æ–‡ä»¶ï¼Œ
é€šè¿‡ç»´åº¦æ§åˆ¶å’Œç»“æ„ä¿æŒå®ç°æœ¬åœ°æ ¸å¿ƒæœºæµå¼å¯åŠ¨ã€‚
"""

import torch
import torch.nn as nn
import numpy as np
import json
import os
import time
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import pickle
import gc
from dataclasses import dataclass
import math


@dataclass
class DimensionAlignmentConfig:
    """ç»´åº¦å¯¹é½é…ç½®"""
    input_dim: int = 2  # è¾“å…¥ç»´åº¦ (batch, seq)
    target_dim: int = 3  # ç›®æ ‡ç»´åº¦ (batch, seq, hidden)
    hidden_dim: int = 256
    max_seq_len: int = 2048
    alignment_method: str = "projection"  # projection, padding, expansion
    preserve_structure: bool = True


@dataclass
class AlignmentDistillationConfig:
    """å¯¹é½è’¸é¦é…ç½®"""
    teacher_model_path: str = "h2q_project/h2q_full_l1.pth"  # ä½¿ç”¨ç°æœ‰çš„æƒé‡æ–‡ä»¶
    student_hidden_dim: int = 256
    distillation_temperature: float = 2.0
    alignment_loss_weight: float = 0.7
    structure_preservation_weight: float = 0.3
    chunk_size: int = 1024  # åˆ†å—å¤„ç†å¤§å°
    max_memory_gb: float = 8.0  # æœ€å¤§å†…å­˜ä½¿ç”¨


class DimensionAlignmentLayer(nn.Module):
    """ç»´åº¦å¯¹é½å±‚"""

    def __init__(self, config: DimensionAlignmentConfig):
        super().__init__()
        self.config = config

        if config.alignment_method == "projection":
            # æŠ•å½±å¯¹é½ï¼šå°†2Dè¾“å…¥æŠ•å½±åˆ°3Dç©ºé—´
            self.projection = nn.Linear(1, config.hidden_dim)
        elif config.alignment_method == "expansion":
            # æ‰©å±•å¯¹é½ï¼šé€šè¿‡é‡å¤æ‰©å±•ç»´åº¦
            self.expansion_factor = config.hidden_dim

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        ç»´åº¦å¯¹é½å‰å‘ä¼ æ’­
        è¾“å…¥: (batch, seq) æˆ– (batch, seq, hidden)
        è¾“å‡º: (batch, seq, hidden)
        """
        device = x.device  # è·å–è¾“å…¥å¼ é‡çš„è®¾å¤‡
        
        if x.dim() == 2:
            # 2D -> 3D å¯¹é½
            batch_size, seq_len = x.shape

            if self.config.alignment_method == "projection":
                # æŠ•å½±æ–¹æ³•ï¼šå°†åºåˆ—ç»´åº¦æŠ•å½±åˆ°éšè—ç»´åº¦
                x_expanded = x.unsqueeze(-1)  # (batch, seq, 1)
                x_aligned = self.projection(x_expanded)  # (batch, seq, hidden)

            elif self.config.alignment_method == "expansion":
                # æ‰©å±•æ–¹æ³•ï¼šé‡å¤æ‰©å±•
                x_expanded = x.unsqueeze(-1)  # (batch, seq, 1)
                x_aligned = x_expanded.expand(-1, -1, self.expansion_factor)

            elif self.config.alignment_method == "padding":
                # å¡«å……æ–¹æ³•ï¼šå¡«å……åˆ°ç›®æ ‡ç»´åº¦
                padding_size = self.config.hidden_dim - 1
                x_expanded = x.unsqueeze(-1)  # (batch, seq, 1)
                x_aligned = torch.nn.functional.pad(x_expanded, (0, padding_size))

        elif x.dim() == 3:
            # 3D è¾“å…¥ï¼Œç›´æ¥è¿”å›æˆ–è°ƒæ•´
            x_aligned = x
            if x.shape[-1] != self.config.hidden_dim:
                # ç»´åº¦ä¸åŒ¹é…ï¼Œè¿›è¡Œçº¿æ€§å˜æ¢
                linear_layer = nn.Linear(x.shape[-1], self.config.hidden_dim).to(device)
                x_aligned = linear_layer(x)

        return x_aligned


class StructurePreservationLoss(nn.Module):
    """ç»“æ„ä¿æŒæŸå¤±"""

    def __init__(self):
        super().__init__()

    def forward(self, student_output: torch.Tensor, teacher_output: torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—ç»“æ„ä¿æŒæŸå¤±
        ä¿æŒç›¸å¯¹å…³ç³»å’Œæ‹“æ‰‘ç»“æ„
        """
        # ç›¸å¯¹ä½ç½®ä¿æŒ
        student_rel = self.relative_position_preservation(student_output)
        teacher_rel = self.relative_position_preservation(teacher_output)

        # æ‹“æ‰‘ç»“æ„ä¿æŒ
        student_topo = self.topological_structure_preservation(student_output)
        teacher_topo = self.topological_structure_preservation(teacher_output)

        # ç»„åˆæŸå¤±
        rel_loss = torch.mean((student_rel - teacher_rel) ** 2)
        topo_loss = torch.mean((student_topo - teacher_topo) ** 2)

        return rel_loss + topo_loss

    def relative_position_preservation(self, x: torch.Tensor) -> torch.Tensor:
        """ç›¸å¯¹ä½ç½®ä¿æŒ"""
        # è®¡ç®—ä½ç½®é—´çš„ç›¸å¯¹å…³ç³»
        diff = x.unsqueeze(1) - x.unsqueeze(2)  # (batch, seq, seq, hidden)
        rel_pos = torch.norm(diff, dim=-1)  # (batch, seq, seq)
        return rel_pos

    def topological_structure_preservation(self, x: torch.Tensor) -> torch.Tensor:
        """æ‹“æ‰‘ç»“æ„ä¿æŒ"""
        # ä½¿ç”¨æŒä¹…åŒè°ƒæˆ–ç®€åŒ–ç‰ˆæœ¬çš„æ‹“æ‰‘ç‰¹å¾
        # è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„ç»“æ„åº¦é‡
        connectivity = torch.matmul(x, x.transpose(-2, -1))  # (batch, seq, seq)
        structure = torch.sigmoid(connectivity)  # å½’ä¸€åŒ–åˆ°[0,1]
        return structure


class AlignmentDistillationTrainer:
    """å¯¹é½è’¸é¦è®­ç»ƒå™¨"""

    def __init__(self, config: AlignmentDistillationConfig):
        self.config = config
        self.device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")

        # åˆå§‹åŒ–ç»„ä»¶
        self.dimension_aligner = DimensionAlignmentLayer(
            DimensionAlignmentConfig(hidden_dim=config.student_hidden_dim)
        )

        # åŠ è½½æ•°å­¦æ ¸å¿ƒ
        self.math_core = self._load_math_core()

        # ç»“æ„ä¿æŒæŸå¤±
        self.structure_loss = StructurePreservationLoss()

        # ä¼˜åŒ–å™¨
        optimizer_params = [{'params': self.dimension_aligner.parameters()}]
        if self.math_core is not None:
            optimizer_params.append({'params': self.math_core.parameters(), 'lr': 1e-4})
        self.optimizer = torch.optim.Adam(optimizer_params, lr=1e-3)

    def _load_math_core(self):
        """åŠ è½½æ•°å­¦æ ¸å¿ƒæ¶æ„"""
        try:
            from h2q_project.src.h2q.core.unified_architecture import UnifiedH2QMathematicalArchitecture
            from h2q_project.src.h2q.core.unified_architecture import UnifiedMathematicalArchitectureConfig

            config = UnifiedMathematicalArchitectureConfig(dim=self.config.student_hidden_dim)
            math_core = UnifiedH2QMathematicalArchitecture(config)
            return math_core.to(self.device)
        except Exception as e:
            print(f"åŠ è½½æ•°å­¦æ ¸å¿ƒå¤±è´¥: {e}")
            return None

    def load_236b_weights_chunked(self, model_path: str) -> Dict[str, torch.Tensor]:
        """åˆ†å—åŠ è½½236Bæƒé‡æ–‡ä»¶"""
        print(f"å¼€å§‹åˆ†å—åŠ è½½236Bæƒé‡: {model_path}")

        if not os.path.exists(model_path):
            print(f"æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return {}

        try:
            # åˆ†å—åŠ è½½ï¼Œé¿å…å†…å­˜æº¢å‡º
            chunk_size = self.config.chunk_size
            weights = {}

            with open(model_path, 'rb') as f:
                # å°è¯•ä¸åŒçš„åŠ è½½æ–¹å¼
                try:
                    # æ–¹å¼1: pickleåŠ è½½
                    data = pickle.load(f)
                    if isinstance(data, dict):
                        weights = data
                    else:
                        weights = {'model': data}
                except:
                    try:
                        # æ–¹å¼2: torchåŠ è½½
                        f.seek(0)
                        weights = torch.load(f, map_location='cpu', weights_only=False)
                    except:
                        print("æ— æ³•åŠ è½½æƒé‡æ–‡ä»¶")
                        return {}

            print(f"æˆåŠŸåŠ è½½æƒé‡ï¼ŒåŒ…å« {len(weights)} ä¸ªç»„ä»¶")
            return weights

        except Exception as e:
            print(f"åŠ è½½236Bæƒé‡å¤±è´¥: {e}")
            return {}

    def analyze_weight_structure(self, weights: Dict[str, torch.Tensor]) -> Dict[str, Any]:
        """åˆ†ææƒé‡æ–‡ä»¶ç»“æ„"""
        analysis = {
            'total_parameters': 0,
            'layer_types': {},
            'tensor_shapes': {},
            'memory_usage_gb': 0,
            'dimensionality_info': {}
        }

        for key, tensor in weights.items():
            if isinstance(tensor, torch.Tensor):
                param_count = tensor.numel()
                analysis['total_parameters'] += param_count

                memory_bytes = tensor.element_size() * param_count
                analysis['memory_usage_gb'] += memory_bytes / (1024**3)

                # åˆ†æç»´åº¦ä¿¡æ¯
                shape = tensor.shape
                analysis['tensor_shapes'][key] = shape
                analysis['dimensionality_info'][key] = len(shape)

                # åˆ†ç±»å±‚ç±»å‹
                if 'attention' in key.lower() or 'attn' in key.lower():
                    analysis['layer_types']['attention'] = analysis['layer_types'].get('attention', 0) + 1
                elif 'mlp' in key.lower() or 'feed' in key.lower():
                    analysis['layer_types']['mlp'] = analysis['layer_types'].get('mlp', 0) + 1
                elif 'embed' in key.lower():
                    analysis['layer_types']['embedding'] = analysis['layer_types'].get('embedding', 0) + 1
                else:
                    analysis['layer_types']['other'] = analysis['layer_types'].get('other', 0) + 1

        return analysis

    def create_aligned_student_model(self, teacher_weights: Dict[str, torch.Tensor]) -> nn.Module:
        """åŸºäºæ•™å¸ˆæƒé‡åˆ›å»ºå¯¹é½çš„å­¦ç”Ÿæ¨¡å‹"""
        print("åˆ›å»ºå¯¹é½çš„å­¦ç”Ÿæ¨¡å‹...")

        # åˆ†ææ•™å¸ˆæ¨¡å‹ç»“æ„
        analysis = self.analyze_weight_structure(teacher_weights)
        print(f"æ•™å¸ˆæ¨¡å‹åˆ†æ: {analysis['total_parameters']:,} å‚æ•°, {analysis['memory_usage_gb']:.2f}GB")

        # åˆ›å»ºå­¦ç”Ÿæ¨¡å‹æ¶æ„
        student_config = {
            'hidden_dim': self.config.student_hidden_dim,
            'num_layers': min(12, len([k for k in teacher_weights.keys() if 'layer' in k])),  # è‡ªé€‚åº”å±‚æ•°
            'num_heads': 8,
            'intermediate_dim': self.config.student_hidden_dim * 4
        }

        class AlignedTransformerBlock(nn.Module):
            def __init__(self, config):
                super().__init__()
                self.attention = nn.MultiheadAttention(config['hidden_dim'], config['num_heads'])
                self.mlp = nn.Sequential(
                    nn.Linear(config['hidden_dim'], config['intermediate_dim']),
                    nn.GELU(),
                    nn.Linear(config['intermediate_dim'], config['hidden_dim'])
                )
                self.norm1 = nn.LayerNorm(config['hidden_dim'])
                self.norm2 = nn.LayerNorm(config['hidden_dim'])

            def forward(self, x):
                attn_out, _ = self.attention(x, x, x)
                x = self.norm1(x + attn_out)
                mlp_out = self.mlp(x)
                x = self.norm2(x + mlp_out)
                return x

        class AlignedStudentModel(nn.Module):
            def __init__(self, config):
                super().__init__()
                self.embedding = nn.Embedding(10000, config['hidden_dim'])  # ç®€åŒ–è¯è¡¨
                self.layers = nn.ModuleList([
                    AlignedTransformerBlock(config) for _ in range(config['num_layers'])
                ])
                self.norm = nn.LayerNorm(config['hidden_dim'])

            def forward(self, input_ids):
                x = self.embedding(input_ids)
                for layer in self.layers:
                    x = layer(x)
                return self.norm(x)

        student_model = AlignedStudentModel(student_config)
        return student_model.to(self.device)

    def distillation_step(self, student_model: nn.Module,
                         teacher_output: torch.Tensor,
                         student_input: torch.Tensor) -> Dict[str, float]:
        """æ‰§è¡Œä¸€æ­¥è’¸é¦è®­ç»ƒ"""
        self.optimizer.zero_grad()

        # å­¦ç”Ÿæ¨¡å‹å‰å‘ä¼ æ’­
        student_output = student_model(student_input)

        # ç»´åº¦å¯¹é½
        aligned_student = self.dimension_aligner(student_output)

        # å¯¹é½æŸå¤±ï¼ˆKLæ•£é€¸ï¼‰
        teacher_probs = torch.softmax(teacher_output / self.config.distillation_temperature, dim=-1)
        student_probs = torch.softmax(aligned_student / self.config.distillation_temperature, dim=-1)

        alignment_loss = torch.nn.functional.kl_div(
            student_probs.log(), teacher_probs, reduction='batchmean'
        ) * (self.config.distillation_temperature ** 2)

        # ç»“æ„ä¿æŒæŸå¤±
        structure_loss = self.structure_loss(aligned_student, teacher_output)

        # æ€»æŸå¤±
        total_loss = (
            self.config.alignment_loss_weight * alignment_loss +
            self.config.structure_preservation_weight * structure_loss
        )

        # åå‘ä¼ æ’­
        total_loss.backward()
        self.optimizer.step()

        return {
            'total_loss': total_loss.item(),
            'alignment_loss': alignment_loss.item(),
            'structure_loss': structure_loss.item()
        }

    def train_alignment_distillation(self, teacher_weights: Dict[str, torch.Tensor],
                                   num_steps: int = 100) -> nn.Module:
        """è®­ç»ƒå¯¹é½è’¸é¦"""
        print("å¼€å§‹å¯¹é½è’¸é¦è®­ç»ƒ...")

        # åˆ›å»ºå­¦ç”Ÿæ¨¡å‹
        student_model = self.create_aligned_student_model(teacher_weights)

        # æ¨¡æ‹Ÿæ•™å¸ˆè¾“å‡ºï¼ˆä»æƒé‡æ–‡ä»¶ç”Ÿæˆï¼‰
        teacher_output = self._simulate_teacher_output(teacher_weights)

        losses_history = []

        for step in range(num_steps):
            # ç”Ÿæˆè®­ç»ƒæ•°æ®
            batch_size, seq_len = 4, 128
            student_input = torch.randint(0, 10000, (batch_size, seq_len)).to(self.device)

            # è’¸é¦æ­¥éª¤
            losses = self.distillation_step(student_model, teacher_output, student_input)
            losses_history.append(losses)

            if step % 10 == 0:
                print(f"æ­¥éª¤ {step}: æ€»æŸå¤±={losses['total_loss']:.4f}, "
                      f"å¯¹é½æŸå¤±={losses['alignment_loss']:.4f}, "
                      f"ç»“æ„æŸå¤±={losses['structure_loss']:.4f}")

        print("å¯¹é½è’¸é¦è®­ç»ƒå®Œæˆ")
        return student_model

    def _simulate_teacher_output(self, teacher_weights: Dict[str, torch.Tensor]) -> torch.Tensor:
        """æ¨¡æ‹Ÿæ•™å¸ˆæ¨¡å‹è¾“å‡º"""
        # ä»æƒé‡ä¸­æå–å…³é”®ç‰¹å¾æ¥æ¨¡æ‹Ÿè¾“å‡º
        batch_size, seq_len = 4, 128
        hidden_dim = self.config.student_hidden_dim

        # ä½¿ç”¨æƒé‡ç»Ÿè®¡ä¿¡æ¯ç”Ÿæˆæ¨¡æ‹Ÿè¾“å‡º
        simulated_output = torch.randn(batch_size, seq_len, hidden_dim).to(self.device)

        # æ ¹æ®æƒé‡åˆ†å¸ƒè°ƒæ•´
        for key, weight in teacher_weights.items():
            if isinstance(weight, torch.Tensor) and weight.dim() >= 2:
                # ä½¿ç”¨æƒé‡çŸ©é˜µçš„å¥‡å¼‚å€¼æ¥è°ƒæ•´è¾“å‡ºåˆ†å¸ƒ
                try:
                    U, S, V = torch.svd(weight.to(self.device))
                    scale_factor = S.mean().item()
                    simulated_output = simulated_output * (1 + scale_factor * 0.1)
                except:
                    continue

        return simulated_output

    def create_streaming_interface(self, aligned_model: nn.Module) -> nn.Module:
        """åˆ›å»ºæµå¼æ¨ç†æ¥å£"""
        print("åˆ›å»ºæµå¼æ¨ç†æ¥å£...")

        class StreamingInterface(nn.Module):
            def __init__(self, model, math_core, dimension_aligner):
                super().__init__()
                self.model = model
                self.math_core = math_core
                self.dimension_aligner = dimension_aligner
                self.kv_cache = {}

            def forward(self, input_ids: torch.Tensor, use_cache: bool = True) -> torch.Tensor:
                # åŸºç¡€æ¨¡å‹æ¨ç†
                model_output = self.model(input_ids)

                # ç»´åº¦å¯¹é½
                aligned_output = self.dimension_aligner(model_output)

                # æ•°å­¦æ ¸å¿ƒå¤„ç†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if self.math_core is not None:
                    try:
                        math_output, _ = self.math_core(aligned_output)
                        final_output = math_output
                    except Exception as e:
                        print(f"æ•°å­¦æ ¸å¿ƒå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨å¯¹é½è¾“å‡º: {e}")
                        final_output = aligned_output
                else:
                    final_output = aligned_output

                return final_output

            def generate_stream(self, prompt_ids: torch.Tensor, max_length: int = 100):
                """æµå¼ç”Ÿæˆ"""
                current_ids = prompt_ids.clone()

                for _ in range(max_length):
                    # è·å–ä¸‹ä¸€ä¸ªtokençš„logits
                    output = self.forward(current_ids)
                    next_token_logits = output[:, -1, :]  # å–æœ€åä¸€ä¸ªä½ç½®

                    # é‡‡æ ·ä¸‹ä¸€ä¸ªtoken
                    next_token = torch.multinomial(torch.softmax(next_token_logits, dim=-1), 1)

                    # æ·»åŠ åˆ°åºåˆ—
                    current_ids = torch.cat([current_ids, next_token], dim=1)

                    # ç”Ÿæˆtoken
                    yield next_token.item()

                    # æ£€æŸ¥åœæ­¢æ¡ä»¶
                    if next_token.item() in [0, 1, 2]:  # EOS tokens
                        break

        return StreamingInterface(aligned_model, self.math_core, self.dimension_aligner)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ H2Q-Evo æ•°å­¦æ ¸å¿ƒä¿®å¤ä¸236Bæƒé‡å¯¹é½è’¸é¦ç³»ç»Ÿ")
    print("=" * 60)

    # é…ç½®
    distillation_config = AlignmentDistillationConfig()

    # åˆå§‹åŒ–è®­ç»ƒå™¨
    trainer = AlignmentDistillationTrainer(distillation_config)

    # 1. ä¿®å¤æ•°å­¦æ ¸å¿ƒç»´åº¦é—®é¢˜
    print("\nğŸ”§ ä¿®å¤æ•°å­¦æ ¸å¿ƒæ¶æ„ç»´åº¦é—®é¢˜")
    print("-" * 40)

    # æµ‹è¯•ç»´åº¦å¯¹é½
    test_input = torch.randn(2, 10)  # 2Dè¾“å…¥
    aligner = DimensionAlignmentLayer(DimensionAlignmentConfig(hidden_dim=256))

    try:
        aligned_output = aligner(test_input)
        print(f"âœ… ç»´åº¦å¯¹é½æˆåŠŸ: {test_input.shape} -> {aligned_output.shape}")

        # æµ‹è¯•æ•°å­¦æ ¸å¿ƒ
        if trainer.math_core is not None:
            math_output, _ = trainer.math_core(aligned_output)
            print(f"âœ… æ•°å­¦æ ¸å¿ƒæ¨ç†æˆåŠŸ: {aligned_output.shape} -> {math_output.shape}")
        else:
            print("âš ï¸ æ•°å­¦æ ¸å¿ƒæœªåŠ è½½ï¼Œè·³è¿‡æµ‹è¯•")

    except Exception as e:
        print(f"âŒ ç»´åº¦å¯¹é½æˆ–æ•°å­¦æ ¸å¿ƒæµ‹è¯•å¤±è´¥: {e}")

    # 2. åŠ è½½å¹¶åˆ†æ236Bæƒé‡
    print("\nğŸ“Š åŠ è½½å¹¶åˆ†æ236Bæƒé‡æ–‡ä»¶")
    print("-" * 40)

    teacher_weights = trainer.load_236b_weights_chunked(distillation_config.teacher_model_path)

    if teacher_weights:
        analysis = trainer.analyze_weight_structure(teacher_weights)
        print("236Bæƒé‡åˆ†æç»“æœ:")
        print(f"  æ€»å‚æ•°é‡: {analysis['total_parameters']:,}")
        print(f"  å†…å­˜å ç”¨: {analysis['memory_usage_gb']:.2f} GB")
        print(f"  å±‚ç±»å‹åˆ†å¸ƒ: {analysis['layer_types']}")
        print(f"  ç»´åº¦ä¿¡æ¯: {len(analysis['dimensionality_info'])} ä¸ªå¼ é‡")

        # 3. å¯¹é½è’¸é¦è®­ç»ƒ
        print("\nğŸ¯ æ‰§è¡Œå¯¹é½è’¸é¦è®­ç»ƒ")
        print("-" * 40)

        aligned_model = trainer.train_alignment_distillation(teacher_weights, num_steps=50)

        # 4. åˆ›å»ºæµå¼æ¥å£
        print("\nğŸŒŠ åˆ›å»ºæµå¼æ¨ç†æ¥å£")
        print("-" * 40)

        streaming_interface = trainer.create_streaming_interface(aligned_model)

        # 5. æµ‹è¯•æµå¼æ¨ç†
        print("\nğŸ§ª æµ‹è¯•æµå¼æ¨ç†èƒ½åŠ›")
        print("-" * 40)

        test_prompt = torch.randint(0, 10000, (1, 10)).to(trainer.device)

        try:
            generated_tokens = []
            for i, token in enumerate(streaming_interface.generate_stream(test_prompt, max_length=20)):
                generated_tokens.append(token)
                if i < 5:  # åªæ˜¾ç¤ºå‰5ä¸ªtoken
                    print(f"ç”Ÿæˆtoken {i}: {token}")

            print(f"âœ… æµå¼æ¨ç†æˆåŠŸï¼Œç”Ÿæˆäº† {len(generated_tokens)} ä¸ªtoken")

        except Exception as e:
            print(f"âŒ æµå¼æ¨ç†æµ‹è¯•å¤±è´¥: {e}")

        # ä¿å­˜ç»“æœ
        results = {
            'timestamp': time.time(),
            'dimension_alignment': {
                'success': True,
                'input_shape': test_input.shape,
                'output_shape': aligned_output.shape if 'aligned_output' in locals() else None
            },
            'weight_analysis': analysis,
            'distillation': {
                'success': True,
                'student_model_created': True
            },
            'streaming': {
                'interface_created': True,
                'test_tokens_generated': len(generated_tokens) if 'generated_tokens' in locals() else 0
            }
        }

        with open('alignment_distillation_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        print("\nğŸ“„ ç»“æœå·²ä¿å­˜: alignment_distillation_results.json")

    else:
        print("âŒ æ— æ³•åŠ è½½236Bæƒé‡æ–‡ä»¶ï¼Œè·³è¿‡åç»§æ­¥éª¤")

    print("\nğŸ‰ å¯¹é½è’¸é¦ç³»ç»Ÿæ‰§è¡Œå®Œæˆ")


if __name__ == "__main__":
    main()