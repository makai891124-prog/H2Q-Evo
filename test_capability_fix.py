#!/usr/bin/env python3
"""
å®Œæ•´çš„AGIèƒ½åŠ›æµ‹è¯•ä¸ç›‘ç£å­¦ä¹ éªŒè¯
åŒ…æ‹¬:
- LLMæ ‡å‡†åŸºå‡†æµ‹è¯•
- è½¨è¿¹æ§åˆ¶ä¸æµå½¢ç¨³å®šæ€§åˆ†æ
- äº¤å‰éªŒè¯
- é”™è¯¯ä¿®æ­£
- è‡ªåŠ¨æµ‹è¯•å‘ç°
"""

import sys
sys.path.insert(0, '/Users/imymm/H2Q-Evo')

import numpy as np


def test_supervised_learning():
    """æµ‹è¯•ç›‘ç£å­¦ä¹ ç³»ç»Ÿ."""
    print("=" * 70)
    print("ğŸ“ ç›‘ç£å­¦ä¹ ç³»ç»Ÿæµ‹è¯•")
    print("=" * 70)
    
    from h2q_project.h2q.agi.supervised_learning import (
        SupervisedLearningMonitor,
        TrajectoryController,
        LeanVerifier,
        CrossValidator,
        ErrorCorrector,
        AutoTestDiscovery
    )
    
    # 1. æµ‹è¯•è½¨è¿¹æ§åˆ¶å™¨
    print("\nğŸ“Š 1. è½¨è¿¹æ§åˆ¶ä¸æµå½¢ç¨³å®šæ€§åˆ†æ")
    print("-" * 50)
    
    controller = TrajectoryController()
    
    # æ¨¡æ‹Ÿå­¦ä¹ è¿‡ç¨‹
    for epoch in range(20):
        loss = 1.0 / (1 + epoch * 0.1) + np.random.uniform(-0.05, 0.05)
        accuracy = 1 - loss + np.random.uniform(-0.02, 0.02)
        gradient_norm = np.random.uniform(0.5, 2.0) if epoch < 15 else np.random.uniform(0.01, 0.1)
        
        point = controller.record_point(
            epoch=epoch,
            loss=loss,
            accuracy=accuracy,
            gradient_norm=gradient_norm,
            learning_rate=0.001
        )
    
    status = controller.get_status_report()
    print(f"  æ€»epochs: {status['total_epochs']}")
    print(f"  å½“å‰æŸå¤±: {status['current_loss']:.4f}")
    print(f"  æµå½¢ç¨³å®šæ€§: {status['stability_index']:.3f}")
    print(f"  æµå½¢æ›²ç‡: {status['manifold_curvature']:.4f}")
    print(f"  æŸå¤±è¶‹åŠ¿: {status['loss_trend']}")
    print(f"  æ£€æµ‹åˆ°å¼‚å¸¸: {status['anomaly_count']}ä¸ª")
    print(f"  å»ºè®®å­¦ä¹ ç‡: {status['suggested_lr']:.6f}")
    
    # 2. æµ‹è¯•äº¤å‰éªŒè¯
    print("\nğŸ”„ 2. å¤šæºäº¤å‰éªŒè¯")
    print("-" * 50)
    
    validator = CrossValidator()
    
    test_questions = [
        ("2 + 3 * 4 = ?", 14, "math"),
        ("ç§¦å§‹çš‡ç»Ÿä¸€å…­å›½æ˜¯å“ªå¹´?", "å…¬å…ƒå‰221å¹´", "chinese"),
        ("What is 15 - 6?", 9, "arithmetic")
    ]
    
    for q, ans, cat in test_questions:
        results = validator.cross_validate(q, ans, cat)
        is_valid, confidence = validator.compute_consensus(results)
        print(f"  é—®é¢˜: {q[:30]}...")
        print(f"  éªŒè¯ç»“æœ: {'âœ… æœ‰æ•ˆ' if is_valid else 'âŒ æ— æ•ˆ'}, ç½®ä¿¡åº¦: {confidence:.2f}")
    
    # 3. æµ‹è¯•é”™è¯¯ä¿®æ­£
    print("\nğŸ”§ 3. é”™è¯¯ä¿®æ­£ç³»ç»Ÿ")
    print("-" * 50)
    
    corrector = ErrorCorrector()
    
    error_cases = [
        ("2 + 3 * 4 = ?", 11, 14, "math"),  # è¿ç®—é¡ºåºé”™è¯¯
        ("What is 100 - 25?", 65, 75, "arithmetic"),  # è®¡ç®—é”™è¯¯
    ]
    
    for q, wrong, correct, cat in error_cases:
        analysis = corrector.analyze_and_correct(q, wrong, correct, cat)
        print(f"  é—®é¢˜: {q}")
        print(f"  é”™è¯¯ç­”æ¡ˆ: {wrong}, æ­£ç¡®ç­”æ¡ˆ: {correct}")
        print(f"  é”™è¯¯ç±»å‹: {analysis['error_type']}")
        print(f"  ä¿®æ­£ç­–ç•¥: {analysis['correction_strategy']['type']}")
        print(f"  å»ºè®®: {analysis['correction_strategy'].get('practice_recommendation', 'N/A')}")
        print()
    
    # 4. æµ‹è¯•LeanéªŒè¯å™¨
    print("ğŸ”¬ 4. å½¢å¼åŒ–éªŒè¯ (Lean4)")
    print("-" * 50)
    
    verifier = LeanVerifier()
    print(f"  Lean4å¯ç”¨: {'æ˜¯' if verifier.lean_available else 'å¦ (ä½¿ç”¨Pythonå›é€€)'}")
    
    # æµ‹è¯•ç®—æœ¯éªŒè¯
    result = verifier.verify_arithmetic("2 + 3 * 4", 14)
    print(f"  éªŒè¯ 2 + 3 * 4 = 14: {'âœ…' if result.is_valid else 'âŒ'}")
    print(f"  éªŒè¯æ–¹æ³•: {result.method.value}")
    print(f"  ç½®ä¿¡åº¦: {result.confidence}")
    
    # 5. æµ‹è¯•è‡ªåŠ¨æµ‹è¯•å‘ç°
    print("\nğŸ” 5. è‡ªåŠ¨æµ‹è¯•å‘ç°")
    print("-" * 50)
    
    discovery = AutoTestDiscovery()
    
    # æ¨¡æ‹Ÿå½“å‰èƒ½åŠ›
    current_caps = {
        "math": 100.0,
        "logic": 100.0,
        "pattern": 100.0,
        "memory": 85.0
    }
    
    new_tests = discovery.discover_new_tests(current_caps)
    print(f"  å‘ç° {len(new_tests)} ä¸ªæ–°æµ‹è¯•:")
    for test in new_tests[:5]:
        source = test.get('source', 'unknown')
        name = test.get('name', test.get('dataset', test.get('repo', 'Unknown')))
        area = test.get('area', 'general')
        difficulty = test.get('difficulty', 'standard')
        print(f"    [{source}] {name}: {area} ({difficulty})")
    
    return True


def test_llm_benchmarks():
    """æµ‹è¯•LLMæ ‡å‡†åŸºå‡†æµ‹è¯•."""
    print("\n" + "=" * 70)
    print("ğŸ¯ LLMæ ‡å‡†åŸºå‡†æµ‹è¯•")
    print("=" * 70)
    
    from h2q_project.h2q.agi.llm_benchmarks import LLMBenchmarkSuite, BenchmarkType
    
    suite = LLMBenchmarkSuite()
    
    print("\nå¯ç”¨åŸºå‡†æµ‹è¯•:")
    for bt in BenchmarkType:
        info = suite.get_benchmark_info(bt)
        if info['total_questions'] > 0:
            print(f"  â€¢ {bt.value.upper()}: {info['total_questions']}é¢˜")
    
    # è¿è¡Œæ‰€æœ‰åŸºå‡†
    print("\nğŸ“Š è¿è¡ŒåŸºå‡†æµ‹è¯•:")
    print("-" * 50)
    
    results = suite.run_all_benchmarks(questions_per_benchmark=6)
    
    for name, data in results["benchmarks"].items():
        print(f"\n  {name.upper()}:")
        print(f"    å‡†ç¡®ç‡: {data['accuracy']:.1f}%")
        print(f"    æ­£ç¡®æ•°: {data['correct']}/{data['total']}")
    
    print("\n" + "=" * 50)
    print(f"ğŸ“ˆ ç»¼åˆå¾—åˆ†: {results['overall_score']:.1f}%")
    print(f"ğŸ“‹ ç­‰çº§: {results['grade']}")
    print("=" * 50)
    
    return results


def test_full_evaluation():
    """æµ‹è¯•å®Œæ•´è¯„ä¼°."""
    print("\n" + "=" * 70)
    print("ğŸ§ª å®Œæ•´èƒ½åŠ›è¯„ä¼° (åŸºç¡€ + LLMåŸºå‡†)")
    print("=" * 70)
    
    from h2q_project.h2q.agi.evolution_24h import CapabilityTester
    
    tester = CapabilityTester()
    results = tester.run_full_evaluation()
    
    return results


def main():
    print("=" * 70)
    print("ğŸš€ H2Q-Evo AGI èƒ½åŠ›æµ‹è¯•ä¸ç›‘ç£å­¦ä¹ éªŒè¯")
    print("=" * 70)
    
    # 1. ç›‘ç£å­¦ä¹ ç³»ç»Ÿæµ‹è¯•
    test_supervised_learning()
    
    # 2. LLMåŸºå‡†æµ‹è¯•
    llm_results = test_llm_benchmarks()
    
    # 3. å®Œæ•´è¯„ä¼°
    full_results = test_full_evaluation()
    
    # ä¿å­˜ç»“æœ
    import json
    results_summary = {
        "timestamp": str(np.datetime64('now')),
        "llm_benchmark_score": llm_results['overall_score'],
        "full_evaluation_score": full_results['combined_score'],
        "grade": full_results['grade']
    }
    
    with open('/Users/imymm/H2Q-Evo/test_results.json', 'w', encoding='utf-8') as f:
        json.dump(results_summary, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 70)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“ ç»“æœå·²ä¿å­˜è‡³: test_results.json")
    print("=" * 70)


if __name__ == "__main__":
    main()
