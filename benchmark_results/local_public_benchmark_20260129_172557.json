{
  "timestamp": "2026-01-29T17:25:57.458399",
  "benchmark": "public_standard_benchmarks",
  "local_server_url": "http://127.0.0.1:8000/chat",
  "anti_cheat": {
    "no_answer_key": true,
    "no_dataset_leak": true,
    "note": "仅提供问题与选项，不提供正确答案"
  },
  "results": {
    "results": {
      "mmlu": {
        "accuracy": 0.2,
        "correct": 4.0,
        "total": 20,
        "multi_select_accuracy": 0.2
      },
      "gsm8k": {
        "accuracy": 0.25,
        "correct": 5.0,
        "total": 20,
        "multi_select_accuracy": 0.25
      },
      "arc": {
        "accuracy": 0.25,
        "correct": 5.0,
        "total": 20,
        "multi_select_accuracy": 0.25
      },
      "hellaswag": {
        "accuracy": 0.2,
        "correct": 4.0,
        "total": 20,
        "multi_select_accuracy": 0.2
      }
    },
    "report": "======================================================================\nH2Q AGI 标准人类基准测试报告\n======================================================================\n\n测试时间: 2026-01-29 17:25:57\n\n============================================================\n[MMLU]\n  总题数: 20\n  正确数(单选): 4.0\n  准确率(单选): 20.0%\n  多选评分: 20.0%\n  用时: 0.01s\n\n  与其他模型比较:\n    ❌ vs GPT-4: 86.4% (-66.4)\n    ❌ vs Claude-3: 86.8% (-66.8)\n    ❌ vs GPT-3.5: 70.0% (-50.0)\n    ❌ vs Llama-2-70B: 69.8% (-49.8)\n    ❌ vs Human-Expert: 89.8% (-69.8)\n    ❌ vs Human-Average: 34.5% (-14.5)\n\n  按学科:\n    college_physics: 50.0%\n    anatomy: 0.0%\n    high_school_statistics: 0.0%\n    miscellaneous: 0.0%\n    prehistory: 100.0%\n    security_studies: 0.0%\n    conceptual_physics: 0.0%\n    marketing: 0.0%\n    professional_law: 33.3%\n    jurisprudence: 0.0%\n    moral_scenarios: 100.0%\n    public_relations: 0.0%\n    management: 0.0%\n    professional_psychology: 0.0%\n\n============================================================\n[GSM8K]\n  总题数: 20\n  正确数(单选): 5.0\n  准确率(单选): 25.0%\n  多选评分: 25.0%\n  用时: 0.01s\n\n  与其他模型比较:\n    ❌ vs GPT-4: 92.0% (-67.0)\n    ❌ vs Claude-3: 88.0% (-63.0)\n    ❌ vs GPT-3.5: 57.1% (-32.1)\n    ❌ vs Llama-2-70B: 56.8% (-31.8)\n    ❌ vs Human-Expert: 95.0% (-70.0)\n\n  按学科:\n    arithmetic: 25.0%\n\n============================================================\n[ARC]\n  总题数: 20\n  正确数(单选): 5.0\n  准确率(单选): 25.0%\n  多选评分: 25.0%\n  用时: 0.01s\n\n  与其他模型比较:\n    ❌ vs GPT-4: 96.3% (-71.3)\n    ❌ vs Claude-3: 96.4% (-71.4)\n    ❌ vs GPT-3.5: 85.2% (-60.2)\n    ❌ vs Llama-2-70B: 67.3% (-42.3)\n    ❌ vs Human-Expert: 95.0% (-70.0)\n\n  按学科:\n    science: 25.0%\n\n============================================================\n[HELLASWAG]\n  总题数: 20\n  正确数(单选): 4.0\n  准确率(单选): 20.0%\n  多选评分: 20.0%\n  用时: 0.01s\n\n  与其他模型比较:\n    ❌ vs GPT-4: 95.3% (-75.3)\n    ❌ vs Claude-3: 95.0% (-75.0)\n    ❌ vs GPT-3.5: 85.5% (-65.5)\n    ❌ vs Llama-2-70B: 87.3% (-67.3)\n    ❌ vs Human-Average: 95.6% (-75.6)\n\n  按学科:\n    commonsense: 20.0%\n\n============================================================\n总体评分(单选): 22.5%\n总题数: 80\n总正确(单选): 18.0\n等级: 需要提升 (Needs Improvement)\n======================================================================"
  }
}