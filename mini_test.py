#!/usr/bin/env python3
"""è¿·ä½ AGIç³»ç»Ÿæµ‹è¯•"""

import torch
import torch.nn as nn
import logging
import asyncio

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('MINI-TEST')

class MiniEncoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv = nn.Conv2d(3, 32, 3, padding=1)
        self.pool = nn.AdaptiveAvgPool2d((4, 4))
        self.fc = nn.Linear(32*16, 128)

    def forward(self, x):
        x = torch.relu(self.conv(x))
        x = self.pool(x)
        return self.fc(x.flatten(1))

class MiniSystem:
    def __init__(self):
        self.device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
        self.encoder = MiniEncoder().to(self.device)
        self.optimizer = torch.optim.Adam(self.encoder.parameters())

    async def run_test(self):
        logger.info('ğŸ¯ å¼€å§‹è¿·ä½ AGIç³»ç»Ÿæµ‹è¯•')

        # æµ‹è¯•æ•°æ®
        batch_size = 2
        x = torch.randn(batch_size, 3, 32, 32).to(self.device)

        # å‰å‘ä¼ æ’­
        output = self.encoder(x)
        logger.info(f'âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}')

        # è®­ç»ƒæ­¥éª¤
        target = torch.randn(batch_size, 128).to(self.device)
        loss_fn = nn.MSELoss()

        for step in range(3):
            self.optimizer.zero_grad()
            output = self.encoder(x)
            loss = loss_fn(output, target)
            loss.backward()
            self.optimizer.step()
            logger.info(f'ğŸ“Š æ­¥éª¤ {step}, æŸå¤±: {loss.item():.4f}')

        logger.info('ğŸ¯ è¿·ä½ AGIç³»ç»Ÿæµ‹è¯•å®Œæˆ')

async def main():
    system = MiniSystem()
    await system.run_test()

if __name__ == "__main__":
    asyncio.run(main())