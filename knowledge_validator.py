#!/usr/bin/env python3
"""
H2Q-Evo çŸ¥è¯†éªŒè¯å’ŒçŸ«æ­£ç³»ç»Ÿ
é€šè¿‡å…¬å¼€å…è´¹çš„APIéªŒè¯å’Œæ”¹è¿›çŸ¥è¯†åº“
"""

import json
import requests
import time
from typing import Dict, List, Tuple, Optional
from datetime import datetime
from pathlib import Path

class KnowledgeValidator:
    """çŸ¥è¯†éªŒè¯å™¨ - è¿æ¥å¤šä¸ªå…è´¹APIè¿›è¡ŒçŸ¥è¯†éªŒè¯"""
    
    def __init__(self):
        self.validation_log = Path("validation_log.json")
        self.validated_count = 0
        self.corrected_count = 0
        
    def validate_with_wikipedia(self, concept: str, domain: str) -> Dict:
        """ä½¿ç”¨Wikipedia APIéªŒè¯çŸ¥è¯†"""
        try:
            # Wikipedia API æœç´¢
            search_url = "https://en.wikipedia.org/w/api.php"
            search_params = {
                "action": "opensearch",
                "search": concept,
                "limit": 1,
                "format": "json"
            }
            
            response = requests.get(search_url, params=search_params, timeout=5)
            if response.status_code == 200:
                results = response.json()
                if len(results) > 3 and len(results[3]) > 0:
                    url = results[3][0]
                    description = results[2][0] if len(results[2]) > 0 else ""
                    
                    return {
                        "source": "wikipedia",
                        "found": True,
                        "description": description,
                        "url": url,
                        "confidence": 0.8
                    }
            
            return {"source": "wikipedia", "found": False}
            
        except Exception as e:
            return {"source": "wikipedia", "error": str(e)}
    
    def validate_with_wolfram(self, concept: str) -> Dict:
        """ä½¿ç”¨Wolfram Alpha Simple APIï¼ˆéœ€è¦å…è´¹API keyï¼‰"""
        # æ³¨æ„ï¼šè¿™éœ€è¦åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½® WOLFRAM_APP_ID
        # å…è´¹æ³¨å†Œ: https://products.wolframalpha.com/simple-api/documentation/
        import os
        app_id = os.getenv("WOLFRAM_APP_ID")
        
        if not app_id:
            return {"source": "wolfram", "found": False, "error": "No API key"}
        
        try:
            url = f"http://api.wolframalpha.com/v1/result"
            params = {
                "i": concept,
                "appid": app_id
            }
            
            response = requests.get(url, params=params, timeout=10)
            if response.status_code == 200:
                return {
                    "source": "wolfram",
                    "found": True,
                    "answer": response.text,
                    "confidence": 0.9
                }
            
            return {"source": "wolfram", "found": False}
            
        except Exception as e:
            return {"source": "wolfram", "error": str(e)}
    
    def validate_with_llm_free(self, concept: str, detail: str, domain: str) -> Dict:
        """ä½¿ç”¨å…è´¹çš„LLM APIéªŒè¯ï¼ˆHugging Face Inference APIï¼‰"""
        try:
            # ä½¿ç”¨Hugging Faceçš„å…è´¹æ¨ç†API
            # å¯ä»¥ä½¿ç”¨å„ç§å¼€æºæ¨¡å‹ï¼Œå¦‚ google/flan-t5-large
            api_url = "https://api-inference.huggingface.co/models/google/flan-t5-large"
            
            # å¯ä»¥ä»ç¯å¢ƒå˜é‡è·å–tokenï¼ˆå¯é€‰ï¼Œæ²¡æœ‰tokenä¹Ÿèƒ½ç”¨ä½†æœ‰é™é¢ï¼‰
            import os
            token = os.getenv("HUGGINGFACE_TOKEN", "")
            
            headers = {}
            if token:
                headers["Authorization"] = f"Bearer {token}"
            
            # æ„é€ éªŒè¯æç¤ºè¯
            prompt = f"Verify this scientific statement about {concept} in {domain}: '{detail}'. Is this accurate? Answer with 'Correct' or 'Incorrect' and explain briefly."
            
            payload = {"inputs": prompt}
            
            response = requests.post(api_url, headers=headers, json=payload, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                if isinstance(result, list) and len(result) > 0:
                    answer = result[0].get("generated_text", "")
                    
                    # ç®€å•çš„å‡†ç¡®æ€§åˆ¤æ–­
                    is_correct = "correct" in answer.lower() and "incorrect" not in answer.lower()
                    
                    return {
                        "source": "huggingface_llm",
                        "found": True,
                        "answer": answer,
                        "is_correct": is_correct,
                        "confidence": 0.75
                    }
            
            return {"source": "huggingface_llm", "found": False, "status": response.status_code}
            
        except Exception as e:
            return {"source": "huggingface_llm", "error": str(e)}
    
    def validate_with_ollama_local(self, concept: str, detail: str, domain: str) -> Dict:
        """ä½¿ç”¨æœ¬åœ°OllamaéªŒè¯ï¼ˆå¦‚æœå·²å®‰è£…ï¼‰"""
        try:
            # æ£€æŸ¥æœ¬åœ°æ˜¯å¦è¿è¡Œäº†Ollama
            response = requests.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": "llama2",  # æˆ–å…¶ä»–å·²å®‰è£…çš„æ¨¡å‹
                    "prompt": f"Verify this {domain} knowledge: {concept} - {detail}. Is this accurate? Answer yes or no and explain briefly.",
                    "stream": False
                },
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                answer = result.get("response", "")
                
                return {
                    "source": "ollama_local",
                    "found": True,
                    "answer": answer,
                    "confidence": 0.85
                }
            
            return {"source": "ollama_local", "found": False}
            
        except Exception as e:
            # Ollamaå¯èƒ½æœªå®‰è£…æˆ–æœªè¿è¡Œï¼Œè¿™æ˜¯æ­£å¸¸çš„
            return {"source": "ollama_local", "available": False}
    
    def comprehensive_validation(self, concept: str, detail: str, domain: str) -> Dict:
        """ç»¼åˆå¤šä¸ªæ¥æºè¿›è¡ŒéªŒè¯"""
        print(f"\nğŸ” éªŒè¯: {concept} ({domain})")
        
        results = {
            "concept": concept,
            "domain": domain,
            "original_detail": detail,
            "validation_time": datetime.now().isoformat(),
            "sources": []
        }
        
        # 1. WikipediaéªŒè¯ï¼ˆå¿«é€Ÿï¼Œå¯é ï¼‰
        wiki_result = self.validate_with_wikipedia(concept, domain)
        results["sources"].append(wiki_result)
        if wiki_result.get("found"):
            print(f"  âœ“ Wikipedia: æ‰¾åˆ°ç›¸å…³æ¡ç›®")
        
        time.sleep(0.5)  # é¿å…APIé™æµ
        
        # 2. å°è¯•Ollamaæœ¬åœ°éªŒè¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        ollama_result = self.validate_with_ollama_local(concept, detail, domain)
        if ollama_result.get("available", True):  # å¦‚æœä¸æ˜¯æ˜¾å¼ä¸å¯ç”¨
            results["sources"].append(ollama_result)
            if ollama_result.get("found"):
                print(f"  âœ“ Ollama: æœ¬åœ°éªŒè¯å®Œæˆ")
        
        # 3. LLMéªŒè¯ï¼ˆå¯é€‰ï¼Œè¾ƒæ…¢ï¼‰
        # llm_result = self.validate_with_llm_free(concept, detail, domain)
        # results["sources"].append(llm_result)
        
        # ç»¼åˆè¯„åˆ†
        confidence_scores = [s.get("confidence", 0) for s in results["sources"] if s.get("found")]
        if confidence_scores:
            results["overall_confidence"] = sum(confidence_scores) / len(confidence_scores)
            results["validated"] = results["overall_confidence"] > 0.6
        else:
            results["overall_confidence"] = 0.5
            results["validated"] = False
        
        self.validated_count += 1
        
        return results
    
    def suggest_correction(self, validation_result: Dict) -> Optional[str]:
        """åŸºäºéªŒè¯ç»“æœå»ºè®®ä¿®æ­£"""
        sources = validation_result.get("sources", [])
        
        # ä¼˜å…ˆä½¿ç”¨Wikipediaçš„æè¿°
        for source in sources:
            if source.get("source") == "wikipedia" and source.get("found"):
                description = source.get("description", "")
                if description and len(description) > 20:
                    self.corrected_count += 1
                    return description
        
        # å…¶æ¬¡ä½¿ç”¨LLMçš„å›ç­”
        for source in sources:
            if source.get("source") in ["huggingface_llm", "ollama_local"] and source.get("found"):
                answer = source.get("answer", "")
                if answer and len(answer) > 20:
                    self.corrected_count += 1
                    return answer
        
        return None
    
    def save_validation_log(self, validations: List[Dict]):
        """ä¿å­˜éªŒè¯æ—¥å¿—"""
        log_data = {
            "timestamp": datetime.now().isoformat(),
            "total_validated": self.validated_count,
            "total_corrected": self.corrected_count,
            "validations": validations
        }
        
        with open(self.validation_log, 'w', encoding='utf-8') as f:
            json.dump(log_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ“ éªŒè¯æ—¥å¿—å·²ä¿å­˜: {self.validation_log}")

class LearningFeedbackLoop:
    """å­¦ä¹ åé¦ˆå¾ªç¯"""
    
    def __init__(self, knowledge_base, validator):
        self.kb = knowledge_base
        self.validator = validator
        self.learning_history = []
    
    def learn_and_validate_batch(self, batch_size: int = 10, difficulty_range: Tuple[int, int] = (1, 5)):
        """æ‰¹é‡å­¦ä¹ å’ŒéªŒè¯çŸ¥è¯†"""
        print("="*80)
        print("ğŸ“ å¼€å§‹å­¦ä¹ å’ŒéªŒè¯å¾ªç¯")
        print("="*80)
        
        # è·å–æœªéªŒè¯çš„çŸ¥è¯†
        unverified = self.kb.get_unverified()
        
        # æŒ‰éš¾åº¦ç­›é€‰
        filtered = [(d, k) for d, k in unverified if difficulty_range[0] <= k['difficulty'] <= difficulty_range[1]]
        
        if not filtered:
            print("âš ï¸ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æœªéªŒè¯çŸ¥è¯†")
            return
        
        # éšæœºé€‰æ‹©batch
        import random
        batch = random.sample(filtered, min(batch_size, len(filtered)))
        
        print(f"\nğŸ“š å­¦ä¹ æ‰¹æ¬¡: {len(batch)} ä¸ªçŸ¥è¯†æ¡ç›®")
        
        validations = []
        for i, (domain, knowledge) in enumerate(batch, 1):
            print(f"\n[{i}/{len(batch)}] {knowledge['concept']}")
            
            # éªŒè¯
            validation = self.validator.comprehensive_validation(
                knowledge['concept'],
                knowledge['detail'],
                domain
            )
            
            # å»ºè®®ä¿®æ­£
            correction = self.validator.suggest_correction(validation)
            
            if correction:
                print(f"  ğŸ’¡ å»ºè®®æ›´æ–°: {correction[:100]}...")
                self.kb.update_knowledge(
                    domain,
                    knowledge['concept'],
                    correction,
                    confidence=validation.get('overall_confidence', 0.7)
                )
            
            # æ ‡è®°ä¸ºå·²éªŒè¯
            if validation.get('validated'):
                self.kb.mark_verified(domain, knowledge['concept'])
                print(f"  âœ… éªŒè¯é€šè¿‡ (ç½®ä¿¡åº¦: {validation.get('overall_confidence', 0)*100:.1f}%)")
            else:
                print(f"  âš ï¸ éªŒè¯å¤±è´¥æˆ–ç½®ä¿¡åº¦ä½")
            
            validations.append(validation)
            
            # é¿å…APIé™æµ
            time.sleep(1)
        
        # ä¿å­˜ç»“æœ
        self.kb.save()
        self.validator.save_validation_log(validations)
        
        # ç»Ÿè®¡
        print("\n"+"="*80)
        print("ğŸ“Š å­¦ä¹ åé¦ˆç»Ÿè®¡")
        print("="*80)
        print(f"éªŒè¯æ€»æ•°: {self.validator.validated_count}")
        print(f"ä¿®æ­£æ€»æ•°: {self.validator.corrected_count}")
        print(f"ä¿®æ­£ç‡: {self.validator.corrected_count/max(self.validator.validated_count, 1)*100:.1f}%")
        
        stats = self.kb.get_stats()
        print(f"çŸ¥è¯†åº“éªŒè¯è¿›åº¦: {stats['verified_count']}/{stats['total_count']} ({stats['verified_count']/max(stats['total_count'], 1)*100:.1f}%)")

if __name__ == "__main__":
    from large_knowledge_base import LargeKnowledgeBase
    
    print("="*80)
    print("ğŸš€ å¯åŠ¨çŸ¥è¯†éªŒè¯å’Œå­¦ä¹ åé¦ˆç³»ç»Ÿ")
    print("="*80)
    
    # åˆå§‹åŒ–
    kb = LargeKnowledgeBase()
    validator = KnowledgeValidator()
    feedback_loop = LearningFeedbackLoop(kb, validator)
    
    # è¿è¡Œä¸€ä¸ªå­¦ä¹ æ‰¹æ¬¡
    feedback_loop.learn_and_validate_batch(
        batch_size=5,  # å…ˆéªŒè¯5ä¸ª
        difficulty_range=(1, 3)  # ä»ç®€å•çš„å¼€å§‹
    )
