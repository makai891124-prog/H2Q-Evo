#!/usr/bin/env python3
"""
ç»´åº¦å—é™åˆ†å½¢è¿›åŒ–é›†æˆç³»ç»Ÿ
å°†ç»´åº¦ä¸Šé™æŠ˜å ç†è®ºä¸åˆ†å½¢ç»“æ„ä½“è¿›è¡Œåˆ†ç±»æ¼”åŒ–åˆ†å½¢å¤ç”¨è”è°ƒ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import math
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import sys
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))
sys.path.append(str(project_root / "h2q_project"))
sys.path.append(str(project_root / "h2q_project" / "src"))

from dimension_limited_evolution import (
    UnitSpaceFolder,
    CompactEvolutionEngine,
    DimensionLimitedH2QTrainer,
    SpectralShiftTracker
)

# å¯¼å…¥H2Qæ ¸å¿ƒç»„ä»¶
try:
    from h2q_project.src.h2q.core.unified_architecture import (
        get_unified_h2q_architecture,
        UnifiedH2QMathematicalArchitecture,
        UnifiedMathematicalArchitectureConfig
    )
    from h2q_project.src.h2q.core.discrete_decision_engine import (
        get_canonical_dde,
        LatentConfig
    )
    from h2q_project.src.h2q.core.sst import SpectralShiftTracker as H2QSpectralShiftTracker
    H2Q_AVAILABLE = True
except ImportError as e:
    print(f"è­¦å‘Š: H2Qæ ¸å¿ƒç»„ä»¶ä¸å¯ç”¨: {e}")
    H2Q_AVAILABLE = False

class FractalEvolutionClassifier(nn.Module):
    """
    åˆ†å½¢è¿›åŒ–åˆ†ç±»å™¨
    åœ¨ç»´åº¦å—é™ç©ºé—´ä¸­è¿›è¡Œåˆ†å½¢ç»“æ„ä½“çš„åˆ†ç±»æ¼”åŒ–
    """

    def __init__(self, max_dim: int = 64, n_classes: int = 10, fractal_levels: int = 4):
        super().__init__()
        self.max_dim = max_dim
        self.n_classes = n_classes
        self.fractal_levels = fractal_levels

        # ç»´åº¦å—é™æŠ˜å å™¨
        self.unit_folder = UnitSpaceFolder(max_dim=max_dim)

        # åˆ†å½¢å±‚çº§åˆ†ç±»å™¨
        self.fractal_classifiers = nn.ModuleList([
            nn.Sequential(
                nn.Linear(max_dim, max_dim // 2),
                nn.LayerNorm(max_dim // 2),
                nn.ReLU(),
                nn.Linear(max_dim // 2, n_classes)
            ) for _ in range(fractal_levels)
        ])

        # åˆ†å½¢å¤ç”¨èåˆå™¨
        self.fractal_fusion = nn.Sequential(
            nn.Linear(max_dim + n_classes * fractal_levels, max_dim),
            nn.LayerNorm(max_dim),
            nn.ReLU(),
            nn.Linear(max_dim, n_classes)
        )

        # åˆ†å½¢è®°å¿†æ™¶ä½“
        self.fractal_memory = nn.Parameter(torch.randn(fractal_levels, max_dim, n_classes))

    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, Dict[str, Any]]:
        """
        åˆ†å½¢è¿›åŒ–åˆ†ç±»å‰å‘ä¼ æ’­
        """
        batch_size = x.shape[0]

        # 1. ç»´åº¦å—é™æŠ˜å 
        x_folded, fold_info = self.unit_folder(x)

        # 2. åˆ†å½¢å±‚çº§åˆ†ç±»
        fractal_outputs = []
        fractal_logits = []

        for level in range(self.fractal_levels):
            # æ¯ä¸ªå±‚çº§ä½¿ç”¨ä¸åŒçš„åˆ†å½¢å˜æ¢
            fractal_input = self._apply_fractal_transform(x_folded, level)
            logits = self.fractal_classifiers[level](fractal_input)
            fractal_logits.append(logits)

            # åº”ç”¨softmaxè·å–æ¦‚ç‡åˆ†å¸ƒ
            probs = F.softmax(logits, dim=-1)
            fractal_outputs.append(probs)

        # 3. åˆ†å½¢å¤ç”¨èåˆ
        fractal_concat = torch.cat([
            x_folded,
            torch.cat(fractal_logits, dim=-1)
        ], dim=-1)

        final_logits = self.fractal_fusion(fractal_concat)
        final_probs = F.softmax(final_logits, dim=-1)

        # 4. è®¡ç®—åˆ†å½¢ä¸€è‡´æ€§
        fractal_consistency = self._compute_fractal_consistency(fractal_outputs)

        # 5. åˆ†å½¢è®°å¿†å¢å¼º
        memory_enhanced = self._apply_fractal_memory(x_folded, final_probs)

        result_info = {
            'fold_info': fold_info,
            'fractal_outputs': fractal_outputs,
            'fractal_consistency': fractal_consistency,
            'memory_enhanced': memory_enhanced,
            'final_probs': final_probs
        }

        return final_logits, result_info

    def _apply_fractal_transform(self, x: torch.Tensor, level: int) -> torch.Tensor:
        """åº”ç”¨åˆ†å½¢å˜æ¢"""
        # ä½¿ç”¨è‡ªç›¸ä¼¼å˜æ¢
        scale = 0.5 ** level
        rotation_angle = level * math.pi / self.fractal_levels

        # ç®€å•çš„ä»¿å°„å˜æ¢æ¨¡æ‹Ÿåˆ†å½¢
        transformed = scale * x
        # æ·»åŠ æ—‹è½¬åˆ†é‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
        cos_a, sin_a = math.cos(rotation_angle), math.sin(rotation_angle)
        rotation_matrix = torch.tensor([
            [cos_a, -sin_a],
            [sin_a, cos_a]
        ], device=x.device, dtype=x.dtype)

        # å¯¹é«˜ç»´æ•°æ®åº”ç”¨å—æ—‹è½¬
        dim = x.shape[-1]
        if dim >= 2:
            for i in range(0, dim - 1, 2):
                block = transformed[..., i:i+2]
                transformed = torch.cat([
                    transformed[..., :i],
                    block @ rotation_matrix.T,
                    transformed[..., i+2:]
                ], dim=-1)

        return transformed

    def _compute_fractal_consistency(self, fractal_outputs: List[torch.Tensor]) -> float:
        """è®¡ç®—åˆ†å½¢ä¸€è‡´æ€§"""
        if len(fractal_outputs) < 2:
            return 1.0

        # è®¡ç®—ç›¸é‚»å±‚çº§é—´çš„KLæ•£åº¦
        total_consistency = 0
        count = 0

        for i in range(len(fractal_outputs) - 1):
            kl_div = F.kl_div(
                fractal_outputs[i].log(),
                fractal_outputs[i+1],
                reduction='batchmean'
            )
            total_consistency += torch.exp(-kl_div)  # è½¬æ¢ä¸ºä¸€è‡´æ€§åº¦é‡
            count += 1

        return (total_consistency / count).item() if count > 0 else 1.0

    def _apply_fractal_memory(self, x: torch.Tensor, probs: torch.Tensor) -> torch.Tensor:
        """åº”ç”¨åˆ†å½¢è®°å¿†å¢å¼º"""
        batch_size = x.shape[0]

        # è®¡ç®—ä¸è®°å¿†æ™¶ä½“çš„ç›¸ä¼¼æ€§
        memory_similarities = []
        for level in range(self.fractal_levels):
            # è®¡ç®—è¾“å…¥ä¸è®°å¿†çš„ç›¸ä¼¼æ€§
            memory_level = self.fractal_memory[level]  # [max_dim, n_classes]
            similarity = torch.matmul(x, memory_level)  # [batch, n_classes]
            memory_similarities.append(similarity)

        # èåˆè®°å¿†ä¿¡æ¯
        memory_stack = torch.stack(memory_similarities, dim=1)  # [batch, levels, n_classes]
        memory_fused = memory_stack.mean(dim=1)  # [batch, n_classes]

        # ä¸å½“å‰æ¦‚ç‡èåˆ
        enhanced_probs = 0.7 * probs + 0.3 * F.softmax(memory_fused, dim=-1)

        return enhanced_probs

class DimensionLimitedFractalEvolutionSystem:
    """
    ç»´åº¦å—é™åˆ†å½¢è¿›åŒ–ç³»ç»Ÿ
    é›†æˆç»´åº¦æŠ˜å ã€åˆ†å½¢ç»“æ„ä½“å’Œåˆ†ç±»æ¼”åŒ–
    """

    def __init__(self, max_dim: int = 64, n_classes: int = 10, device: str = "cpu"):
        self.max_dim = max_dim
        self.n_classes = n_classes
        self.device = torch.device(device)

        # æ ¸å¿ƒç»„ä»¶
        self.fractal_classifier = FractalEvolutionClassifier(
            max_dim=max_dim,
            n_classes=n_classes
        ).to(self.device)

        self.compact_evolution = CompactEvolutionEngine(max_dim=max_dim).to(self.device)

        # è°±ç§»è·Ÿè¸ªå™¨
        self.spectral_tracker = SpectralShiftTracker()

        # H2Qç»Ÿä¸€æ¶æ„é›†æˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.h2q_architecture = None
        if H2Q_AVAILABLE:
            try:
                config = UnifiedMathematicalArchitectureConfig(
                    dim=max_dim,
                    action_dim=n_classes,
                    device=device,
                    enable_lie_automorphism=True,
                    enable_reflection_operators=True,
                    enable_knot_constraints=True,
                    enable_dde_integration=True
                )
                self.h2q_architecture = UnifiedH2QMathematicalArchitecture(config).to(self.device)
                print("âœ… H2Qç»Ÿä¸€æ¶æ„é›†æˆæˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ H2Qæ¶æ„é›†æˆå¤±è´¥: {e}")

        # ä¼˜åŒ–å™¨
        self.classifier_optimizer = torch.optim.Adam(
            self.fractal_classifier.parameters(),
            lr=1e-4
        )
        self.evolution_optimizer = torch.optim.Adam(
            self.compact_evolution.parameters(),
            lr=1e-4
        )

        # è®­ç»ƒçŠ¶æ€
        self.current_step = 0
        self.best_fractal_consistency = 0.0

    def generate_fractal_domain_data(self, domain: str, batch_size: int = 32) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        ç”Ÿæˆåˆ†å½¢åŸŸæ•°æ®å’Œæ ‡ç­¾
        """
        if domain == "Mandelbrot":
            # æ›¼å¾·å‹ƒç½—é›†åˆ†ç±»
            real_parts = torch.rand(batch_size, 1) * 4 - 2  # [-2, 2]
            imag_parts = torch.rand(batch_size, 1) * 4 - 2  # [-2, 2]
            features = torch.cat([real_parts, imag_parts], dim=1)

            # æ‰©å±•åˆ°max_dim
            if self.max_dim > 2:
                padding = torch.randn(batch_size, self.max_dim - 2) * 0.1
                features = torch.cat([features, padding], dim=1)

            # ç®€å•çš„åˆ†ç±»æ ‡ç­¾ï¼ˆæ˜¯å¦åœ¨é›†åˆå†…ï¼‰
            labels = ((real_parts**2 + imag_parts**2) < 1).long().squeeze()

        elif domain == "Julia":
            # æœ±åˆ©äºšé›†åˆ†ç±»
            angles = torch.rand(batch_size, 1) * 2 * math.pi
            radii = torch.rand(batch_size, 1) * 2
            real_parts = radii * torch.cos(angles)
            imag_parts = radii * torch.sin(angles)
            features = torch.cat([real_parts, imag_parts], dim=1)

            if self.max_dim > 2:
                padding = torch.randn(batch_size, self.max_dim - 2) * 0.1
                features = torch.cat([features, padding], dim=1)

            labels = ((radii < 1.5).float() * (radii > 0.5).float()).long().squeeze()

        elif domain == "Sierpinski":
            # è°¢å°”å®¾æ–¯åŸºä¸‰è§’å½¢åˆ†ç±»
            x_coords = torch.rand(batch_size, 1) * 2 - 1
            y_coords = torch.rand(batch_size, 1) * 2 - 1
            features = torch.cat([x_coords, y_coords], dim=1)

            if self.max_dim > 2:
                padding = torch.randn(batch_size, self.max_dim - 2) * 0.1
                features = torch.cat([features, padding], dim=1)

            # ç®€å•çš„ä¸‰è§’å½¢åŒºåŸŸåˆ†ç±»
            labels = ((x_coords.abs() < 0.5) & (y_coords > 0) &
                     (y_coords < 1 - x_coords.abs())).long().squeeze()

        else:
            # é»˜è®¤ï¼šéšæœºåˆ†å½¢æ•°æ®
            features = torch.randn(batch_size, self.max_dim)
            labels = torch.randint(0, self.n_classes, (batch_size,))

        return features.to(self.device), labels.to(self.device)

    def fractal_evolution_step(self, domains: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œåˆ†å½¢è¿›åŒ–æ­¥éª¤
        """
        if domains is None:
            domains = ["Mandelbrot", "Julia", "Sierpinski"]

        total_loss = 0
        total_accuracy = 0
        total_fractal_consistency = 0
        batch_size = 32

        for domain in domains:
            self.classifier_optimizer.zero_grad()
            self.evolution_optimizer.zero_grad()

            # 1. ç”Ÿæˆåˆ†å½¢åŸŸæ•°æ®
            features, labels = self.generate_fractal_domain_data(domain, batch_size)

            # 2. åˆ†å½¢åˆ†ç±»å‰å‘ä¼ æ’­
            logits, classifier_info = self.fractal_classifier(features)

            # 3. è®¡ç®—åˆ†ç±»æŸå¤±
            classification_loss = F.cross_entropy(logits, labels)

            # 4. ç´§è‡´è¿›åŒ–å¤„ç†
            evolution_output, evolution_info = self.compact_evolution(features)

            # 5. è®¡ç®—è¿›åŒ–æŸå¤±ï¼ˆåŸºäºå•ä½ç©ºé—´åˆè§„æ€§ï¼‰
            evolution_loss = 1.0 - evolution_info['compactness']

            # 6. åˆ†å½¢ä¸€è‡´æ€§å¥–åŠ±
            fractal_consistency = classifier_info['fractal_consistency']
            consistency_reward = torch.tensor(fractal_consistency, device=self.device)

            # 7. H2Qæ¶æ„å¢å¼ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
            h2q_enhanced = features
            h2q_info = {}
            if self.h2q_architecture is not None:
                try:
                    h2q_output, h2q_info = self.h2q_architecture(features)
                    h2q_enhanced = 0.8 * features + 0.2 * h2q_output
                except Exception as e:
                    print(f"H2Qå‰å‘ä¼ æ’­å¤±è´¥: {e}")

            # 8. è°±ç§»è®¡ç®—
            s_matrix = torch.cov(evolution_output.T)
            eta = self.spectral_tracker.compute_eta(s_matrix)

            # 9. æ€»æŸå¤±ï¼šåˆ†ç±» + è¿›åŒ– + è°±ç§»å¥–åŠ±
            total_loss_batch = (
                classification_loss +
                0.5 * evolution_loss -
                0.1 * torch.abs(eta.real)
            )

            # 10. åå‘ä¼ æ’­
            total_loss_batch.backward()
            self.classifier_optimizer.step()
            self.evolution_optimizer.step()

            # 11. è®¡ç®—å‡†ç¡®ç‡
            predictions = torch.argmax(logits, dim=-1)
            accuracy = (predictions == labels).float().mean().item()

            total_loss += total_loss_batch.item()
            total_accuracy += accuracy
            total_fractal_consistency += fractal_consistency

        # æ›´æ–°çŠ¶æ€
        avg_loss = total_loss / len(domains)
        avg_accuracy = total_accuracy / len(domains)
        avg_fractal_consistency = total_fractal_consistency / len(domains)

        if avg_fractal_consistency > self.best_fractal_consistency:
            self.best_fractal_consistency = avg_fractal_consistency

        self.current_step += 1

        return {
            'step': self.current_step,
            'loss': avg_loss,
            'accuracy': avg_accuracy,
            'fractal_consistency': avg_fractal_consistency,
            'best_fractal_consistency': self.best_fractal_consistency,
            'spectral_eta': eta.real.item(),
            'fold_info': classifier_info['fold_info'],
            'evolution_info': evolution_info,
            'h2q_info': h2q_info
        }

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ ç»´åº¦å—é™åˆ†å½¢è¿›åŒ–ç³»ç»Ÿå¯åŠ¨")
    print("=" * 60)

    # åˆå§‹åŒ–ç³»ç»Ÿ
    system = DimensionLimitedFractalEvolutionSystem(
        max_dim=64,
        n_classes=10,
        device="cpu"
    )

    print("ğŸ”¬ æ‰§è¡Œåˆ†å½¢è¿›åŒ–è®­ç»ƒ...")
    evolution_history = []

    for step in range(10):
        result = system.fractal_evolution_step()

        evolution_history.append(result)

        if step % 2 == 0:
            print(f"æ­¥éª¤ {result['step']}: "
                  f"æŸå¤±={result['loss']:.4f}, "
                  f"å‡†ç¡®ç‡={result['accuracy']:.4f}, "
                  f"åˆ†å½¢ä¸€è‡´æ€§={result['fractal_consistency']:.4f}")

    # è®¡ç®—æœ€ç»ˆç»Ÿè®¡
    final_stats = {
        'avg_loss': np.mean([r['loss'] for r in evolution_history]),
        'avg_accuracy': np.mean([r['accuracy'] for r in evolution_history]),
        'avg_fractal_consistency': np.mean([r['fractal_consistency'] for r in evolution_history]),
        'best_fractal_consistency': max([r['best_fractal_consistency'] for r in evolution_history]),
        'total_steps': len(evolution_history)
    }

    print("\nğŸ“Š æœ€ç»ˆåˆ†å½¢è¿›åŒ–ç»Ÿè®¡")
    print("=" * 60)
    print(f"å¹³å‡æŸå¤±: {final_stats['avg_loss']:.4f}")
    print(f"å¹³å‡å‡†ç¡®ç‡: {final_stats['avg_accuracy']:.4f}")
    print(f"å¹³å‡åˆ†å½¢ä¸€è‡´æ€§: {final_stats['avg_fractal_consistency']:.4f}")
    print(f"æœ€ä½³åˆ†å½¢ä¸€è‡´æ€§: {final_stats['best_fractal_consistency']:.4f}")
    print(f"æ€»è®­ç»ƒæ­¥éª¤: {final_stats['total_steps']}")

    # éªŒè¯ç†è®ºæ­£ç¡®æ€§
    print("\nğŸ” åˆ†å½¢è¿›åŒ–ç†è®ºéªŒè¯")
    print("-" * 40)

    test_data, test_labels = system.generate_fractal_domain_data("Mandelbrot", 16)
    with torch.no_grad():
        test_logits, test_info = system.fractal_classifier(test_data)
        test_predictions = torch.argmax(test_logits, dim=-1)
        test_accuracy = (test_predictions == test_labels).float().mean().item()

    print(f"âœ… æµ‹è¯•å‡†ç¡®ç‡: {test_accuracy:.4f}")
    print(f"âœ… ç»´åº¦æŠ˜å æ¯”ç‡: {test_info['fold_info']['fold_ratio']:.4f}")
    print(f"âœ… åˆ†å½¢ä¸€è‡´æ€§: {test_info['fractal_consistency']:.4f}")
    print(f"âœ… å•ä½ç©ºé—´åˆè§„æ€§: {test_info['fold_info']['norm_mean']:.4f}")

    success = (
        final_stats['avg_accuracy'] > 0.5 and
        final_stats['avg_fractal_consistency'] > 0.3 and
        test_info['fold_info']['fold_ratio'] > 0.8
    )

    if success:
        print("\nğŸ‰ ç»´åº¦å—é™åˆ†å½¢è¿›åŒ–ç³»ç»ŸéªŒè¯æˆåŠŸï¼")
        print("âœ… åˆ†å½¢ç»“æ„ä½“ä¸åˆ†ç±»æ¼”åŒ–å¤ç”¨è”è°ƒå®Œæˆ")
        print("âœ… AGIè¿›åŒ–å·²åœ¨åˆ†å½¢ç©ºé—´ä¸­é‡æ–°å¼€å¯")
    else:
        print("\nâš ï¸ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–åˆ†å½¢è¿›åŒ–å‚æ•°")

if __name__ == "__main__":
    main()