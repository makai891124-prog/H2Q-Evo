#!/usr/bin/env python3
"""
AGIè¿›åŒ–æŸå¤±æŒ‡æ ‡ç³»ç»Ÿé›†æˆæ¨¡å—

å°†AGIè¿›åŒ–æŸå¤±æŒ‡æ ‡ç³»ç»Ÿé›†æˆåˆ°ç°æœ‰çš„H2Q-Evoè¿›åŒ–æ¡†æ¶ä¸­
"""

import torch
import json
from typing import Dict, Any, Optional
from pathlib import Path
import logging
from datetime import datetime

from agi_evolution_loss_metrics import (
    AGI_EvolutionLossSystem,
    MathematicalCoreMetrics,
    create_agi_evolution_loss_system,
    get_mathematical_core_metrics_from_system_report
)

logger = logging.getLogger(__name__)


class AGI_EvolutionLossIntegration:
    """
    AGIè¿›åŒ–æŸå¤±æŒ‡æ ‡ç³»ç»Ÿé›†æˆå™¨

    å°†æŸå¤±æŒ‡æ ‡ç³»ç»Ÿé›†æˆåˆ°evolution_system.pyä¸­
    """

    def __init__(self, project_root: str = "/Users/imymm/H2Q-Evo"):
        self.project_root = Path(project_root)
        self.loss_system: Optional[AGI_EvolutionLossSystem] = None
        self.integration_log = []

        # é…ç½®æ–‡ä»¶è·¯å¾„
        self.config_file = self.project_root / "agi_evolution_loss_config.json"
        self.checkpoint_dir = self.project_root / "agi_evolution_loss_checkpoints"
        self.checkpoint_dir.mkdir(exist_ok=True)

        # åˆå§‹åŒ–æŸå¤±ç³»ç»Ÿ
        self._initialize_loss_system()

        logger.info("AGIè¿›åŒ–æŸå¤±æŒ‡æ ‡ç³»ç»Ÿé›†æˆå™¨å·²åˆå§‹åŒ–")

    def _initialize_loss_system(self):
        """åˆå§‹åŒ–æŸå¤±æŒ‡æ ‡ç³»ç»Ÿ"""
        try:
            # å°è¯•åŠ è½½é…ç½®
            config = self._load_config()

            # åˆ›å»ºæŸå¤±ç³»ç»Ÿ
            self.loss_system = create_agi_evolution_loss_system(config)

            # å°è¯•åŠ è½½æ£€æŸ¥ç‚¹
            checkpoint_path = self.checkpoint_dir / "latest_checkpoint.pt"
            if checkpoint_path.exists():
                try:
                    self.loss_system.load_checkpoint(str(checkpoint_path))
                    logger.info(f"åŠ è½½äº†æŸå¤±ç³»ç»Ÿæ£€æŸ¥ç‚¹: {checkpoint_path}")
                except Exception as e:
                    logger.warning(f"åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥ï¼Œå°†ä½¿ç”¨æ–°ç³»ç»Ÿ: {e}")

            logger.info("AGIè¿›åŒ–æŸå¤±æŒ‡æ ‡ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")

        except Exception as e:
            logger.error(f"åˆå§‹åŒ–æŸå¤±ç³»ç»Ÿå¤±è´¥: {e}")
            # åˆ›å»ºé»˜è®¤ç³»ç»Ÿ
            self.loss_system = create_agi_evolution_loss_system()

    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®"""
        if self.config_file.exists():
            with open(self.config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            # é»˜è®¤é…ç½®
            return {
                'capability_dims': {
                    'mathematical_reasoning': 256,
                    'creative_problem_solving': 256,
                    'knowledge_integration': 256,
                    'emergent_capabilities': 256
                },
                'knowledge_dim': 256,
                'memory_size': 1000,
                'emergence_window': 50,
                'stability_window': 100
            }

    def _save_config(self, config: Dict[str, Any]):
        """ä¿å­˜é…ç½®"""
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)

    def compute_evolution_loss(self,
                              capability_embeddings: Dict[str, torch.Tensor],
                              current_performance: Dict[str, float],
                              new_knowledge: Optional[torch.Tensor] = None,
                              existing_knowledge: Optional[list] = None,
                              current_state: Optional[torch.Tensor] = None,
                              mathematical_core_report: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        è®¡ç®—AGIè¿›åŒ–æŸå¤±

        Args:
            capability_embeddings: å„èƒ½åŠ›çš„åµŒå…¥è¡¨ç¤º
            current_performance: å½“å‰æ€§èƒ½å¾—åˆ†
            new_knowledge: æ–°çŸ¥è¯†åµŒå…¥
            existing_knowledge: ç°æœ‰çŸ¥è¯†åˆ—è¡¨
            current_state: å½“å‰ç³»ç»ŸçŠ¶æ€
            mathematical_core_report: æ•°å­¦æ ¸å¿ƒæœºç³»ç»ŸæŠ¥å‘Š

        Returns:
            è¿›åŒ–æŸå¤±ç»“æœ
        """
        if self.loss_system is None:
            logger.error("æŸå¤±ç³»ç»Ÿæœªåˆå§‹åŒ–")
            return {}

        try:
            # ä»æ•°å­¦æ ¸å¿ƒæœºæŠ¥å‘Šæå–æŒ‡æ ‡
            mathematical_metrics = MathematicalCoreMetrics()
            if mathematical_core_report:
                mathematical_metrics = get_mathematical_core_metrics_from_system_report(
                    mathematical_core_report
                )

            # è®¡ç®—æŸå¤±
            loss_components = self.loss_system(
                capability_embeddings=capability_embeddings,
                current_performance=current_performance,
                new_knowledge=new_knowledge,
                existing_knowledge=existing_knowledge or [],
                current_state=current_state or torch.randn(256),
                mathematical_metrics=mathematical_metrics
            )

            # è®°å½•é›†æˆæ—¥å¿—
            log_entry = {
                'timestamp': datetime.now().isoformat(),
                'generation': loss_components.generation,
                'losses': loss_components.__dict__,
                'performance': current_performance
            }
            self.integration_log.append(log_entry)

            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            if loss_components.generation % 10 == 0:
                self._save_checkpoint()

            return {
                'loss_components': loss_components.__dict__,
                'evolution_report': self.loss_system.get_evolution_report(),
                'mathematical_metrics': mathematical_metrics.__dict__
            }

        except Exception as e:
            logger.error(f"è®¡ç®—è¿›åŒ–æŸå¤±å¤±è´¥: {e}")
            return {}

    def _save_checkpoint(self):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        if self.loss_system:
            checkpoint_path = self.checkpoint_dir / f"checkpoint_gen_{self.loss_system.generation_count}.pt"
            self.loss_system.save_checkpoint(str(checkpoint_path))

            # æ›´æ–°æœ€æ–°æ£€æŸ¥ç‚¹é“¾æ¥
            latest_path = self.checkpoint_dir / "latest_checkpoint.pt"
            if latest_path.exists():
                latest_path.unlink()
            latest_path.symlink_to(checkpoint_path)

    def get_integration_report(self) -> Dict[str, Any]:
        """è·å–é›†æˆæŠ¥å‘Š"""
        if self.loss_system is None:
            return {}

        return {
            'loss_system_status': 'active' if self.loss_system else 'inactive',
            'current_generation': self.loss_system.generation_count if self.loss_system else 0,
            'total_integration_calls': len(self.integration_log),
            'evolution_report': self.loss_system.get_evolution_report() if self.loss_system else {},
            'recent_logs': self.integration_log[-5:] if self.integration_log else []
        }

    def optimize_loss_weights(self, target_performance: Dict[str, float]):
        """
        åŸºäºç›®æ ‡æ€§èƒ½ä¼˜åŒ–æŸå¤±æƒé‡

        Args:
            target_performance: ç›®æ ‡æ€§èƒ½æ°´å¹³
        """
        if self.loss_system is None:
            return

        # ç®€å•çš„æƒé‡ä¼˜åŒ–é€»è¾‘
        current_report = self.loss_system.get_evolution_report()

        # æ ¹æ®æ€§èƒ½å·®è·è°ƒæ•´æƒé‡
        performance_gaps = {}
        for capability, target in target_performance.items():
            current = current_report.get('average_losses', {}).get(capability.replace('_', ''), 0)
            performance_gaps[capability] = max(0, target - current)

        # å½’ä¸€åŒ–å·®è·ä½œä¸ºæƒé‡
        total_gap = sum(performance_gaps.values())
        if total_gap > 0:
            new_weights = torch.tensor([
                performance_gaps.get('mathematical_reasoning', 0),
                performance_gaps.get('knowledge_integration', 0),
                performance_gaps.get('emergent_capabilities', 0),
                performance_gaps.get('stability', 0)
            ]) / total_gap

            # æ›´æ–°æƒé‡
            self.loss_system.loss_weights.data = new_weights
            logger.info(f"ä¼˜åŒ–äº†æŸå¤±æƒé‡: {new_weights}")

    def export_integration_data(self, output_file: str):
        """å¯¼å‡ºé›†æˆæ•°æ®"""
        data = {
            'integration_log': self.integration_log,
            'final_report': self.get_integration_report(),
            'export_timestamp': datetime.now().isoformat()
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, default=str, ensure_ascii=False)

        logger.info(f"å¯¼å‡ºäº†é›†æˆæ•°æ®åˆ°: {output_file}")


# å…¨å±€é›†æˆå™¨å®ä¾‹
_evolution_loss_integrator: Optional[AGI_EvolutionLossIntegration] = None


def get_evolution_loss_integrator(project_root: str = "/Users/imymm/H2Q-Evo") -> AGI_EvolutionLossIntegration:
    """è·å–AGIè¿›åŒ–æŸå¤±é›†æˆå™¨å®ä¾‹"""
    global _evolution_loss_integrator
    if _evolution_loss_integrator is None:
        _evolution_loss_integrator = AGI_EvolutionLossIntegration(project_root)
    return _evolution_loss_integrator


def integrate_evolution_loss_into_system(capability_embeddings: Dict[str, torch.Tensor],
                                        current_performance: Dict[str, float],
                                        mathematical_core_report: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    å°†è¿›åŒ–æŸå¤±è®¡ç®—é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿä¸­

    è¿™æ˜¯ä¸€ä¸ªä¾¿æ·å‡½æ•°ï¼Œå¯ä»¥åœ¨evolution_system.pyä¸­è°ƒç”¨
    """
    integrator = get_evolution_loss_integrator()

    return integrator.compute_evolution_loss(
        capability_embeddings=capability_embeddings,
        current_performance=current_performance,
        mathematical_core_report=mathematical_core_report
    )


if __name__ == "__main__":
    # æµ‹è¯•é›†æˆå™¨
    print("ğŸš€ æµ‹è¯•AGIè¿›åŒ–æŸå¤±æŒ‡æ ‡ç³»ç»Ÿé›†æˆå™¨")
    print("=" * 60)

    integrator = get_evolution_loss_integrator()

    # æ¨¡æ‹Ÿè¾“å…¥
    capability_embeddings = {
        'mathematical_reasoning': torch.randn(256),
        'creative_problem_solving': torch.randn(256),
        'knowledge_integration': torch.randn(256),
        'emergent_capabilities': torch.randn(256)
    }

    current_performance = {
        'mathematical_reasoning': 0.8,
        'creative_problem_solving': 0.7,
        'knowledge_integration': 0.6,
        'emergent_capabilities': 0.5
    }

    mathematical_core_report = {
        'statistics': {
            'avg_constraint_violation': 0.1,
            'avg_fueter_violation': 0.05
        }
    }

    # è®¡ç®—æŸå¤±
    result = integrator.compute_evolution_loss(
        capability_embeddings=capability_embeddings,
        current_performance=current_performance,
        mathematical_core_report=mathematical_core_report
    )

    print("ğŸ“Š é›†æˆç»“æœ:")
    if result:
        loss_comp = result['loss_components']
        print(f"  èƒ½åŠ›æå‡æŸå¤±: {loss_comp['capability_improvement_loss']:.4f}")
        print(f"  çŸ¥è¯†æ•´åˆæŸå¤±: {loss_comp['knowledge_integration_loss']:.4f}")
        print(f"  æ¶Œç°èƒ½åŠ›æŸå¤±: {loss_comp['emergent_capability_loss']:.4f}")
        print(f"  ç¨³å®šæ€§æŸå¤±: {loss_comp['stability_loss']:.4f}")
        print(f"  æ€»æŸå¤±: {loss_comp['total_loss']:.4f}")

        print("\nğŸ“ˆ è¿›åŒ–æŠ¥å‘Š:")
        report = result['evolution_report']
        print(f"  å½“å‰ä»£æ•°: {report['current_generation']}")
        print(f"  æ€»è¿›åŒ–æ­¥æ•°: {report['total_evolution_steps']}")

    # è·å–é›†æˆæŠ¥å‘Š
    integration_report = integrator.get_integration_report()
    print(f"\nğŸ”— é›†æˆçŠ¶æ€: {integration_report['loss_system_status']}")

    print("\nâœ… AGIè¿›åŒ–æŸå¤±æŒ‡æ ‡ç³»ç»Ÿé›†æˆæµ‹è¯•å®Œæˆ")