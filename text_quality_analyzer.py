#!/usr/bin/env python3
"""
H2Q-Evo æ–‡æœ¬è´¨é‡åˆ†æä¸æ”¹è¿›ç³»ç»Ÿ
===================================

åˆ†æä¸å¯è¯»æ–‡æœ¬é—®é¢˜å¹¶æä¾›è§£å†³æ–¹æ¡ˆ
- è´¨é‡è¯„ä¼°æŒ‡æ ‡
- æ”¹è¿›ç­–ç•¥
- å¯¹æ¯”æµ‹è¯•
- è‡ªç”±è¿›åŒ–å»ºè®®
"""

import sys
import torch
import torch.nn as nn
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import json
import re
import math
from collections import Counter

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent
H2Q_PROJECT = PROJECT_ROOT / "h2q_project"
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(H2Q_PROJECT))

from local_long_text_generator import LocalLongTextGenerator


class TextQualityAnalyzer:
    """æ–‡æœ¬è´¨é‡åˆ†æå™¨"""

    def __init__(self):
        self.quality_metrics = {}

    def analyze_text_quality(self, text: str) -> Dict[str, float]:
        """åˆ†ææ–‡æœ¬è´¨é‡"""
        metrics = {}

        # 1. å­—ç¬¦å¤šæ ·æ€§
        unique_chars = len(set(text))
        total_chars = len(text)
        metrics['char_diversity'] = unique_chars / total_chars if total_chars > 0 else 0

        # 2. è¯æ±‡å¤šæ ·æ€§ï¼ˆç®€å•ä¼°è®¡ï¼‰
        words = re.findall(r'\b\w+\b', text.lower())
        unique_words = len(set(words))
        total_words = len(words)
        metrics['word_diversity'] = unique_words / total_words if total_words > 0 else 0

        # 3. é‡å¤æ¨¡å¼æ£€æµ‹
        repeated_patterns = self._detect_repeated_patterns(text)
        metrics['repetition_score'] = min(1.0, repeated_patterns / 10.0)  # å½’ä¸€åŒ–

        # 4. å¯è¯»æ€§è¯„åˆ†ï¼ˆåŸºäºå­—ç¬¦åˆ†å¸ƒï¼‰
        readable_chars = sum(1 for c in text if c.isalnum() or c in ' \n\t.,!?;:"\'')
        metrics['readability'] = readable_chars / total_chars if total_chars > 0 else 0

        # 5. ç»“æ„å®Œæ•´æ€§ï¼ˆå¥å­å®Œæ•´æ€§ï¼‰
        sentences = re.split(r'[.!?]+', text)
        complete_sentences = sum(1 for s in sentences if len(s.strip()) > 5)
        metrics['structural_integrity'] = complete_sentences / len(sentences) if sentences else 0

        # 6. æ•´ä½“è´¨é‡è¯„åˆ†
        metrics['overall_quality'] = (
            metrics['char_diversity'] * 0.2 +
            metrics['word_diversity'] * 0.3 +
            (1 - metrics['repetition_score']) * 0.2 +
            metrics['readability'] * 0.2 +
            metrics['structural_integrity'] * 0.1
        )

        return metrics

    def _detect_repeated_patterns(self, text: str, min_length: int = 3) -> int:
        """æ£€æµ‹é‡å¤æ¨¡å¼"""
        patterns = {}
        text_lower = text.lower()

        for i in range(len(text_lower) - min_length + 1):
            pattern = text_lower[i:i+min_length]
            if pattern in patterns:
                patterns[pattern] += 1
            else:
                patterns[pattern] = 1

        # è®¡ç®—é‡å¤æ¨¡å¼çš„ä¸¥é‡ç¨‹åº¦
        repeated_count = sum(count - 1 for count in patterns.values() if count > 1)
        return repeated_count


class TextGenerationComparator:
    """æ–‡æœ¬ç”Ÿæˆå¯¹æ¯”å™¨"""

    def __init__(self):
        self.analyzer = TextQualityAnalyzer()
        self.generators = {}

    def add_generator(self, name: str, generator_func):
        """æ·»åŠ ç”Ÿæˆå™¨"""
        self.generators[name] = generator_func

    def compare_generators(self, prompts: List[str], max_length: int = 200) -> Dict[str, Any]:
        """å¯¹æ¯”ä¸åŒç”Ÿæˆå™¨çš„æ€§èƒ½"""
        results = {}

        for prompt in prompts:
            print(f"\nğŸ¯ æµ‹è¯•æç¤º: {prompt}")
            print("-" * 50)

            prompt_results = {}

            for gen_name, generator in self.generators.items():
                try:
                    generated_text = generator(prompt, max_length)
                    quality_metrics = self.analyzer.analyze_text_quality(generated_text)

                    prompt_results[gen_name] = {
                        'text': generated_text,
                        'metrics': quality_metrics,
                        'length': len(generated_text)
                    }

                    print(f"\nğŸ¤– {gen_name}:")
                    print(f"  ğŸ“ é•¿åº¦: {len(generated_text)} å­—ç¬¦")
                    print(f"  ğŸ¯ è´¨é‡è¯„åˆ†: {quality_metrics['overall_quality']:.3f}")
                    print(f"  ğŸ“ å­—ç¬¦å¤šæ ·æ€§: {quality_metrics['char_diversity']:.3f}")
                    print(f"  ğŸ”„ é‡å¤åº¦: {quality_metrics['repetition_score']:.3f}")
                    print(f"  ğŸ“– å¯è¯»æ€§: {quality_metrics['readability']:.3f}")
                    print(f"  ğŸ—ï¸ ç»“æ„å®Œæ•´æ€§: {quality_metrics['structural_integrity']:.3f}")
                    print(f"  ğŸ’¬ ç”Ÿæˆå†…å®¹: {generated_text[:100]}{'...' if len(generated_text) > 100 else ''}")

                except Exception as e:
                    print(f"âŒ {gen_name} ç”Ÿæˆå¤±è´¥: {e}")
                    prompt_results[gen_name] = {'error': str(e)}

            results[prompt] = prompt_results

        return results

    def generate_improvement_report(self, comparison_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ”¹è¿›æŠ¥å‘Š"""
        report = []
        report.append("# H2Q-Evo æ–‡æœ¬ç”Ÿæˆè´¨é‡æ”¹è¿›æŠ¥å‘Š")
        report.append("=" * 50)

        # æ±‡æ€»ç»Ÿè®¡
        generator_stats = {}
        for prompt, gen_results in comparison_results.items():
            for gen_name, result in gen_results.items():
                if 'error' not in result:
                    if gen_name not in generator_stats:
                        generator_stats[gen_name] = []
                    generator_stats[gen_name].append(result['metrics']['overall_quality'])

        report.append("\n## ğŸ“Š ç”Ÿæˆå™¨æ€§èƒ½æ±‡æ€»")
        for gen_name, scores in generator_stats.items():
            avg_score = sum(scores) / len(scores)
            report.append(f"- **{gen_name}**: å¹³å‡è´¨é‡è¯„åˆ† {avg_score:.3f}")

        # é—®é¢˜åˆ†æ
        report.append("\n## ğŸ” è´¨é‡é—®é¢˜åˆ†æ")
        report.append("åŸºäºæµ‹è¯•ç»“æœï¼Œå‘ç°çš„ä¸»è¦é—®é¢˜ï¼š")

        # åˆ†æç¬¬ä¸€ä¸ªç”Ÿæˆå™¨çš„ç»“æœä½œä¸ºåŸºå‡†
        first_gen = list(generator_stats.keys())[0]
        if generator_stats[first_gen]:
            avg_metrics = {}
            for prompt, gen_results in comparison_results.items():
                if first_gen in gen_results and 'error' not in gen_results[first_gen]:
                    metrics = gen_results[first_gen]['metrics']
                    for key, value in metrics.items():
                        if key not in avg_metrics:
                            avg_metrics[key] = []
                        avg_metrics[key].append(value)

            for key, values in avg_metrics.items():
                avg_value = sum(values) / len(values)
                if key == 'char_diversity' and avg_value < 0.1:
                    report.append(f"- **å­—ç¬¦å¤šæ ·æ€§ä¸è¶³** ({avg_value:.3f}): æ–‡æœ¬ä¸­é‡å¤å­—ç¬¦è¿‡å¤š")
                elif key == 'repetition_score' and avg_value > 0.5:
                    report.append(f"- **é‡å¤æ¨¡å¼ä¸¥é‡** ({avg_value:.3f}): å­˜åœ¨å¤§é‡é‡å¤çš„æ–‡æœ¬æ¨¡å¼")
                elif key == 'readability' and avg_value < 0.7:
                    report.append(f"- **å¯è¯»æ€§å·®** ({avg_value:.3f}): åŒ…å«å¤ªå¤šä¸å¯è¯»å­—ç¬¦")
                elif key == 'structural_integrity' and avg_value < 0.3:
                    report.append(f"- **ç»“æ„ä¸å®Œæ•´** ({avg_value:.3f}): å¥å­ç»“æ„æ®‹ç¼º")

        # æ”¹è¿›å»ºè®®
        report.append("\n## ğŸ’¡ æ”¹è¿›å»ºè®®")
        report.append("### 1. æ¨¡å‹æ¶æ„æ”¹è¿›")
        report.append("- ä½¿ç”¨æ›´å¤§çš„è¯æ±‡è¡¨ï¼ˆä»256æ‰©å±•åˆ°50,000+ï¼‰")
        report.append("- å®ç°BPEæˆ–WordPieceåˆ†è¯")
        report.append("- å¢åŠ æ¨¡å‹å‚æ•°å’Œå±‚æ•°")
        report.append("- ä½¿ç”¨é¢„è®­ç»ƒæƒé‡åˆå§‹åŒ–")

        report.append("\n### 2. è®­ç»ƒæ•°æ®ä¼˜åŒ–")
        report.append("- ä½¿ç”¨æ›´é«˜è´¨é‡ã€å¤šæ ·åŒ–çš„è®­ç»ƒæ•°æ®")
        report.append("- å¢åŠ æ•°æ®é‡ï¼ˆä»å‡ KBæ‰©å±•åˆ°GBçº§åˆ«ï¼‰")
        report.append("- å®ç°æ•°æ®å¢å¼ºæŠ€æœ¯")
        report.append("- å¹³è¡¡ä¸åŒé¢†åŸŸçš„æ–‡æœ¬åˆ†å¸ƒ")

        report.append("\n### 3. è§£ç ç­–ç•¥æ”¹è¿›")
        report.append("- å®ç°Top-kå’ŒTop-pé‡‡æ ·")
        report.append("- æ·»åŠ æ¸©åº¦æ§åˆ¶")
        report.append("- ä½¿ç”¨é‡å¤æƒ©ç½šæœºåˆ¶")
        report.append("- å®ç°é•¿åº¦æƒ©ç½š")

        report.append("\n### 4. é‡å­å¢å¼ºé›†æˆ")
        report.append("- é›†æˆH2Qçš„é‡å­æ¨ç†èƒ½åŠ›")
        report.append("- ä½¿ç”¨å…¨çº¯æµä¸­é—´ä»¶è¿›è¡Œæ¨ç†å¢å¼º")
        report.append("- å®ç°é‡å­å†³ç­–å¼•æ“è¾…åŠ©ç”Ÿæˆ")
        report.append("- åˆ©ç”¨æ‹“æ‰‘å­¦åŸç†ä¼˜åŒ–ç”Ÿæˆè¿‡ç¨‹")

        report.append("\n### 5. åå¤„ç†æŠ€æœ¯")
        report.append("- å®ç°æ–‡æœ¬åå¤„ç†å’Œæ¸…ç†")
        report.append("- æ·»åŠ è¯­æ³•æ£€æŸ¥å’Œä¿®æ­£")
        report.append("- ä½¿ç”¨è¯­è¨€æ¨¡å‹è¿›è¡Œé‡æ’åº")
        report.append("- å®ç°å¤šæ ·æ€§å¢å¼ºæŠ€æœ¯")

        return "\n".join(report)


def create_baseline_generators():
    """åˆ›å»ºåŸºå‡†ç”Ÿæˆå™¨è¿›è¡Œå¯¹æ¯”"""
    comparator = TextGenerationComparator()

    # 1. åŸå§‹æœ¬åœ°ç”Ÿæˆå™¨
    original_generator = LocalLongTextGenerator()
    comparator.add_generator("åŸå§‹æœ¬åœ°ç”Ÿæˆå™¨", lambda prompt, length: original_generator.generate_long_text(prompt, max_tokens=length))

    # 2. éšæœºå­—ç¬¦ç”Ÿæˆå™¨ï¼ˆä½œä¸ºåŸºå‡†ï¼‰
    def random_char_generator(prompt: str, max_length: int) -> str:
        import random
        chars = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 ,.!?;:"
        result = prompt
        for _ in range(max_length - len(prompt)):
            result += random.choice(chars)
        return result

    comparator.add_generator("éšæœºå­—ç¬¦ç”Ÿæˆå™¨", random_char_generator)

    # 3. ç®€å•æ¨¡å¼é‡å¤ç”Ÿæˆå™¨
    def pattern_generator(prompt: str, max_length: int) -> str:
        base_patterns = ["äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "é‡å­è®¡ç®—"]
        result = prompt
        while len(result) < max_length:
            pattern = base_patterns[len(result) % len(base_patterns)]
            result += " " + pattern
        return result[:max_length]

    comparator.add_generator("æ¨¡å¼é‡å¤ç”Ÿæˆå™¨", pattern_generator)

    return comparator


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*60)
    print("ğŸ” H2Q-Evo æ–‡æœ¬è´¨é‡åˆ†æä¸æ”¹è¿›ç³»ç»Ÿ")
    print("="*60)
    print("ğŸ¯ ç›®æ ‡ï¼šåˆ†æä¸å¯è¯»æ–‡æœ¬é—®é¢˜ï¼Œæä¾›æ”¹è¿›æ–¹æ¡ˆ")
    print("ğŸ›¡ï¸ å®‰å…¨ï¼šå®Œå…¨ç¦»çº¿ï¼Œæ— è”ç½‘")
    print("="*60 + "\n")

    # åˆ›å»ºç”Ÿæˆå™¨å¯¹æ¯”å™¨
    comparator = create_baseline_generators()

    # æµ‹è¯•æç¤º
    test_prompts = [
        "äººå·¥æ™ºèƒ½çš„å‘å±•",
        "é‡å­è®¡ç®—åŸç†",
        "æœºå™¨å­¦ä¹ ç®—æ³•",
        "æ·±åº¦å­¦ä¹ æ¨¡å‹"
    ]

    # è¿è¡Œå¯¹æ¯”æµ‹è¯•
    print("ğŸ§ª è¿è¡Œç”Ÿæˆè´¨é‡å¯¹æ¯”æµ‹è¯•...")
    comparison_results = comparator.compare_generators(test_prompts, max_length=150)

    # ç”Ÿæˆæ”¹è¿›æŠ¥å‘Š
    print("\nğŸ“‹ ç”Ÿæˆæ”¹è¿›æŠ¥å‘Š...")
    improvement_report = comparator.generate_improvement_report(comparison_results)

    # ä¿å­˜æŠ¥å‘Š
    report_path = PROJECT_ROOT / "text_quality_improvement_report.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(improvement_report)

    print(f"ğŸ’¾ æ”¹è¿›æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    # æ˜¾ç¤ºå…³é”®å‘ç°
    print("\nğŸ¯ å…³é”®å‘ç°:")
    print("1. **å­—ç¬¦çº§æ¨¡å‹é™åˆ¶**: å½“å‰ä½¿ç”¨256å­—ç¬¦è¯æ±‡è¡¨ï¼Œæ— æ³•ç”Ÿæˆæœ‰æ„ä¹‰çš„è¯æ±‡")
    print("2. **è®­ç»ƒæ•°æ®ä¸è¶³**: æ•°æ®é‡å°ï¼Œè´¨é‡ä½ï¼Œå¯¼è‡´æ¨¡å‹æ— æ³•å­¦ä¹ è¯­è¨€æ¨¡å¼")
    print("3. **ç¼ºå°‘é¢„è®­ç»ƒ**: ä»éšæœºåˆå§‹åŒ–å¼€å§‹ï¼Œæ”¶æ•›å›°éš¾")
    print("4. **è§£ç ç­–ç•¥ç®€å•**: æ²¡æœ‰ä½¿ç”¨å…ˆè¿›çš„é‡‡æ ·æŠ€æœ¯")
    print("5. **é‡å­å¢å¼ºæœªé›†æˆ**: æ²¡æœ‰åˆ©ç”¨H2Qçš„æ ¸å¿ƒé‡å­æ¨ç†èƒ½åŠ›")

    print("\nğŸš€ è§£å†³æ–¹æ¡ˆ:")
    print("1. **å®ç°é«˜çº§åˆ†è¯**: ä»å­—ç¬¦çº§å‡çº§åˆ°å­è¯çº§ï¼ˆBPEï¼‰")
    print("2. **æ‰©å¤§è®­ç»ƒæ•°æ®**: åˆ›å»ºé«˜è´¨é‡ã€å¤šæ ·åŒ–çš„è®­ç»ƒæ•°æ®é›†")
    print("3. **é›†æˆé¢„è®­ç»ƒ**: åˆ©ç”¨ç°æœ‰H2Qæ¨¡å‹æƒé‡")
    print("4. **æ”¹è¿›è§£ç **: å®ç°Top-kã€Top-pé‡‡æ ·å’Œé‡å¤æƒ©ç½š")
    print("5. **é‡å­æ¨ç†å¢å¼º**: é›†æˆH2Qçš„é‡å­å†³ç­–å¼•æ“")

    print("\nğŸ§¬ è‡ªç”±è¿›åŒ–è·¯å¾„:")
    print("1. **é˜¶æ®µ1**: å®ç°BPEåˆ†è¯å’Œæ›´å¤§çš„è¯æ±‡è¡¨")
    print("2. **é˜¶æ®µ2**: åˆ›å»ºå¤§è§„æ¨¡é«˜è´¨é‡è®­ç»ƒæ•°æ®é›†")
    print("3. **é˜¶æ®µ3**: é›†æˆH2Qé¢„è®­ç»ƒæ¨¡å‹å’Œé‡å­æ¨ç†")
    print("4. **é˜¶æ®µ4**: å®ç°å…ˆè¿›çš„è§£ç ç­–ç•¥å’Œåå¤„ç†")
    print("5. **é˜¶æ®µ5**: è‡ªåŠ¨åŒ–è´¨é‡è¯„ä¼°å’ŒæŒç»­æ”¹è¿›")

    print(f"\nğŸ“– è¯¦ç»†æ”¹è¿›æ–¹æ¡ˆè¯·æŸ¥çœ‹: {report_path}")


if __name__ == "__main__":
    main()